{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":".grid-item { border: 1px solid #eee; padding: 2em; display: inline-block; width: 19em; height: 19em; vertical-align: top; } How to Make a Website from Scratch via Github Larry Pierce, aka Dad Wordy Passwords I Heart Make SQL + Jinja = Templating Done Right\u2122 Move to MkDocs A Rustic Journey Through Stream Stats Getting Rusty with Vim Dev Blog Tools :: A Quick Tour of My Setup What the SQL?! JOIN me at UNION Station Base16 Shell FZF + WordNet = Dictionary GNU Screen What the SQL?!? Lateral Joins What the SQL?!? WINDOW What the SQL?!? Recursive PSA: Vim Modulo '%' Returns Negative Numbers! Photography Refactored Making a Window Submode in Vim Vim Toggle Movement: I Just Want to Go Home Yank Without Jank Sensible Horizontal Scroll in Vim Vim Side Search: Making Search Fun Again BS to the Black Hole","title":"Latest Posts"},{"location":"about/","text":"Why, Scott, Why?! \u00b6 \"Why, Scott, Why?!\" is a collection of posts and projects which catalog the developer's history in the field. The site's name reflects a common sentiment when working with him due to his proclivity for making tools for problems no one thinks they have. Need to solve Wheel of Fortune puzzles from the command line? Neither has anyone else. Who is Scott? \u00b6 Scott makes software. His most interesting projects are tools spoken in passing, born of statements like, \"Wouldn't it be great if AWESOME_THING existed?\" Scott makes posts. A teacher at heart who loves sharing tips and tricks to anyone who will listen. May these articles live on longer than him so future readers can appreciate how easy they have it now. Writing code in a terminal using Vim? What's that?! Scott makes jokes. His sense of humor is an acquired taste full of puns and absurdities. Trail and error is used extensively throughout the process. One of them has got to be funny. Q & A \u00b6 Should SQL be taught in the class room? \u00b6 Yes. A language that describes data should be everyone's second language. It's supported by more business tools than Javascript and is easier to learn. How to exit Vim? \u00b6 Type literally: :qa! then press <enter> What's your favorite language? \u00b6 Ruby. It's not the fastest, but the most succinct for my uses. This may change depending on the project. Some tasks need speed, some may already be mostly implemented in another language's ecosystem, and sometimes Ruby is a bad team fit if everyone isn't comfortable with it. If I'm on a desert, I'll write Ruby in the sand. 10.times { p \"HELP\" } What projects have you worked on? \u00b6 See projects . What about my question? \u00b6 Do you have a question for Scott? Ask in the comments and he'll post an answer here or as a separate post.","title":"About"},{"location":"about/#why-scott-why","text":"\"Why, Scott, Why?!\" is a collection of posts and projects which catalog the developer's history in the field. The site's name reflects a common sentiment when working with him due to his proclivity for making tools for problems no one thinks they have. Need to solve Wheel of Fortune puzzles from the command line? Neither has anyone else.","title":"Why, Scott, Why?!"},{"location":"about/#who-is-scott","text":"Scott makes software. His most interesting projects are tools spoken in passing, born of statements like, \"Wouldn't it be great if AWESOME_THING existed?\" Scott makes posts. A teacher at heart who loves sharing tips and tricks to anyone who will listen. May these articles live on longer than him so future readers can appreciate how easy they have it now. Writing code in a terminal using Vim? What's that?! Scott makes jokes. His sense of humor is an acquired taste full of puns and absurdities. Trail and error is used extensively throughout the process. One of them has got to be funny.","title":"Who is Scott?"},{"location":"about/#q-a","text":"","title":"Q &amp; A"},{"location":"about/#should-sql-be-taught-in-the-class-room","text":"Yes. A language that describes data should be everyone's second language. It's supported by more business tools than Javascript and is easier to learn.","title":"Should SQL be taught in the class room?"},{"location":"about/#how-to-exit-vim","text":"Type literally: :qa! then press <enter>","title":"How to exit Vim?"},{"location":"about/#whats-your-favorite-language","text":"Ruby. It's not the fastest, but the most succinct for my uses. This may change depending on the project. Some tasks need speed, some may already be mostly implemented in another language's ecosystem, and sometimes Ruby is a bad team fit if everyone isn't comfortable with it. If I'm on a desert, I'll write Ruby in the sand. 10.times { p \"HELP\" }","title":"What's your favorite language?"},{"location":"about/#what-projects-have-you-worked-on","text":"See projects .","title":"What projects have you worked on?"},{"location":"about/#what-about-my-question","text":"Do you have a question for Scott? Ask in the comments and he'll post an answer here or as a separate post.","title":"What about my question?"},{"location":"projects/","text":"Projects \u00b6 Here's a list of Scott's public projects. The Vim projects are the most popular. Most of the projects could and use some TLC, but they worked at one point in time and served the author well. Smoke \u00b6 https://github.com/ddrscott/smoke Make your terminal smoke. Fake Pipe / Anonymizer \u00b6 https://github.com/ddrscott/fake_pipe A simply way to anonymize data for exporting to various departments for analytics and troubleshooting. This tool allows us to annotate a DB schema with special comments that can trigger different data mutations. Thread Logger \u00b6 https://github.com/ddrscott/thread_logger This is a logger wrapper that keeps in memory a ring buffer of log lines isolated to the Thread.current. The main use of this is to have access to log history for when exception happen. Ansinine \u00b6 https://github.com/ddrscott/ansinine Asinine things to do with ANSI escape codes. Flameboyant \u00b6 https://github.com/ddrscott/flameboyant Ruby profile with flame graphs. GCP Directory \u00b6 https://github.com/ddrscott/gcp_directory Listen to a directory for new files and send them to Google Cloud Print. Golumn \u00b6 https://github.com/ddrscott/golumn Golumn is a desktop CSV viewer to replace the column command. Think column with a \"g\". It behaves similar to the column command, but with a graphic user interface. It bridges the command line and desktop divide by allowing us to present tabular data outside the confines of the terminal. Hipaatitis \u00b6 https://github.com/ddrscott/hipaatitis A fake reference medical CRM with fake data and naughty queries. Listen SQL \u00b6 https://github.com/ddrscott/listen_sql Helper scripts to monitor SQL file changes and execute them using psql. Math Finder \u00b6 https://ddrscott.github.io/math-finder/ Find math problems in the number grid. Kids love it. Solver included. Model Mirror \u00b6 https://github.com/ddrscott/model_mirror This project provides a basic viewer of your Rails models without needing to configure your model relationships in YACF (Yet Another Config File). ModelMirror inspects your existing ActiveRecord associations using reflection to figure out the relationships. Poppy \u00b6 https://github.com/ddrscott/poppy Always on top resizable dialog displaying a URL. S3 Index \u00b6 https://github.com/ddrscott/s3_index This gem is intended to provide a catalog of S3 objects in order to easily query the metadata about those objects. S3 can provide a list of objects, but that is slow. With S3Index, you can save and query that list using standard database tools and SQL. Slack CLI \u00b6 https://github.com/ddrscott/slack_cli Post Slack messages from CLI. Socket2me \u00b6 https://github.com/ddrscott/socket2me Execute Javascript in the browser from the server using WebSockets. SQL Probe \u00b6 https://github.com/ddrscott/sql_probe SQL Probe is a tool to trace SQL utilization in your application and provides a UI to investigate how tables are accessed. Stream Stats \u00b6 https://github.com/ddrscott/stream_stats Output statistics about data from stdin while redirecting the data to stdout. The statistics are bytes read, bytes read per second, lines read, lines read per second and total seconds. Similar to pv command which I didn't know about until after I created this project. Sudoku \u00b6 https://github.com/ddrscott/sudoku Solver using backtracking prioritizing fewer choices first. vim-cycle-movements \u00b6 https://github.com/ddrscott/vim-cycle-movements http://ddrscott.github.io/blog/2016/vim-toggle-movement Provides a mechanism to perform different movements based on repetition. vim-sendtext \u00b6 https://github.com/ddrscott/vim-sendtext SendText-like support for running Vim with iTerm2 vim-side-search \u00b6 https://github.com/ddrscott/vim-side-search This plugin adds ag output to a side buffer with quick navigation mappings using comfortable Vim conventions. vim-textobj-anyblock \u00b6 https://github.com/ddrscott/vim-textobj-anyblock Guess the surrounding text object. vim-window \u00b6 https://github.com/ddrscott/vim-window This aims to make Vim window layouts a easier. The default mappings and commands make managing more than a couple windows difficult. wheeler \u00b6 https://github.com/ddrscott/wheeler Wheeler is a naive Wheel of Fortune solver. It does this by indexing sampled text from where ever into every possible contiguous combination of words up to a max phrase length.","title":"Projects"},{"location":"projects/#projects","text":"Here's a list of Scott's public projects. The Vim projects are the most popular. Most of the projects could and use some TLC, but they worked at one point in time and served the author well.","title":"Projects"},{"location":"projects/#smoke","text":"https://github.com/ddrscott/smoke Make your terminal smoke.","title":"Smoke"},{"location":"projects/#fake-pipe-anonymizer","text":"https://github.com/ddrscott/fake_pipe A simply way to anonymize data for exporting to various departments for analytics and troubleshooting. This tool allows us to annotate a DB schema with special comments that can trigger different data mutations.","title":"Fake Pipe / Anonymizer"},{"location":"projects/#thread-logger","text":"https://github.com/ddrscott/thread_logger This is a logger wrapper that keeps in memory a ring buffer of log lines isolated to the Thread.current. The main use of this is to have access to log history for when exception happen.","title":"Thread Logger"},{"location":"projects/#ansinine","text":"https://github.com/ddrscott/ansinine Asinine things to do with ANSI escape codes.","title":"Ansinine"},{"location":"projects/#flameboyant","text":"https://github.com/ddrscott/flameboyant Ruby profile with flame graphs.","title":"Flameboyant"},{"location":"projects/#gcp-directory","text":"https://github.com/ddrscott/gcp_directory Listen to a directory for new files and send them to Google Cloud Print.","title":"GCP Directory"},{"location":"projects/#golumn","text":"https://github.com/ddrscott/golumn Golumn is a desktop CSV viewer to replace the column command. Think column with a \"g\". It behaves similar to the column command, but with a graphic user interface. It bridges the command line and desktop divide by allowing us to present tabular data outside the confines of the terminal.","title":"Golumn"},{"location":"projects/#hipaatitis","text":"https://github.com/ddrscott/hipaatitis A fake reference medical CRM with fake data and naughty queries.","title":"Hipaatitis"},{"location":"projects/#listen-sql","text":"https://github.com/ddrscott/listen_sql Helper scripts to monitor SQL file changes and execute them using psql.","title":"Listen SQL"},{"location":"projects/#math-finder","text":"https://ddrscott.github.io/math-finder/ Find math problems in the number grid. Kids love it. Solver included.","title":"Math Finder"},{"location":"projects/#model-mirror","text":"https://github.com/ddrscott/model_mirror This project provides a basic viewer of your Rails models without needing to configure your model relationships in YACF (Yet Another Config File). ModelMirror inspects your existing ActiveRecord associations using reflection to figure out the relationships.","title":"Model Mirror"},{"location":"projects/#poppy","text":"https://github.com/ddrscott/poppy Always on top resizable dialog displaying a URL.","title":"Poppy"},{"location":"projects/#s3-index","text":"https://github.com/ddrscott/s3_index This gem is intended to provide a catalog of S3 objects in order to easily query the metadata about those objects. S3 can provide a list of objects, but that is slow. With S3Index, you can save and query that list using standard database tools and SQL.","title":"S3 Index"},{"location":"projects/#slack-cli","text":"https://github.com/ddrscott/slack_cli Post Slack messages from CLI.","title":"Slack CLI"},{"location":"projects/#socket2me","text":"https://github.com/ddrscott/socket2me Execute Javascript in the browser from the server using WebSockets.","title":"Socket2me"},{"location":"projects/#sql-probe","text":"https://github.com/ddrscott/sql_probe SQL Probe is a tool to trace SQL utilization in your application and provides a UI to investigate how tables are accessed.","title":"SQL Probe"},{"location":"projects/#stream-stats","text":"https://github.com/ddrscott/stream_stats Output statistics about data from stdin while redirecting the data to stdout. The statistics are bytes read, bytes read per second, lines read, lines read per second and total seconds. Similar to pv command which I didn't know about until after I created this project.","title":"Stream Stats"},{"location":"projects/#sudoku","text":"https://github.com/ddrscott/sudoku Solver using backtracking prioritizing fewer choices first.","title":"Sudoku"},{"location":"projects/#vim-cycle-movements","text":"https://github.com/ddrscott/vim-cycle-movements http://ddrscott.github.io/blog/2016/vim-toggle-movement Provides a mechanism to perform different movements based on repetition.","title":"vim-cycle-movements"},{"location":"projects/#vim-sendtext","text":"https://github.com/ddrscott/vim-sendtext SendText-like support for running Vim with iTerm2","title":"vim-sendtext"},{"location":"projects/#vim-side-search","text":"https://github.com/ddrscott/vim-side-search This plugin adds ag output to a side buffer with quick navigation mappings using comfortable Vim conventions.","title":"vim-side-search"},{"location":"projects/#vim-textobj-anyblock","text":"https://github.com/ddrscott/vim-textobj-anyblock Guess the surrounding text object.","title":"vim-textobj-anyblock"},{"location":"projects/#vim-window","text":"https://github.com/ddrscott/vim-window This aims to make Vim window layouts a easier. The default mappings and commands make managing more than a couple windows difficult.","title":"vim-window"},{"location":"projects/#wheeler","text":"https://github.com/ddrscott/wheeler Wheeler is a naive Wheel of Fortune solver. It does this by indexing sampled text from where ever into every possible contiguous combination of words up to a max phrase length.","title":"wheeler"},{"location":"blog/2014/octopress-to-the-rescue/","text":"Octopress to the Rescue \u00b6 After nearly a year without Posterous, I've finally got around to migrating to another system. This time around it's a static blog builder: http://octopress.org/ Octopress is a wrapper around Jekyll which is a utility for creating a static blogging site. A blog that can be hosted on anything that can server files: Apache, AWS, Dropbox, etc... Q: Why not use WordPress, Tumbler, Blogger?!? \u00b6 Those tailor to non-developers and their editors are not the ones I use everyday, my IDE. Octopress lets me write my articles the same way as I write code: plain text. It uses markdown or any other HTML generator I configure. Static pages are easier for me to deploy when I have to switch hosting providers. Hopefully Github sticks around for a while, but if they don't, I can rest assured I can have the article hosted some where else faster than DNS propagation. puts \"I can use code snippets\" # And they will be nicely formatted. maybe_one_day do use ( CodePen ) or use ( jsFiddle ) end The initial theme I selected is https://github.com/sevenadrian/MediumFox . It's clean, simple and pretty much what I would have tried to make if I had time. They seemed to have omitted some features from the classic theme, but as with all Open Source projects it is easy to remedy. Time to post to do my first deploy... then convert all the Posterous archives.","title":"Octopress to the Rescue"},{"location":"blog/2014/octopress-to-the-rescue/#octopress-to-the-rescue","text":"After nearly a year without Posterous, I've finally got around to migrating to another system. This time around it's a static blog builder: http://octopress.org/ Octopress is a wrapper around Jekyll which is a utility for creating a static blogging site. A blog that can be hosted on anything that can server files: Apache, AWS, Dropbox, etc...","title":"Octopress to the Rescue"},{"location":"blog/2014/octopress-to-the-rescue/#q-why-not-use-wordpress-tumbler-blogger","text":"Those tailor to non-developers and their editors are not the ones I use everyday, my IDE. Octopress lets me write my articles the same way as I write code: plain text. It uses markdown or any other HTML generator I configure. Static pages are easier for me to deploy when I have to switch hosting providers. Hopefully Github sticks around for a while, but if they don't, I can rest assured I can have the article hosted some where else faster than DNS propagation. puts \"I can use code snippets\" # And they will be nicely formatted. maybe_one_day do use ( CodePen ) or use ( jsFiddle ) end The initial theme I selected is https://github.com/sevenadrian/MediumFox . It's clean, simple and pretty much what I would have tried to make if I had time. They seemed to have omitted some features from the classic theme, but as with all Open Source projects it is easy to remedy. Time to post to do my first deploy... then convert all the Posterous archives.","title":"Q: Why not use WordPress, Tumbler, Blogger?!?"},{"location":"blog/2014/tech-stack-2014-edition/","text":"Tech Stack 2014 Edition \u00b6 I've built a lot of things, but the most interesting thing is usually what I'm currently working on or have built recently. With that in mind I thought I'd take a moment to reflect on the technology stack of my current project. Overview \u00b6 The service provided is a mobile eBook store. End users can find, buy and read books in their browser and on mobile app platforms like iOS and Android. Frameworks \u00b6 The framework selection was very organic and was not chosen all at once. I had extensive background in Rails so it made sense to start there and integrate into other systems via RubyGem plugins when vanilla Rails/Database didn't fit. Ruby on Rails \u00b6 I've been using this since version 1, and never looked back. Rails and the Ruby language \"get\" me. They think the way I do \u2013 they complete me. Prior to Ruby I was using Java and writing wrappers that were very similar Ruby and ActiveRecord/Support so to find a language and framework that did all that and more was a dream come true. The discovery was in 2005 which makes it 9 years old. That's like 50 tech years. That being said. I still have not found another language or framework that does things more intuitively that Ruby or Rails. Maybe I'm an old dog that can't learn new tricks. Maybe I'm stuck in my ways. Regardless, I still feel productive and I believe my human clients agree. Solr / Sunspot \u00b6 We started using SQL search and quickly ran into performance walls for the variety queries we needed to perform, so we needed something else. Lucene is the industry standard in searching. Solr puts a wrapper around Lucene that allows for dynamic index fields additions and provides more search options. Sunspot integrates all that into ActiveRecord. It took maybe 10 minutes for us to try out Sunspot in our current catalog modals and made the user search experience faster. The thing we miss by not having database queries is table joins. Joins are available in Solr, but have a similar performance hit as DB. The workaround for joins was to have a wide data set. Example Sunspot Model Config \u00b6 class Node belongs_to :title end class Title has_many :nodes has_many :prices searchable do text :name text :contributors text :snippet integer :nodes , multiple : true do solr_nodes ; end string :countries , multiple : true do solr_countries ; end string :currencies , multiple : true do solr_currencies ; end Price . select ( :country , :currency ) . uniq . each do | price | double \" #{ price . country } _ #{ price . currency } \" do solr_country_currency ( price ); end end # ... many other fields end def solr_countries prices . pluck ( :country ) end def solr_currencies prices . pluck ( :currency ) end def solr_country_currency ( price ) prices . where ( country : price . country , currency : price . currency ) . first . try ( :price ) end end class Price belongs_to :title end Example Sunspot Search \u00b6 Title . search do full_text ( 'cats' ) with ( :US_USD ) . less_than ( 1 . 0 ) end The Sunspot site has many examples: http://sunspot.github.io/ Redis \u00b6 http://redis.io describes themselves as: Redis is an open source, BSD licensed, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets. To me this is a remote shared hash, array, stack, and queue. All atomic all almost fast as locale memory structures. Here's how I'm using it: Rails.cache for reponse caching Resque queues to off load long jobs to a background process. System wide mutex via setnx and hsetnx command Anything that would require a DB lock, I would prefer to let Redis handle the lock. This one concept has allowed my RDBMS to stay small and lean. ... Check out their documentation for more ideas. Every time I read through the docs I come up with 10 more things I could take off my RDBMS. If only I had could do it over again. Couch DB \u00b6 Couch is our dump of raw contents. We only use 20% of Couch's features because the remaining map/reduce portions of the system took long for our data set. I'm sure there are better ways to use it, but in the end one the main features of how it indexes and aggregates data we can't use. Maybe in the future, but we've already moved on. The feature we do use though is a version controlled document store. We take in various sources of data from an external source, convert it to JSON, add a few state tracking fields, and store it in Couch. Couch make the document retrieval fast and painless. Apache/Passenger \u00b6 I should be using Nginx, but haven't quite gotten around to figuring it out. Apache is fast enough for our needs right now. Passenger is the gold standard in managing multiple Ruby web processes. Nothing too exciting here. It just works. Node.js \u00b6 http://nodejs.org/ This is where the system starts to Frankenstein. We use Node.js for Socket.io Socket.io \u00b6 http://socket.io/ Most of the cool factor of your system revolves around the use of Socket.io to bring realtime server push to all our front ends: Browser and Apps. When we have a flash sale or special offer web sockets delivers.","title":"Tech Stack 2014 Edition"},{"location":"blog/2014/tech-stack-2014-edition/#tech-stack-2014-edition","text":"I've built a lot of things, but the most interesting thing is usually what I'm currently working on or have built recently. With that in mind I thought I'd take a moment to reflect on the technology stack of my current project.","title":"Tech Stack 2014 Edition"},{"location":"blog/2014/tech-stack-2014-edition/#overview","text":"The service provided is a mobile eBook store. End users can find, buy and read books in their browser and on mobile app platforms like iOS and Android.","title":"Overview"},{"location":"blog/2014/tech-stack-2014-edition/#frameworks","text":"The framework selection was very organic and was not chosen all at once. I had extensive background in Rails so it made sense to start there and integrate into other systems via RubyGem plugins when vanilla Rails/Database didn't fit.","title":"Frameworks"},{"location":"blog/2014/tech-stack-2014-edition/#ruby-on-rails","text":"I've been using this since version 1, and never looked back. Rails and the Ruby language \"get\" me. They think the way I do \u2013 they complete me. Prior to Ruby I was using Java and writing wrappers that were very similar Ruby and ActiveRecord/Support so to find a language and framework that did all that and more was a dream come true. The discovery was in 2005 which makes it 9 years old. That's like 50 tech years. That being said. I still have not found another language or framework that does things more intuitively that Ruby or Rails. Maybe I'm an old dog that can't learn new tricks. Maybe I'm stuck in my ways. Regardless, I still feel productive and I believe my human clients agree.","title":"Ruby on Rails"},{"location":"blog/2014/tech-stack-2014-edition/#solr-sunspot","text":"We started using SQL search and quickly ran into performance walls for the variety queries we needed to perform, so we needed something else. Lucene is the industry standard in searching. Solr puts a wrapper around Lucene that allows for dynamic index fields additions and provides more search options. Sunspot integrates all that into ActiveRecord. It took maybe 10 minutes for us to try out Sunspot in our current catalog modals and made the user search experience faster. The thing we miss by not having database queries is table joins. Joins are available in Solr, but have a similar performance hit as DB. The workaround for joins was to have a wide data set.","title":"Solr / Sunspot"},{"location":"blog/2014/tech-stack-2014-edition/#example-sunspot-model-config","text":"class Node belongs_to :title end class Title has_many :nodes has_many :prices searchable do text :name text :contributors text :snippet integer :nodes , multiple : true do solr_nodes ; end string :countries , multiple : true do solr_countries ; end string :currencies , multiple : true do solr_currencies ; end Price . select ( :country , :currency ) . uniq . each do | price | double \" #{ price . country } _ #{ price . currency } \" do solr_country_currency ( price ); end end # ... many other fields end def solr_countries prices . pluck ( :country ) end def solr_currencies prices . pluck ( :currency ) end def solr_country_currency ( price ) prices . where ( country : price . country , currency : price . currency ) . first . try ( :price ) end end class Price belongs_to :title end","title":"Example Sunspot Model Config"},{"location":"blog/2014/tech-stack-2014-edition/#example-sunspot-search","text":"Title . search do full_text ( 'cats' ) with ( :US_USD ) . less_than ( 1 . 0 ) end The Sunspot site has many examples: http://sunspot.github.io/","title":"Example Sunspot Search"},{"location":"blog/2014/tech-stack-2014-edition/#redis","text":"http://redis.io describes themselves as: Redis is an open source, BSD licensed, advanced key-value store. It is often referred to as a data structure server since keys can contain strings, hashes, lists, sets and sorted sets. To me this is a remote shared hash, array, stack, and queue. All atomic all almost fast as locale memory structures. Here's how I'm using it: Rails.cache for reponse caching Resque queues to off load long jobs to a background process. System wide mutex via setnx and hsetnx command Anything that would require a DB lock, I would prefer to let Redis handle the lock. This one concept has allowed my RDBMS to stay small and lean. ... Check out their documentation for more ideas. Every time I read through the docs I come up with 10 more things I could take off my RDBMS. If only I had could do it over again.","title":"Redis"},{"location":"blog/2014/tech-stack-2014-edition/#couch-db","text":"Couch is our dump of raw contents. We only use 20% of Couch's features because the remaining map/reduce portions of the system took long for our data set. I'm sure there are better ways to use it, but in the end one the main features of how it indexes and aggregates data we can't use. Maybe in the future, but we've already moved on. The feature we do use though is a version controlled document store. We take in various sources of data from an external source, convert it to JSON, add a few state tracking fields, and store it in Couch. Couch make the document retrieval fast and painless.","title":"Couch DB"},{"location":"blog/2014/tech-stack-2014-edition/#apachepassenger","text":"I should be using Nginx, but haven't quite gotten around to figuring it out. Apache is fast enough for our needs right now. Passenger is the gold standard in managing multiple Ruby web processes. Nothing too exciting here. It just works.","title":"Apache/Passenger"},{"location":"blog/2014/tech-stack-2014-edition/#nodejs","text":"http://nodejs.org/ This is where the system starts to Frankenstein. We use Node.js for Socket.io","title":"Node.js"},{"location":"blog/2014/tech-stack-2014-edition/#socketio","text":"http://socket.io/ Most of the cool factor of your system revolves around the use of Socket.io to bring realtime server push to all our front ends: Browser and Apps. When we have a flash sale or special offer web sockets delivers.","title":"Socket.io"},{"location":"blog/2016/ansi-codes-with-character/","text":"ANSI Codes with Character \u00b6 This was a lightening talk given to the office about ANSI Escape Codes. Most of the time, all 5 minutes of it, was spent explaining the code snippets. Wiki about ANSI Codes What is an ANSI code? \u00b6 ANSI Escape Codes are a nearly universal means of embedding display options in computer terminals. \\e[ is how to tell the terminal we're giving it a command instead just outputting text. What does that mean?!? Let the examples do the talking. Color Examples \u00b6 echo -e \"\\e[2J\\e[32m It's not easy being green \\e[0m\" echo -e \"\\e[2J\\e[31m Apples are red \\e[0m\" ( 30 .. 37 ) . each { | i | puts \"i: \\e [ #{ i } m #{ i } \\e [0m\" } Position Examples \u00b6 x = `tput cols` . to_i y = `tput lines` . to_i loop do print \" \\e [s\" # Save current cursor position print \" \\e [ #{ rand ( y ) } ; #{ rand ( x ) } H\" # move to row/column print \"\ud83d\udca9\" # print POOP! print \" \\e [u\" # restore position sleep ( rand ) end # Ruby oneliner troll ruby -e 'x=`tput cols`.to_i; y=`tput lines`.to_i; loop {print \"\\e[s\\e[#{rand(y)};#{rand(x)}H\ud83d\udca9\\e[u\"; sleep(rand)}' ANSI-nine Examples \u00b6 # Poop-field curl -s https://raw.githubusercontent.com/ddrscott/ansinine/master/stars | ruby # Smoke curl -s https://raw.githubusercontent.com/ddrscott/ansinine/master/fire.rb | ruby","title":"ANSI Codes with Character"},{"location":"blog/2016/ansi-codes-with-character/#ansi-codes-with-character","text":"This was a lightening talk given to the office about ANSI Escape Codes. Most of the time, all 5 minutes of it, was spent explaining the code snippets. Wiki about ANSI Codes","title":"ANSI Codes with Character"},{"location":"blog/2016/ansi-codes-with-character/#what-is-an-ansi-code","text":"ANSI Escape Codes are a nearly universal means of embedding display options in computer terminals. \\e[ is how to tell the terminal we're giving it a command instead just outputting text. What does that mean?!? Let the examples do the talking.","title":"What is an ANSI code?"},{"location":"blog/2016/ansi-codes-with-character/#color-examples","text":"echo -e \"\\e[2J\\e[32m It's not easy being green \\e[0m\" echo -e \"\\e[2J\\e[31m Apples are red \\e[0m\" ( 30 .. 37 ) . each { | i | puts \"i: \\e [ #{ i } m #{ i } \\e [0m\" }","title":"Color Examples"},{"location":"blog/2016/ansi-codes-with-character/#position-examples","text":"x = `tput cols` . to_i y = `tput lines` . to_i loop do print \" \\e [s\" # Save current cursor position print \" \\e [ #{ rand ( y ) } ; #{ rand ( x ) } H\" # move to row/column print \"\ud83d\udca9\" # print POOP! print \" \\e [u\" # restore position sleep ( rand ) end # Ruby oneliner troll ruby -e 'x=`tput cols`.to_i; y=`tput lines`.to_i; loop {print \"\\e[s\\e[#{rand(y)};#{rand(x)}H\ud83d\udca9\\e[u\"; sleep(rand)}'","title":"Position Examples"},{"location":"blog/2016/ansi-codes-with-character/#ansi-nine-examples","text":"# Poop-field curl -s https://raw.githubusercontent.com/ddrscott/ansinine/master/stars | ruby # Smoke curl -s https://raw.githubusercontent.com/ddrscott/ansinine/master/fire.rb | ruby","title":"ANSI-nine Examples"},{"location":"blog/2016/bs-to-the-black-hole/","text":"BS to the Black Hole \u00b6 First post in 2 years. Sorry to keep you waiting. I've been playing with Vim again, more specifically NeoVim https://neovim.io/ , and this time I think it's going to stick. The Problem \u00b6 Sometimes, I want to delete text without worrying about blowing away the unnamed register. This can be done by prefixing a normal or visual delete with \"_ , but that's an awkward dance for my pinky and ring finger. Go ahead, try it. You'll feel like you're in junior high again. Solution #1 \u00b6 Setup a single key to do that \"_ thing for me. So my naive approach was to add the following: nnoremap < BS > \"_ vnoremap < BS > \"_ This was fine for 32.1 seconds of usability testing. It did the job, but what cames after a \"_ was usually a dw or db operator. Ah oh, I said the \"o\" word. That means I have to make a opfunc . (Who makes these rules?!?) Solution #2 \u00b6 So what is this operator going to let us do? How about <BS>iw or <BS>ap or v{motion around something you hate}<BS> ? If any of those seem awesome, here's how to get in on the hot action! \" Add to your .vimrc or init.vim or vim.after or :e $MYVIMRC func ! BlackHoleDeleteOperator ( type ) if a :type == # 'char' execute 'normal! `[v`]\"_d' elseif a :type == # 'line' execute 'normal! `[V`]\"_d' else execute 'normal! `<' . a :type . '`>\"_d' endif endf \" Map to <BS> because it's under worked in Vim. nnoremap < silent > < BS > < Esc > : set opfunc = BlackHoleDeleteOperator < CR > g @ vnoremap < silent > < BS > : < C - u > call BlackHoleDeleteOperator ( visualmode ())< CR > How Does it Work? \u00b6 opfunc is best explained in Vim help. Use :help opfunc and follow the <C-]> until clarity is achieved. :help normal - evaluates the following characters as if they were typed. :help marks - page down a bit to get the list of automatic marks based on last positions of various changes, jumps, and actions. http://learnvimscriptthehardway.stevelosh.com/chapters/33.html - seriously, this guy does a lot better explaining than me. Learn it the hard way, first, ask questions later. Closing \u00b6 Thanks for getting this far. Do you have a better mapping for <BS> ? Do you have a more creative solution than typing \"_ to access the black hole register? Let me know by commenting or share this post to some one who does.","title":"BS to the Black Hole"},{"location":"blog/2016/bs-to-the-black-hole/#bs-to-the-black-hole","text":"First post in 2 years. Sorry to keep you waiting. I've been playing with Vim again, more specifically NeoVim https://neovim.io/ , and this time I think it's going to stick.","title":"BS to the Black Hole"},{"location":"blog/2016/bs-to-the-black-hole/#the-problem","text":"Sometimes, I want to delete text without worrying about blowing away the unnamed register. This can be done by prefixing a normal or visual delete with \"_ , but that's an awkward dance for my pinky and ring finger. Go ahead, try it. You'll feel like you're in junior high again.","title":"The Problem"},{"location":"blog/2016/bs-to-the-black-hole/#solution-1","text":"Setup a single key to do that \"_ thing for me. So my naive approach was to add the following: nnoremap < BS > \"_ vnoremap < BS > \"_ This was fine for 32.1 seconds of usability testing. It did the job, but what cames after a \"_ was usually a dw or db operator. Ah oh, I said the \"o\" word. That means I have to make a opfunc . (Who makes these rules?!?)","title":"Solution #1"},{"location":"blog/2016/bs-to-the-black-hole/#solution-2","text":"So what is this operator going to let us do? How about <BS>iw or <BS>ap or v{motion around something you hate}<BS> ? If any of those seem awesome, here's how to get in on the hot action! \" Add to your .vimrc or init.vim or vim.after or :e $MYVIMRC func ! BlackHoleDeleteOperator ( type ) if a :type == # 'char' execute 'normal! `[v`]\"_d' elseif a :type == # 'line' execute 'normal! `[V`]\"_d' else execute 'normal! `<' . a :type . '`>\"_d' endif endf \" Map to <BS> because it's under worked in Vim. nnoremap < silent > < BS > < Esc > : set opfunc = BlackHoleDeleteOperator < CR > g @ vnoremap < silent > < BS > : < C - u > call BlackHoleDeleteOperator ( visualmode ())< CR >","title":"Solution #2"},{"location":"blog/2016/bs-to-the-black-hole/#how-does-it-work","text":"opfunc is best explained in Vim help. Use :help opfunc and follow the <C-]> until clarity is achieved. :help normal - evaluates the following characters as if they were typed. :help marks - page down a bit to get the list of automatic marks based on last positions of various changes, jumps, and actions. http://learnvimscriptthehardway.stevelosh.com/chapters/33.html - seriously, this guy does a lot better explaining than me. Learn it the hard way, first, ask questions later.","title":"How Does it Work?"},{"location":"blog/2016/bs-to-the-black-hole/#closing","text":"Thanks for getting this far. Do you have a better mapping for <BS> ? Do you have a more creative solution than typing \"_ to access the black hole register? Let me know by commenting or share this post to some one who does.","title":"Closing"},{"location":"blog/2016/making-a-window-submode/","text":"Making a Window Submode in Vim \u00b6 I found a plugin that is changing my Vim-tire life! This plugin is so awesome it should be built into default Vim. What does the plugin do? It enables the creation of new submodes. Why would a person want more modes?!? Isn't dealing with modes the main deterrent for new Vim users? Isn't Normal, Insert, Command-line, Visual, Select, and Operator-pending enough? (Did I miss one?) Let's try out a new submode and see what happens. Problem \u00b6 Window commands are prefixed with <C-w> . Want to create a horizontal split? Try <C-w>s , didn't mean to do that and want to do vertical split? <C-w>q<C-w>v . Want to resize the vertical split 50<C-w>> ? Too wide? Narrow it with 5<C-w>< . Move back to the other window? <C-w>p or <C-w>w . Are your fingers getting tired? After I get the windows just right using default mappings my fingers are crying for mercy. Here's a short list of common default window commands: \" Change window focus { n } < C - w > h move cursor left { n } window { n } < C - w > l move cursor right { n } window { n } < C - w > j move cursor down { n } window { n } < C - w > k move cursor up { n } window \" Move window < C - w > H move window far left < C - w > L move window far right < C - w > J move window far bottom < C - w > K move window far top \" Change size { n } < C - w >+ increase height by { n } rows { n } < C - w >- decrease height by { n } rows { n } < C - w >< decrease width by { n } columns { n } < C - w >> increase width by { n } columns < C - w >| maximize width < C - w > _ maximize height < C - w >= equalize sizes For a comprehensive list of window commands try :help windows.txt . Solution A \u00b6 The most common solution to window-command-itis is to map other keys to these common actions so to include the <C-w> prefix. From spf13-vim : map < C - J > < C - W > j < C - W > _ map < C - K > < C - W > k < C - W > _ map < C - L > < C - W > l < C - W > _ map < C - H > < C - W > h < C - W > _ \" Note: They go one extra by maximizing the height after entering the split. From Thoughbot : nnoremap < C - J > < C - W >< C - J > nnoremap < C - K > < C - W >< C - K > nnoremap < C - L > < C - W >< C - L > nnoremap < C - H > < C - W >< C - H > This has been the accepted solution for most, but it takes away so many convenient keys. And in some cases, it even overrides default behaviour. <C-L> , I miss you. C-H , isn't that also <BS> ? Guess I won't be using you either. Solution B - Submode to the Rescue \u00b6 This entire solution depends on kana/vim-submode , I consider it one of Japan's national treasures along with ninjas and ramen. Unfortunately, Kana's example use of submodes is a little underwhelming: undo/redo using g- and g+ . I agree with the author that using g- and g+ is not convenient, and using g++++-++-+ is easier, but the solution for that was simply u and <C-R> . I feel a better application for a new submode is window management. Imagine if resizing a split was <C-w>++++++++ or <C-w>------=->>>>>>>><> or changing cursor location was <C-w>hjlll or moving was <C-w>HjKLkjh . Imagine no more! First, install the plugin. If you're not sure how to install a plugin, try junegunn/vim-plug . Next, add the following to your $MYVIMRC . \" A message will appear in the message line when you're in a submode \" and stay there until the mode has existed. let g :submode_always_show_submode = 1 \" We're taking over the default <C-w> setting. Don't worry we'll do \" our best to put back the default functionality. call submode#enter_with ( 'window' , 'n' , '' , '<C-w>' ) \" Note: <C-c> will also get you out to the mode without this mapping. \" Note: <C-[> also behaves as <ESC> call submode#leave_with ( 'window' , 'n' , '' , '<ESC>' ) \" Go through every letter for key in [ 'a' , 'b' , 'c' , 'd' , 'e' , 'f' , 'g' , 'h' , 'i' , 'j' , 'k' , 'l' , 'm' , \\ 'n' , 'o' , 'p' , 'q' , 'r' , 's' , 't' , 'u' , 'v' , 'w' , 'x' , 'y' , 'z' ] \" maps lowercase, uppercase and <C-key> call submode#map ( 'window' , 'n' , '' , key , '<C-w>' . key ) call submode#map ( 'window' , 'n' , '' , toupper ( key ), '<C-w>' . toupper ( key )) call submode#map ( 'window' , 'n' , '' , '<C-' . key . '>' , '<C-w>' . '<C-' . key . '>' ) endfor \" Go through symbols. Sadly, '|', not supported in submode plugin. for key in [ '=' , '_' , '+' , '-' , '<' , '>' ] call submode#map ( 'window' , 'n' , '' , key , '<C-w>' . key ) endfor \" Old way, just in case. nnoremap < Leader > w < C - w > After :source $MYVIMRC , you'll have a glorious new submode in Vim. You can see I named it window mode. Can you guess how to get into window mode? <C-w> , the normal prefix used to do any wincmd . If this is too drastic, feel free to change line #7 to something else. Just replace <C-w> with a different normal mapping. Let's give it a test drive. I know you can't see what keys I'm pressing, but I guarantee I only pressed <C-w> once. I also didn't have to remember any new key bindings. The hesitation in the demo is the resistance to hitting <C-w> every time, which I'll get over soon enough. Bonus Mappings \u00b6 But wait there's more! In case I haven't provided enough tips for one post, here's the overrides I have in $MYVIMRC to make windowing even better. \" I don't like <C-w>q, <C-w>c won't exit Vim when it's the last window. call submode#map ( 'window' , 'n' , '' , 'q' , '<C-w>c' ) call submode#map ( 'window' , 'n' , '' , '<C-q>' , '<C-w>c' ) \" <lowercase-pipe> sets the width to 80 columns, pipe (<S-\\>) by default \" maximizes the width. call submode#map ( 'window' , 'n' , '' , '\\' , ':vertical resize 80<CR>' ) \" Resize faster call submode#map ( 'window' , 'n' , '' , '+' , '3<C-w>+' ) call submode#map ( 'window' , 'n' , '' , '-' , '3<C-w>-' ) call submode#map ( 'window' , 'n' , '' , '<' , '10<C-w><' ) call submode#map ( 'window' , 'n' , '' , '>' , '10<C-w>>' ) Rainbows without Unicorns \u00b6 While learning this new way of windowing, there have been a few negatives: I forget that I'm in window mode and get disoriented when I think I'm moving the cursor within a buffer, but it jumps around to other splits. For one off window commands, I have to hit an extra key to get out of window mode or wait for the timeout. When I use some one else's computer, I'm useless. I think most of these annoyances will go away with time, and the benefits overtime in keystroke savings are non-trivial. As for #3 , regardless of submodes, the brain freeze will never go away, because no one thinks as strangely as me, and that's a Good Thing\u2122. Thanks \u00b6 Shout-out to Kana Natsuno, @kana1 , http://whileimautomaton.net/ , https://github.com/kana . None of this awesomeness would be possible without https://github.com/kana/vim-submode . She makes some totally sweet plug-ins. Check out her stuff. You won't regret it! Let me know what you think. Am I crazy? What other things deserve a submode? Hit me up in the comments below! Thanks for reading!","title":"Making a Window Submode in Vim"},{"location":"blog/2016/making-a-window-submode/#making-a-window-submode-in-vim","text":"I found a plugin that is changing my Vim-tire life! This plugin is so awesome it should be built into default Vim. What does the plugin do? It enables the creation of new submodes. Why would a person want more modes?!? Isn't dealing with modes the main deterrent for new Vim users? Isn't Normal, Insert, Command-line, Visual, Select, and Operator-pending enough? (Did I miss one?) Let's try out a new submode and see what happens.","title":"Making a Window Submode in Vim"},{"location":"blog/2016/making-a-window-submode/#problem","text":"Window commands are prefixed with <C-w> . Want to create a horizontal split? Try <C-w>s , didn't mean to do that and want to do vertical split? <C-w>q<C-w>v . Want to resize the vertical split 50<C-w>> ? Too wide? Narrow it with 5<C-w>< . Move back to the other window? <C-w>p or <C-w>w . Are your fingers getting tired? After I get the windows just right using default mappings my fingers are crying for mercy. Here's a short list of common default window commands: \" Change window focus { n } < C - w > h move cursor left { n } window { n } < C - w > l move cursor right { n } window { n } < C - w > j move cursor down { n } window { n } < C - w > k move cursor up { n } window \" Move window < C - w > H move window far left < C - w > L move window far right < C - w > J move window far bottom < C - w > K move window far top \" Change size { n } < C - w >+ increase height by { n } rows { n } < C - w >- decrease height by { n } rows { n } < C - w >< decrease width by { n } columns { n } < C - w >> increase width by { n } columns < C - w >| maximize width < C - w > _ maximize height < C - w >= equalize sizes For a comprehensive list of window commands try :help windows.txt .","title":"Problem"},{"location":"blog/2016/making-a-window-submode/#solution-a","text":"The most common solution to window-command-itis is to map other keys to these common actions so to include the <C-w> prefix. From spf13-vim : map < C - J > < C - W > j < C - W > _ map < C - K > < C - W > k < C - W > _ map < C - L > < C - W > l < C - W > _ map < C - H > < C - W > h < C - W > _ \" Note: They go one extra by maximizing the height after entering the split. From Thoughbot : nnoremap < C - J > < C - W >< C - J > nnoremap < C - K > < C - W >< C - K > nnoremap < C - L > < C - W >< C - L > nnoremap < C - H > < C - W >< C - H > This has been the accepted solution for most, but it takes away so many convenient keys. And in some cases, it even overrides default behaviour. <C-L> , I miss you. C-H , isn't that also <BS> ? Guess I won't be using you either.","title":"Solution A"},{"location":"blog/2016/making-a-window-submode/#solution-b-submode-to-the-rescue","text":"This entire solution depends on kana/vim-submode , I consider it one of Japan's national treasures along with ninjas and ramen. Unfortunately, Kana's example use of submodes is a little underwhelming: undo/redo using g- and g+ . I agree with the author that using g- and g+ is not convenient, and using g++++-++-+ is easier, but the solution for that was simply u and <C-R> . I feel a better application for a new submode is window management. Imagine if resizing a split was <C-w>++++++++ or <C-w>------=->>>>>>>><> or changing cursor location was <C-w>hjlll or moving was <C-w>HjKLkjh . Imagine no more! First, install the plugin. If you're not sure how to install a plugin, try junegunn/vim-plug . Next, add the following to your $MYVIMRC . \" A message will appear in the message line when you're in a submode \" and stay there until the mode has existed. let g :submode_always_show_submode = 1 \" We're taking over the default <C-w> setting. Don't worry we'll do \" our best to put back the default functionality. call submode#enter_with ( 'window' , 'n' , '' , '<C-w>' ) \" Note: <C-c> will also get you out to the mode without this mapping. \" Note: <C-[> also behaves as <ESC> call submode#leave_with ( 'window' , 'n' , '' , '<ESC>' ) \" Go through every letter for key in [ 'a' , 'b' , 'c' , 'd' , 'e' , 'f' , 'g' , 'h' , 'i' , 'j' , 'k' , 'l' , 'm' , \\ 'n' , 'o' , 'p' , 'q' , 'r' , 's' , 't' , 'u' , 'v' , 'w' , 'x' , 'y' , 'z' ] \" maps lowercase, uppercase and <C-key> call submode#map ( 'window' , 'n' , '' , key , '<C-w>' . key ) call submode#map ( 'window' , 'n' , '' , toupper ( key ), '<C-w>' . toupper ( key )) call submode#map ( 'window' , 'n' , '' , '<C-' . key . '>' , '<C-w>' . '<C-' . key . '>' ) endfor \" Go through symbols. Sadly, '|', not supported in submode plugin. for key in [ '=' , '_' , '+' , '-' , '<' , '>' ] call submode#map ( 'window' , 'n' , '' , key , '<C-w>' . key ) endfor \" Old way, just in case. nnoremap < Leader > w < C - w > After :source $MYVIMRC , you'll have a glorious new submode in Vim. You can see I named it window mode. Can you guess how to get into window mode? <C-w> , the normal prefix used to do any wincmd . If this is too drastic, feel free to change line #7 to something else. Just replace <C-w> with a different normal mapping. Let's give it a test drive. I know you can't see what keys I'm pressing, but I guarantee I only pressed <C-w> once. I also didn't have to remember any new key bindings. The hesitation in the demo is the resistance to hitting <C-w> every time, which I'll get over soon enough.","title":"Solution B - Submode to the Rescue"},{"location":"blog/2016/making-a-window-submode/#bonus-mappings","text":"But wait there's more! In case I haven't provided enough tips for one post, here's the overrides I have in $MYVIMRC to make windowing even better. \" I don't like <C-w>q, <C-w>c won't exit Vim when it's the last window. call submode#map ( 'window' , 'n' , '' , 'q' , '<C-w>c' ) call submode#map ( 'window' , 'n' , '' , '<C-q>' , '<C-w>c' ) \" <lowercase-pipe> sets the width to 80 columns, pipe (<S-\\>) by default \" maximizes the width. call submode#map ( 'window' , 'n' , '' , '\\' , ':vertical resize 80<CR>' ) \" Resize faster call submode#map ( 'window' , 'n' , '' , '+' , '3<C-w>+' ) call submode#map ( 'window' , 'n' , '' , '-' , '3<C-w>-' ) call submode#map ( 'window' , 'n' , '' , '<' , '10<C-w><' ) call submode#map ( 'window' , 'n' , '' , '>' , '10<C-w>>' )","title":"Bonus Mappings"},{"location":"blog/2016/making-a-window-submode/#rainbows-without-unicorns","text":"While learning this new way of windowing, there have been a few negatives: I forget that I'm in window mode and get disoriented when I think I'm moving the cursor within a buffer, but it jumps around to other splits. For one off window commands, I have to hit an extra key to get out of window mode or wait for the timeout. When I use some one else's computer, I'm useless. I think most of these annoyances will go away with time, and the benefits overtime in keystroke savings are non-trivial. As for #3 , regardless of submodes, the brain freeze will never go away, because no one thinks as strangely as me, and that's a Good Thing\u2122.","title":"Rainbows without Unicorns"},{"location":"blog/2016/making-a-window-submode/#thanks","text":"Shout-out to Kana Natsuno, @kana1 , http://whileimautomaton.net/ , https://github.com/kana . None of this awesomeness would be possible without https://github.com/kana/vim-submode . She makes some totally sweet plug-ins. Check out her stuff. You won't regret it! Let me know what you think. Am I crazy? What other things deserve a submode? Hit me up in the comments below! Thanks for reading!","title":"Thanks"},{"location":"blog/2016/negative-modulo/","text":"PSA: Vim Modulo '%' Returns Negative Numbers! \u00b6 Surprise! Vim has the same modulo bug as Javascript. Some say it's not a bug, but if Ruby and Google Calculator is wrong, I don't want to be right. Vim, :echo -10 % 3 returns -1 Javascript -10 % 3 returns -1 Ruby/IRB, -10 % 3 returns 2 -- my expectation is here Solution \u00b6 Add this function some where in your Vimscript and throw away % . \" ((n % m) + m) % m` or `((-10 % 3) + 3) % 3` returns `2` function ! s: mod ( n , m ) return (( a : n % a : m ) + a : m ) % a : m endfunction I hope this saves someone some time somewhere out there. It's an hour I'll never get back, but happy to give back. References https://www.google.com/#q=-10+%25+3 http://vimdoc.sourceforge.net/htmldoc/eval.html#expr6 http://math.stackexchange.com/questions/519845/modulo-of-a-negative-number/519856 https://en.wikipedia.org/wiki/Modulo_operation http://stackoverflow.com/questions/4467539/javascript-modulo-not-behaving","title":"PSA: Vim Modulo '%' Returns Negative Numbers!"},{"location":"blog/2016/negative-modulo/#psa-vim-modulo-returns-negative-numbers","text":"Surprise! Vim has the same modulo bug as Javascript. Some say it's not a bug, but if Ruby and Google Calculator is wrong, I don't want to be right. Vim, :echo -10 % 3 returns -1 Javascript -10 % 3 returns -1 Ruby/IRB, -10 % 3 returns 2 -- my expectation is here","title":"PSA: Vim Modulo '%' Returns Negative Numbers!"},{"location":"blog/2016/negative-modulo/#solution","text":"Add this function some where in your Vimscript and throw away % . \" ((n % m) + m) % m` or `((-10 % 3) + 3) % 3` returns `2` function ! s: mod ( n , m ) return (( a : n % a : m ) + a : m ) % a : m endfunction I hope this saves someone some time somewhere out there. It's an hour I'll never get back, but happy to give back. References https://www.google.com/#q=-10+%25+3 http://vimdoc.sourceforge.net/htmldoc/eval.html#expr6 http://math.stackexchange.com/questions/519845/modulo-of-a-negative-number/519856 https://en.wikipedia.org/wiki/Modulo_operation http://stackoverflow.com/questions/4467539/javascript-modulo-not-behaving","title":"Solution"},{"location":"blog/2016/photography-lightening-talk/","text":"Photography Refactored \u00b6 Someone convinced me to do a lightening talk about photography. Here's the slide deck.","title":"Photography Refactored"},{"location":"blog/2016/photography-lightening-talk/#photography-refactored","text":"Someone convinced me to do a lightening talk about photography. Here's the slide deck.","title":"Photography Refactored"},{"location":"blog/2016/ruby-abuse/","text":"Ruby Abuse: How Not to Write Ruby, But Still Have Fun \u00b6 alias \u03bb lambda sadd = \u03bb { | ns , a | [* ns , a ]. sort } hsort = \u03bb { | h | Hash [ h . sort ] } hadd = \u03bb { | h , n , g | h . merge ( g => sadd . ( h [ g ] , n )) } school = \u03bb { | gs | School . new ( gs ) } School = Struct . new ( :gs ) do define_method :add , \u03bb { | n , g | ( school . ( hsort . ( hadd . ( to_hash , n , g )))) } define_method :to_hash , \u03bb { | | gs || {} } define_method :grade , \u03bb { | g | to_hash [ g ] || [] } end","title":"Ruby Abuse: How Not to Write Ruby, But Still Have Fun"},{"location":"blog/2016/ruby-abuse/#ruby-abuse-how-not-to-write-ruby-but-still-have-fun","text":"alias \u03bb lambda sadd = \u03bb { | ns , a | [* ns , a ]. sort } hsort = \u03bb { | h | Hash [ h . sort ] } hadd = \u03bb { | h , n , g | h . merge ( g => sadd . ( h [ g ] , n )) } school = \u03bb { | gs | School . new ( gs ) } School = Struct . new ( :gs ) do define_method :add , \u03bb { | n , g | ( school . ( hsort . ( hadd . ( to_hash , n , g )))) } define_method :to_hash , \u03bb { | | gs || {} } define_method :grade , \u03bb { | g | to_hash [ g ] || [] } end","title":"Ruby Abuse: How Not to Write Ruby, But Still Have Fun"},{"location":"blog/2016/side-search/","text":"Vim Side Search: Making Search Fun Again \u00b6 The quickfix feature is nice, but it doesn't give enough context around the search term that leads to use ag from terminal and switch back and forth between programs. I do this search dance every day and I've had it! There must be better way! Problem \u00b6 Look at the quickfix window above. It spends most of its space showing the file name of the hit, then the remainder is spent on text around it. In projects using Rails Engines with deeply nested directory structures, this often leaves me with just a bunch of paths in the quickfix . Solution A - The Unix Way \u00b6 Some may argue Vim isn't suppose to do search. Vim rightly delegates to the Unix philosophy by allowing an external program do its searching. Let's try that for this solution using grep , ack , and ag . We've run the 3 separate programs (normally, I would only use ag ) then browse the results to see if there's an interesting file. At this point I start using my handy-dandy mouse to scroll around, precisely highlight the path of interest, copy, and type vim <Paste> . Intuitive? Yes. Fast? No! Maybe I should use tmux or screen so I don't need to mouse around, but trying to select a path is still pretty slow for me and requires more cognitive load than I have patience for. After all, I'm trying to concentrate on a refactor or something, not how to open a bunch of files. Should I practice more? Yes. Will I? No! We're going to use ag from now on, since it's faster than ack , and has prettier output than grep . I really really really tried to get grep to output for humans, but couldn't figure it out. Solution B - Vim without Quickfix \u00b6 Let Vim do some work for us. vim `ag --ignore=\\*.{css,scss} -l help` +'/help' What's that?!? Open Vim passing the result of ag command. ag is run with some file exclusions, -l only file names, and help is the search term. +'/help' tells Vim to immediately start searching for 'help'. After all that, Vim should have started with a bunch of buffers. View them with :ls . Take notice of the buffer numbers to see how many files were found. Use n and N to jump through search matches in the file. Use :bn to go to the next buffer and start hitting n again to cycle through the changes. If the number of files is small enough, you may be able to use :ball to open every buffer in its own window. Thats a lot of work to jump through changes. Good thing the quickfix exists. Solution C - Quickfix \u00b6 This is here for posterity. quickfix DOES make cycling through changes easier than Solution B, but as I stated in the intro, it doesn't give the context that we want. Thoughtbot has a pretty good article about how to setup Vim to use ag . Once you do that, you can :grep help to get the following output: Use :cnext , :cprev , :cfirst , :clast to go to next, previous, first, and last quickfix result respectively. Map those to keys to make it easier to navigate. nnoremap [q :cprev<CR> nnoremap ]q :cnext<CR> nnoremap [Q :cfirst<CR> nnoremap ]Q :clast<CR> Get more help about quickfix using :help quickfix . Cry after realizing even :help quickfix can't show more context. I'll be here when you're done. Solution D - Side Search Plugin \u00b6 So how do we get the best of both worlds? How do we enter the land of a thousand wives/husbands? How do we get ag output and quick navigation? For me, it was writing a plugin in. For you it's using it. https://github.com/ddrscott/vim-side-search After installing the plugin using your favorite package manager, you'll have access to the following functionality: Things to notice: ag output is in a buffer with additional syntax highlighting! n and N used to jump to matches. Regular Vim navigation works, too! <CR> and <C-w><CR> used to open change and jump to change! Number of matches shown in the buffer name! I use too many exclamation points!!! The plugin's README has more details. Closing \u00b6 I've been using this plugin ever since its inception and don't know where I'd be without it. It gets some inspiration from fugitive's :Gstatus mode/buffer, and I wish there were more plugins that added functionality from stdout instead of transforming it into a different format. Unix tools makers spend a lot of time thinking about the output. Let's use it to our advantage. I've learn a lot creating this plugin and plan to write about it in a future post. Do you love it or hate it? Have more ideas for Side Search? Please let me know what you think of it. Have more ideas or issues for Side Search? Hit me up on Github . References \u00b6 The Silver Searcher by Geoff Greer man ag man grep man tmux man screen :help quickfix Faster Grepping in Vim by Thoughtbot The number 12 In The News \u00b6 Hacker News Reddit","title":"Vim Side Search: Making Search Fun Again"},{"location":"blog/2016/side-search/#vim-side-search-making-search-fun-again","text":"The quickfix feature is nice, but it doesn't give enough context around the search term that leads to use ag from terminal and switch back and forth between programs. I do this search dance every day and I've had it! There must be better way!","title":"Vim Side Search: Making Search Fun Again"},{"location":"blog/2016/side-search/#problem","text":"Look at the quickfix window above. It spends most of its space showing the file name of the hit, then the remainder is spent on text around it. In projects using Rails Engines with deeply nested directory structures, this often leaves me with just a bunch of paths in the quickfix .","title":"Problem"},{"location":"blog/2016/side-search/#solution-a-the-unix-way","text":"Some may argue Vim isn't suppose to do search. Vim rightly delegates to the Unix philosophy by allowing an external program do its searching. Let's try that for this solution using grep , ack , and ag . We've run the 3 separate programs (normally, I would only use ag ) then browse the results to see if there's an interesting file. At this point I start using my handy-dandy mouse to scroll around, precisely highlight the path of interest, copy, and type vim <Paste> . Intuitive? Yes. Fast? No! Maybe I should use tmux or screen so I don't need to mouse around, but trying to select a path is still pretty slow for me and requires more cognitive load than I have patience for. After all, I'm trying to concentrate on a refactor or something, not how to open a bunch of files. Should I practice more? Yes. Will I? No! We're going to use ag from now on, since it's faster than ack , and has prettier output than grep . I really really really tried to get grep to output for humans, but couldn't figure it out.","title":"Solution A - The Unix Way"},{"location":"blog/2016/side-search/#solution-b-vim-without-quickfix","text":"Let Vim do some work for us. vim `ag --ignore=\\*.{css,scss} -l help` +'/help' What's that?!? Open Vim passing the result of ag command. ag is run with some file exclusions, -l only file names, and help is the search term. +'/help' tells Vim to immediately start searching for 'help'. After all that, Vim should have started with a bunch of buffers. View them with :ls . Take notice of the buffer numbers to see how many files were found. Use n and N to jump through search matches in the file. Use :bn to go to the next buffer and start hitting n again to cycle through the changes. If the number of files is small enough, you may be able to use :ball to open every buffer in its own window. Thats a lot of work to jump through changes. Good thing the quickfix exists.","title":"Solution B - Vim without Quickfix"},{"location":"blog/2016/side-search/#solution-c-quickfix","text":"This is here for posterity. quickfix DOES make cycling through changes easier than Solution B, but as I stated in the intro, it doesn't give the context that we want. Thoughtbot has a pretty good article about how to setup Vim to use ag . Once you do that, you can :grep help to get the following output: Use :cnext , :cprev , :cfirst , :clast to go to next, previous, first, and last quickfix result respectively. Map those to keys to make it easier to navigate. nnoremap [q :cprev<CR> nnoremap ]q :cnext<CR> nnoremap [Q :cfirst<CR> nnoremap ]Q :clast<CR> Get more help about quickfix using :help quickfix . Cry after realizing even :help quickfix can't show more context. I'll be here when you're done.","title":"Solution C - Quickfix"},{"location":"blog/2016/side-search/#solution-d-side-search-plugin","text":"So how do we get the best of both worlds? How do we enter the land of a thousand wives/husbands? How do we get ag output and quick navigation? For me, it was writing a plugin in. For you it's using it. https://github.com/ddrscott/vim-side-search After installing the plugin using your favorite package manager, you'll have access to the following functionality: Things to notice: ag output is in a buffer with additional syntax highlighting! n and N used to jump to matches. Regular Vim navigation works, too! <CR> and <C-w><CR> used to open change and jump to change! Number of matches shown in the buffer name! I use too many exclamation points!!! The plugin's README has more details.","title":"Solution D - Side Search Plugin"},{"location":"blog/2016/side-search/#closing","text":"I've been using this plugin ever since its inception and don't know where I'd be without it. It gets some inspiration from fugitive's :Gstatus mode/buffer, and I wish there were more plugins that added functionality from stdout instead of transforming it into a different format. Unix tools makers spend a lot of time thinking about the output. Let's use it to our advantage. I've learn a lot creating this plugin and plan to write about it in a future post. Do you love it or hate it? Have more ideas for Side Search? Please let me know what you think of it. Have more ideas or issues for Side Search? Hit me up on Github .","title":"Closing"},{"location":"blog/2016/side-search/#references","text":"The Silver Searcher by Geoff Greer man ag man grep man tmux man screen :help quickfix Faster Grepping in Vim by Thoughtbot The number 12","title":"References"},{"location":"blog/2016/side-search/#in-the-news","text":"Hacker News Reddit","title":"In The News"},{"location":"blog/2016/sidescroll/","text":"Sensible Horizontal Scroll in Vim \u00b6 Sometimes it's the little things that make a big difference, and this is about as small as it can get. Occasionally, I hold down l , w , or e to view long lines which have disappeared off the window. It's a bad habit and the penalty always ruins my concentration. But after I found this setting, I'm free to cursor around like an innocent child unaware of death. TL;DR -- set sidescroll=1 Problem \u00b6 When set wrap is off, otherwise known as set nowrap , and a line is longer than the window can handle, you'll need to scroll to see more of the line. {x}zl and {x}zh will scroll the screen right and left respectively. That's a lot to remember to see some more text. Which leads me to hold down w or e to get it done followed by janky behavior when the cursor gets to the edge of the window. The default behavior of revealing more text is \u00bd a window width at a time. This abrupt jump throws off my fragile concentration. Solution A \u00b6 Turn on word wrapping. set wrap . Boring, but effective. You might also want to make word wrapping look nicer. I do that with the following settings. set breakindent set breakindentopt = sbr \" I use a unicode curly array with a <backslash><space> set showbreak = \u21aa > \\ This of course doesn't solve the problem if, in fact, we want wrapping off. Solution B \u00b6 set sidescroll = 1 This simple setting makes Vim behave like every other plain editor. It will incrementally scroll one character at a time to reveal more text as needed. Here's the help doc to clear things up: 'sidescroll' 'ss' number (default 0) global The minimal number of columns to scroll horizontally. Used only when the 'wrap' option is off and the cursor is moved off of the screen. When it is zero the cursor will be put in the middle of the screen. When using a slow terminal set it to a large number or 0. When using a fast terminal use a small number or 1. Not used for \"zh\" and \"zl\" commands. 'sidescrolloff' 'siso' number (default 0) global The minimal number of screen columns to keep to the left and to the right of the cursor if 'nowrap' is set. Setting this option to a value greater than 0 while having |'sidescroll'| also at a non-zero value makes some context visible in the line you are scrolling in horizontally (except at beginning of the line). Setting this option to a large value (like 999) has the effect of keeping the cursor horizontally centered in the window, as long as one does not come too close to the beginning of the line. Example: Try this together with 'sidescroll' and 'listchars' as in the following example to never allow the cursor to move onto the \"extends\" character: :set nowrap sidescroll=1 listchars=extends:>,precedes:< :set sidescrolloff=1 Seems like the default was intended for a \"slow terminal\". If you're using a slow terminal while editing a large amount of unwrapped text, I'd recommend getting a computer from this millennia and enabling sidescroll . Also note that a sensible example is shown in the sidescrolloff section. Off Topic... \u00b6 It's interesting to study all the decisions made due to slow terminals. Try :help slow-terminal for a quick look and try :helpgrep slow to see way more mentions. Use :help helpgrep if you didn't know about helpgrep :) Closing \u00b6 I'm sure you're thinking why so many words were written for a single setting. Similar to my previous post about Yank without Jank , these unexpected janky behaviors cause anxiety. Anxiety that usually can't be identified or resolved in the heat of a coding session, but is there, wading in the weeds, ready to pounce at your next stray keystroke. As a student of Vim, I want identify and resolve these issues so I can get back to why I like Vim; using the dot operator.","title":"Sensible Horizontal Scroll in Vim"},{"location":"blog/2016/sidescroll/#sensible-horizontal-scroll-in-vim","text":"Sometimes it's the little things that make a big difference, and this is about as small as it can get. Occasionally, I hold down l , w , or e to view long lines which have disappeared off the window. It's a bad habit and the penalty always ruins my concentration. But after I found this setting, I'm free to cursor around like an innocent child unaware of death. TL;DR -- set sidescroll=1","title":"Sensible Horizontal Scroll in Vim"},{"location":"blog/2016/sidescroll/#problem","text":"When set wrap is off, otherwise known as set nowrap , and a line is longer than the window can handle, you'll need to scroll to see more of the line. {x}zl and {x}zh will scroll the screen right and left respectively. That's a lot to remember to see some more text. Which leads me to hold down w or e to get it done followed by janky behavior when the cursor gets to the edge of the window. The default behavior of revealing more text is \u00bd a window width at a time. This abrupt jump throws off my fragile concentration.","title":"Problem"},{"location":"blog/2016/sidescroll/#solution-a","text":"Turn on word wrapping. set wrap . Boring, but effective. You might also want to make word wrapping look nicer. I do that with the following settings. set breakindent set breakindentopt = sbr \" I use a unicode curly array with a <backslash><space> set showbreak = \u21aa > \\ This of course doesn't solve the problem if, in fact, we want wrapping off.","title":"Solution A"},{"location":"blog/2016/sidescroll/#solution-b","text":"set sidescroll = 1 This simple setting makes Vim behave like every other plain editor. It will incrementally scroll one character at a time to reveal more text as needed. Here's the help doc to clear things up: 'sidescroll' 'ss' number (default 0) global The minimal number of columns to scroll horizontally. Used only when the 'wrap' option is off and the cursor is moved off of the screen. When it is zero the cursor will be put in the middle of the screen. When using a slow terminal set it to a large number or 0. When using a fast terminal use a small number or 1. Not used for \"zh\" and \"zl\" commands. 'sidescrolloff' 'siso' number (default 0) global The minimal number of screen columns to keep to the left and to the right of the cursor if 'nowrap' is set. Setting this option to a value greater than 0 while having |'sidescroll'| also at a non-zero value makes some context visible in the line you are scrolling in horizontally (except at beginning of the line). Setting this option to a large value (like 999) has the effect of keeping the cursor horizontally centered in the window, as long as one does not come too close to the beginning of the line. Example: Try this together with 'sidescroll' and 'listchars' as in the following example to never allow the cursor to move onto the \"extends\" character: :set nowrap sidescroll=1 listchars=extends:>,precedes:< :set sidescrolloff=1 Seems like the default was intended for a \"slow terminal\". If you're using a slow terminal while editing a large amount of unwrapped text, I'd recommend getting a computer from this millennia and enabling sidescroll . Also note that a sensible example is shown in the sidescrolloff section.","title":"Solution B"},{"location":"blog/2016/sidescroll/#off-topic","text":"It's interesting to study all the decisions made due to slow terminals. Try :help slow-terminal for a quick look and try :helpgrep slow to see way more mentions. Use :help helpgrep if you didn't know about helpgrep :)","title":"Off Topic..."},{"location":"blog/2016/sidescroll/#closing","text":"I'm sure you're thinking why so many words were written for a single setting. Similar to my previous post about Yank without Jank , these unexpected janky behaviors cause anxiety. Anxiety that usually can't be identified or resolved in the heat of a coding session, but is there, wading in the weeds, ready to pounce at your next stray keystroke. As a student of Vim, I want identify and resolve these issues so I can get back to why I like Vim; using the dot operator.","title":"Closing"},{"location":"blog/2016/vim-toggle-movement/","text":"Vim Toggle Movement: I Just Want to Go Home \u00b6 I have a problem with the ^ key. I need its functionality, but its proximity is too far for either of my stubby index fingers. No vimrc change can physically move it closer to me, but I have found a way to move its funtionality to another a key. A key which already knows how to go home. An alternate home. A home where my heart isn't. Enough drama, what's the problem?!? The Problem \u00b6 In my daily coding, I have a deep seeded need to go to the first non-blank character of a line. The only key that Vim provides for that functionality is ^ , the hardest key to reach from the home row. A much more comfortable key to reach is 0 , but that shoots us past the first non-blank character all the way to the left edge of the window. <Home> is the ugly step child of either option since it's even harder to reach and takes us to the first column, too. In case you don't believe me. Here's what the Vim document says: 0 To the first character of the line. |exclusive| motion. *<Home>* *<kHome>* <Home> To the first character of the line. |exclusive| motion. When moving up or down next, stay in same TEXT column (if possible). Most other commands stay in the same SCREEN column. <Home> works like \"1|\", which differs from \"0\" when the line starts with a <Tab>. *^* ^ To the first non-blank character of the line. |exclusive| motion. Why can't I have a key that is easy to reach and takes me to the first non-blank?!? I could swap the functionality of 0 and ^ : nnoremap 0 ^ nnoremap ^ 0 This still forces me to reach for ^ when I need to need to get to that left edge. There must be a better way! The Solution \u00b6 Let's give 0 some super toggling powers. When I hit it the first time, I want it be be like ^ . If I hit it again, I want it to finish its travels and go to the first column. Solution A \u00b6 function ! ToggleHomeZero () let pos = getpos ( '.' ) execute \"normal! ^\" if pos == getpos ( '.' ) execute \"normal! 0\" endif endfunction nnoremap 0 : call ToggleHome ()< CR > This gets us exactly to the center of Venn diagrams heart: Easy to reach + First non-blank character + First column = Rainbow Colored Unicorn! Solution B \u00b6 After enjoying staring at the function for a while, I realized we could add super toggling powers to other movements. Lets extract the normal commands into arguments and share the love with other keys! function ! ToggleMovement ( firstOp , thenOp ) let pos = getpos ( '.' ) execute \"normal! \" . a :firstOp if pos == getpos ( '.' ) execute \"normal! \" . a :thenOp endif endfunction \" The original carat 0 swap nnoremap < silent > 0 : call ToggleMovement ( '^' , '0' )< CR > \" How about ; and , nnoremap < silent > ; : call ToggleMovement ( ';' , ',' )< CR > nnoremap < silent > , : call ToggleMovement ( ',' , ';' )< CR > \" How about H and L nnoremap < silent > H : call ToggleMovement ( 'H' , 'L' )< CR > nnoremap < silent > L : call ToggleMovement ( 'L' , 'H' )< CR > \" How about G and gg nnoremap < silent > G : call ToggleMovement ( 'G' , 'gg' )< CR > nnoremap < silent > gg : call ToggleMovement ( 'gg' , 'G' )< CR > Conclusion \u00b6 ToggleMovement is the gift that keeps on giving! What other movement can we add to the list? Let me know in the comments below.","title":"Vim Toggle Movement: I Just Want to Go Home"},{"location":"blog/2016/vim-toggle-movement/#vim-toggle-movement-i-just-want-to-go-home","text":"I have a problem with the ^ key. I need its functionality, but its proximity is too far for either of my stubby index fingers. No vimrc change can physically move it closer to me, but I have found a way to move its funtionality to another a key. A key which already knows how to go home. An alternate home. A home where my heart isn't. Enough drama, what's the problem?!?","title":"Vim Toggle Movement: I Just Want to Go Home"},{"location":"blog/2016/vim-toggle-movement/#the-problem","text":"In my daily coding, I have a deep seeded need to go to the first non-blank character of a line. The only key that Vim provides for that functionality is ^ , the hardest key to reach from the home row. A much more comfortable key to reach is 0 , but that shoots us past the first non-blank character all the way to the left edge of the window. <Home> is the ugly step child of either option since it's even harder to reach and takes us to the first column, too. In case you don't believe me. Here's what the Vim document says: 0 To the first character of the line. |exclusive| motion. *<Home>* *<kHome>* <Home> To the first character of the line. |exclusive| motion. When moving up or down next, stay in same TEXT column (if possible). Most other commands stay in the same SCREEN column. <Home> works like \"1|\", which differs from \"0\" when the line starts with a <Tab>. *^* ^ To the first non-blank character of the line. |exclusive| motion. Why can't I have a key that is easy to reach and takes me to the first non-blank?!? I could swap the functionality of 0 and ^ : nnoremap 0 ^ nnoremap ^ 0 This still forces me to reach for ^ when I need to need to get to that left edge. There must be a better way!","title":"The Problem"},{"location":"blog/2016/vim-toggle-movement/#the-solution","text":"Let's give 0 some super toggling powers. When I hit it the first time, I want it be be like ^ . If I hit it again, I want it to finish its travels and go to the first column.","title":"The Solution"},{"location":"blog/2016/vim-toggle-movement/#solution-a","text":"function ! ToggleHomeZero () let pos = getpos ( '.' ) execute \"normal! ^\" if pos == getpos ( '.' ) execute \"normal! 0\" endif endfunction nnoremap 0 : call ToggleHome ()< CR > This gets us exactly to the center of Venn diagrams heart: Easy to reach + First non-blank character + First column = Rainbow Colored Unicorn!","title":"Solution A"},{"location":"blog/2016/vim-toggle-movement/#solution-b","text":"After enjoying staring at the function for a while, I realized we could add super toggling powers to other movements. Lets extract the normal commands into arguments and share the love with other keys! function ! ToggleMovement ( firstOp , thenOp ) let pos = getpos ( '.' ) execute \"normal! \" . a :firstOp if pos == getpos ( '.' ) execute \"normal! \" . a :thenOp endif endfunction \" The original carat 0 swap nnoremap < silent > 0 : call ToggleMovement ( '^' , '0' )< CR > \" How about ; and , nnoremap < silent > ; : call ToggleMovement ( ';' , ',' )< CR > nnoremap < silent > , : call ToggleMovement ( ',' , ';' )< CR > \" How about H and L nnoremap < silent > H : call ToggleMovement ( 'H' , 'L' )< CR > nnoremap < silent > L : call ToggleMovement ( 'L' , 'H' )< CR > \" How about G and gg nnoremap < silent > G : call ToggleMovement ( 'G' , 'gg' )< CR > nnoremap < silent > gg : call ToggleMovement ( 'gg' , 'G' )< CR >","title":"Solution B"},{"location":"blog/2016/vim-toggle-movement/#conclusion","text":"ToggleMovement is the gift that keeps on giving! What other movement can we add to the list? Let me know in the comments below.","title":"Conclusion"},{"location":"blog/2016/yank-without-jank/","text":"Yank Without Jank \u00b6 For all the great things Vim has to offer, it still has some inconsistencies with basic editors that I simply can't unlearn. One of these nasties is moving the cursor after a visual yank. Go ahead, try it: vipy . Where's your cursor? Where did you expect it to be located? When you're in a boring editor and do shift-down-down-down <Cmd-c> , where's your cursor? Where did you expect it to be located? This janky behaviour always throws me off for a moment, then I compose myself, do a <backtick><greaterthan> to jump to the end of my selection, and p . There must be a better way! Solution A \u00b6 Rebind y to do exactly what we did above: vnoremap y y ` > This work and I lived with it for a few minutes, but it still wasn't perfect. I noticed when I do line select using capital V the cursor would still move. The vertical motion was perfect, but horizontal motion was still jarring. Solution B \u00b6 Let's try using marks to keep things in place: vnoremap y myy` y vnoremap Y myY` y The capital Y mapping is just in case we want to do a line wise yank from a character wise selection. Like a well trained dog, the cursor stays even though you yank it. BONUS This snippet also takes over the y marker, so you can manually <backtick>y at a later time to continue yanking where you left off. This is great when you're moving a lot of stuff around and want pick up where you last were. You can also change the mark to capitals in the binding so it spans buffers, too. Closing \u00b6 I've been using this setting for a while and noticed my blood pressure is way down. No more yank anxiety means I'm a step closer to editing utopia! Let me know how this goes for you in the comments below. Updates from Comments \u00b6 Commenter @Krzysztof noticed Solution B wasn't allowing the user to specify the target register. He was awesome enough to update the solution. Here's his solution: vnoremap < expr > y \"my\\\"\" . v : register . \"y`y\" I've updated $MYVIMRC and it works great. Thanks @Krzysztof for being awesome!","title":"Yank Without Jank"},{"location":"blog/2016/yank-without-jank/#yank-without-jank","text":"For all the great things Vim has to offer, it still has some inconsistencies with basic editors that I simply can't unlearn. One of these nasties is moving the cursor after a visual yank. Go ahead, try it: vipy . Where's your cursor? Where did you expect it to be located? When you're in a boring editor and do shift-down-down-down <Cmd-c> , where's your cursor? Where did you expect it to be located? This janky behaviour always throws me off for a moment, then I compose myself, do a <backtick><greaterthan> to jump to the end of my selection, and p . There must be a better way!","title":"Yank Without Jank"},{"location":"blog/2016/yank-without-jank/#solution-a","text":"Rebind y to do exactly what we did above: vnoremap y y ` > This work and I lived with it for a few minutes, but it still wasn't perfect. I noticed when I do line select using capital V the cursor would still move. The vertical motion was perfect, but horizontal motion was still jarring.","title":"Solution A"},{"location":"blog/2016/yank-without-jank/#solution-b","text":"Let's try using marks to keep things in place: vnoremap y myy` y vnoremap Y myY` y The capital Y mapping is just in case we want to do a line wise yank from a character wise selection. Like a well trained dog, the cursor stays even though you yank it. BONUS This snippet also takes over the y marker, so you can manually <backtick>y at a later time to continue yanking where you left off. This is great when you're moving a lot of stuff around and want pick up where you last were. You can also change the mark to capitals in the binding so it spans buffers, too.","title":"Solution B"},{"location":"blog/2016/yank-without-jank/#closing","text":"I've been using this setting for a while and noticed my blood pressure is way down. No more yank anxiety means I'm a step closer to editing utopia! Let me know how this goes for you in the comments below.","title":"Closing"},{"location":"blog/2016/yank-without-jank/#updates-from-comments","text":"Commenter @Krzysztof noticed Solution B wasn't allowing the user to specify the target register. He was awesome enough to update the solution. Here's his solution: vnoremap < expr > y \"my\\\"\" . v : register . \"y`y\" I've updated $MYVIMRC and it works great. Thanks @Krzysztof for being awesome!","title":"Updates from Comments"},{"location":"blog/2017/base16-shell/","text":"Base16 Shell \u00b6 After many years using the excellent Solarized color scheme, it has started to feel stale. Sometimes I think the dark blueish tint brings down my mood. Other times, I wonder what life could be like if I stared at more cheerful colors. Thus starts my farewell from Solarized, and hello to Base16. From Base16's Github README : Base16 provides carefully chosen syntax highlighting and a default set of sixteen colors suitable for a wide range of applications. Base16 is not a single theme but a set of guidelines with numerous implementations. Which means after integrating into Base16 once, I'll have access to an unlimited supply of themes in the future! Installation \u00b6 Base16 has perfect iTerm and shell integration. Once the repo was installed locally, I called base16_ocean and was greeted by brand new palette. No iTerm tweaking, no downloading this other thing and importing stuff into iTerm. It was literally 2 steps performed in shell and then pick a theme. Here's what you do. (FYI. This is pretty much copy/paste from their repo) # 1. clone the repo to `~/.config/base16-shell` git clone https://github.com/chriskempson/base16-shell.git ~/.config/base16-shell # 2. update ~/.bashrc or ~/.zshrc cat >> ~/.zshrc <<'SH' BASE16_SH ELL = $HOME /.config/base16-shell/ [ -n \" $PS1 \" ] && [ -s $BASE16_SHELL /profile_helper.sh ] && eval \" $( $BASE16_SHELL /profile_helper.sh ) \" SH After you're done with those steps, start a new terminal session or source the file, and start choosing a theme. Try base16_ocean to see what I'm seeing. Try base16_<tab> to see what other options you have available. To preview what they look like before making a choice go to their website: https://chriskempson.github.io/base16/ . Vim Integration \u00b6 Install plugin from https://github.com/chriskempson/base16-vim . Add the following to your .vimrc : if filereadable ( expand ( \"~/.vimrc_background\" )) let base16colorspace = 256 source ~ /.vimrc_background endif base16-shell commands create the ~/.vimrc_background file every time a base16_* alias is used. This allows Vim to always stay synchronized with shell which is AWESOME! Conclusion \u00b6 After cycling through everyone of the user created themes, I've settled on base16_ocean as my new home. I may get tired of it, I may not, but either way I'm just a shell command away from changing. Indecision has never been so easy.","title":"Base16 Shell"},{"location":"blog/2017/base16-shell/#base16-shell","text":"After many years using the excellent Solarized color scheme, it has started to feel stale. Sometimes I think the dark blueish tint brings down my mood. Other times, I wonder what life could be like if I stared at more cheerful colors. Thus starts my farewell from Solarized, and hello to Base16. From Base16's Github README : Base16 provides carefully chosen syntax highlighting and a default set of sixteen colors suitable for a wide range of applications. Base16 is not a single theme but a set of guidelines with numerous implementations. Which means after integrating into Base16 once, I'll have access to an unlimited supply of themes in the future!","title":"Base16 Shell"},{"location":"blog/2017/base16-shell/#installation","text":"Base16 has perfect iTerm and shell integration. Once the repo was installed locally, I called base16_ocean and was greeted by brand new palette. No iTerm tweaking, no downloading this other thing and importing stuff into iTerm. It was literally 2 steps performed in shell and then pick a theme. Here's what you do. (FYI. This is pretty much copy/paste from their repo) # 1. clone the repo to `~/.config/base16-shell` git clone https://github.com/chriskempson/base16-shell.git ~/.config/base16-shell # 2. update ~/.bashrc or ~/.zshrc cat >> ~/.zshrc <<'SH' BASE16_SH ELL = $HOME /.config/base16-shell/ [ -n \" $PS1 \" ] && [ -s $BASE16_SHELL /profile_helper.sh ] && eval \" $( $BASE16_SHELL /profile_helper.sh ) \" SH After you're done with those steps, start a new terminal session or source the file, and start choosing a theme. Try base16_ocean to see what I'm seeing. Try base16_<tab> to see what other options you have available. To preview what they look like before making a choice go to their website: https://chriskempson.github.io/base16/ .","title":"Installation"},{"location":"blog/2017/base16-shell/#vim-integration","text":"Install plugin from https://github.com/chriskempson/base16-vim . Add the following to your .vimrc : if filereadable ( expand ( \"~/.vimrc_background\" )) let base16colorspace = 256 source ~ /.vimrc_background endif base16-shell commands create the ~/.vimrc_background file every time a base16_* alias is used. This allows Vim to always stay synchronized with shell which is AWESOME!","title":"Vim Integration"},{"location":"blog/2017/base16-shell/#conclusion","text":"After cycling through everyone of the user created themes, I've settled on base16_ocean as my new home. I may get tired of it, I may not, but either way I'm just a shell command away from changing. Indecision has never been so easy.","title":"Conclusion"},{"location":"blog/2017/fzf-dictionary/","text":"FZF + WordNet = Dictionary \u00b6 FZF + WordNet = Dictionary . FZF is a fuzzy finding command line tool. WordNet is a dictionary structured for developers. When married together, we can get a snappy dictionary to help us find just the right word for any occasion. Install Required Program \u00b6 Before making our new shell function, lets install the required programs. https://github.com/junegunn/fzf http://wordnetweb.princeton.edu/perl/webwn These directions are for Max OSX with homebrew installed. If you're on a different system, read the docs from the sites above to get the programs for your operating system. brew install fzf brew cask install xquartz brew install wordnet FZF \u00b6 FZF stands for Fuzzy Finder. It is a program which enables the user to filter a set of lines from standard in and feed those line back to standard out. A basic example is: find . | fzf . This presents a list of all files in the current working directory and prompts the user for input. As you type letters, the list will narrow, keeping only the items matching the search criteria. After selecting an entry from the list the line or lines chosen is printed to standard out. It provides a nifty argument --preview which can execute a program and display its output as an aside in the terminal. We'll write more about FZF in the future. WordNet \u00b6 WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. The resulting network of meaningfully related words and concepts can be navigated with the browser. WordNet is also freely and publicly available for download. WordNet's structure makes it a useful tool for computational linguistics and natural language processing. WordNet superficially resembles a thesaurus, in that it groups words together based on their meanings. However, there are some important distinctions. First, WordNet interlinks not just word forms\u2014strings of letters\u2014but specific senses of words. As a result, words that are found in close proximity to one another in the network are semantically disambiguated. Second, WordNet labels the semantic relations among words, whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity. Using WordNet we can find information similar to what is in a dictionary and thesaurus combined. Example output of looking up happy is: % wn happy -over Overview of adj happy The adj happy has 4 senses (first 2 from tagged texts) 1. (37) happy -- (enjoying or showing or marked by joy or pleasure; \"a happy smile\"; \"spent many happy days on the beach\"; \"a happy marriage\") 2. (2) felicitous, happy -- (marked by good fortune; \"a felicitous life\"; \"a happy outcome\") 3. glad, happy -- (eagerly disposed to act or to be of service; \"glad to help\") 4. happy, well-chosen -- (well expressed and to the point; \"a happy turn of phrase\"; \"a few well-chosen words\") xquartz is needed since the WordNet package also works in GUI mode. The GUI app has a useful interface and could be more intuitive to use if you don't mind clicking around. The GUI app can be started with wnb , but we're not here for GUI stuff. Let's move on to making our terminal script. Shell Script \u00b6 The following 3 functions can be used individually and are helpful all on their own. Add these directly into your shell profile or in a separate file and source it from the profile. fold is normally a built in command. By default it adds newlines when text overflows the terminal, but it doesn't do it in an easy to read fashion. The default behavior can break in the middle of a word and assumes a terminal width of 80 columns. Our fold function breaks at spaces and passes the whole terminal width to it when no other arguments are provided. # Default `fold` to screen width and break at spaces function fold { if [ $# -eq 0 ] ; then /usr/bin/fold -w $COLUMNS -s else /usr/bin/fold $* fi } spell is the FZF portion of our script. This fuzzy matches the built in Mac dictionary with a preview window containing the WordNet overview of the selected word. # Use `fzf` against system dictionary function spell { cat /usr/share/dict/words | fzf --preview 'wn {} -over | fold' --preview-window = up:60% } The dic script uses spell to help find a word then outputs WordNet's definition. # Lookup definition of word using `wn $1 -over`. # If $1 is not provided, we'll use the `spell` command to pick a word. # # Requires: # brew install wordnet # brew install fzf function dic { if [ $# -eq 0 ] ; then wn ` spell ` -over | fold else wn $1 -over | fold fi } Here's another demo of the dic function: Conclusion \u00b6 Gluing programs together with fzf --preview is fun. Let us know what other recipes you come up with in the comments below.","title":"FZF + WordNet = Dictionary"},{"location":"blog/2017/fzf-dictionary/#fzf-wordnet-dictionary","text":"FZF + WordNet = Dictionary . FZF is a fuzzy finding command line tool. WordNet is a dictionary structured for developers. When married together, we can get a snappy dictionary to help us find just the right word for any occasion.","title":"FZF + WordNet = Dictionary"},{"location":"blog/2017/fzf-dictionary/#install-required-program","text":"Before making our new shell function, lets install the required programs. https://github.com/junegunn/fzf http://wordnetweb.princeton.edu/perl/webwn These directions are for Max OSX with homebrew installed. If you're on a different system, read the docs from the sites above to get the programs for your operating system. brew install fzf brew cask install xquartz brew install wordnet","title":"Install Required Program"},{"location":"blog/2017/fzf-dictionary/#fzf","text":"FZF stands for Fuzzy Finder. It is a program which enables the user to filter a set of lines from standard in and feed those line back to standard out. A basic example is: find . | fzf . This presents a list of all files in the current working directory and prompts the user for input. As you type letters, the list will narrow, keeping only the items matching the search criteria. After selecting an entry from the list the line or lines chosen is printed to standard out. It provides a nifty argument --preview which can execute a program and display its output as an aside in the terminal. We'll write more about FZF in the future.","title":"FZF"},{"location":"blog/2017/fzf-dictionary/#wordnet","text":"WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. The resulting network of meaningfully related words and concepts can be navigated with the browser. WordNet is also freely and publicly available for download. WordNet's structure makes it a useful tool for computational linguistics and natural language processing. WordNet superficially resembles a thesaurus, in that it groups words together based on their meanings. However, there are some important distinctions. First, WordNet interlinks not just word forms\u2014strings of letters\u2014but specific senses of words. As a result, words that are found in close proximity to one another in the network are semantically disambiguated. Second, WordNet labels the semantic relations among words, whereas the groupings of words in a thesaurus does not follow any explicit pattern other than meaning similarity. Using WordNet we can find information similar to what is in a dictionary and thesaurus combined. Example output of looking up happy is: % wn happy -over Overview of adj happy The adj happy has 4 senses (first 2 from tagged texts) 1. (37) happy -- (enjoying or showing or marked by joy or pleasure; \"a happy smile\"; \"spent many happy days on the beach\"; \"a happy marriage\") 2. (2) felicitous, happy -- (marked by good fortune; \"a felicitous life\"; \"a happy outcome\") 3. glad, happy -- (eagerly disposed to act or to be of service; \"glad to help\") 4. happy, well-chosen -- (well expressed and to the point; \"a happy turn of phrase\"; \"a few well-chosen words\") xquartz is needed since the WordNet package also works in GUI mode. The GUI app has a useful interface and could be more intuitive to use if you don't mind clicking around. The GUI app can be started with wnb , but we're not here for GUI stuff. Let's move on to making our terminal script.","title":"WordNet"},{"location":"blog/2017/fzf-dictionary/#shell-script","text":"The following 3 functions can be used individually and are helpful all on their own. Add these directly into your shell profile or in a separate file and source it from the profile. fold is normally a built in command. By default it adds newlines when text overflows the terminal, but it doesn't do it in an easy to read fashion. The default behavior can break in the middle of a word and assumes a terminal width of 80 columns. Our fold function breaks at spaces and passes the whole terminal width to it when no other arguments are provided. # Default `fold` to screen width and break at spaces function fold { if [ $# -eq 0 ] ; then /usr/bin/fold -w $COLUMNS -s else /usr/bin/fold $* fi } spell is the FZF portion of our script. This fuzzy matches the built in Mac dictionary with a preview window containing the WordNet overview of the selected word. # Use `fzf` against system dictionary function spell { cat /usr/share/dict/words | fzf --preview 'wn {} -over | fold' --preview-window = up:60% } The dic script uses spell to help find a word then outputs WordNet's definition. # Lookup definition of word using `wn $1 -over`. # If $1 is not provided, we'll use the `spell` command to pick a word. # # Requires: # brew install wordnet # brew install fzf function dic { if [ $# -eq 0 ] ; then wn ` spell ` -over | fold else wn $1 -over | fold fi } Here's another demo of the dic function:","title":"Shell Script"},{"location":"blog/2017/fzf-dictionary/#conclusion","text":"Gluing programs together with fzf --preview is fun. Let us know what other recipes you come up with in the comments below.","title":"Conclusion"},{"location":"blog/2017/gnu-screen/","text":"GNU Screen \u00b6 Screen is a full-screen window manager that multiplexes a physical terminal between several processes, typically interactive shells. TL;DR - Screen keeps your ssh sessions alive on a host. Installation \u00b6 Most servers have screen installed already. If they don't it can be installed via apt-get install screen , yum install screen , brew install screen . Sorry Windows, try Remote Desktop. Startup \u00b6 Get a terminal on a remote host (or local) then run screen screen If you're not brave, try man screen to read more about. Once screen has started, you'll want to remember <C-a>? . That is how you get the screen options menu. It's typed literal hold CTRL and press a . To quit the screen app, type exit . To keep screen running, type <C-a>d to detach from the program. To reattach to that session try screen -x . Options \u00b6 There are tons of options and they're best found by reading the man page or Googling gnu screen shortcuts . Here's some of my favorites. Startup Flags \u00b6 screen -DDR . Force others of the current session and reattach yourself. screen -x . Reattach yourself, but allow others to stay in. This is cooperative mode. Good for pairing and much faster than GUI screen sharing. Control Keys \u00b6 <C-a><C-c> . Create a \"tab\" to have multiple sessions. <C-a><C-a> . Toggle to previous session. <C-a><Space> . Switch next session. <C-a>a . Send a literal <C-a> back to shell. Config File and Pretty Colors \u00b6 It's easy to get lost in screen without a status line. So creating this file in your home directory will help. ~/.screenrc hardstatus alwayslastline hardstatus string '%{= kG}[ %{G}%H %{g}][%= %{= kw}%?%-Lw%?%{r}(%{W}%n*%f%t%?(%u)%?%{r})%{w}%?%+Lw%?%?%= %{g}][%{B} %m-%d %{W}%c %{g}]' This should give you a pretty statusline at the bottom of your terminal. Here's what it looks like: TMUX \u00b6 A strong competitor to screen is tmux . It has a more modern code base and is actively maintained. The reason I personally don't use it is out of habit and it's not installed everywhere. screen just works for my work flow. References \u00b6 https://www.gnu.org/software/screen/ http://www.pixelbeat.org/lkdb/screen.html http://aperiodic.net/screen/quick_reference","title":"GNU Screen"},{"location":"blog/2017/gnu-screen/#gnu-screen","text":"Screen is a full-screen window manager that multiplexes a physical terminal between several processes, typically interactive shells. TL;DR - Screen keeps your ssh sessions alive on a host.","title":"GNU Screen"},{"location":"blog/2017/gnu-screen/#installation","text":"Most servers have screen installed already. If they don't it can be installed via apt-get install screen , yum install screen , brew install screen . Sorry Windows, try Remote Desktop.","title":"Installation"},{"location":"blog/2017/gnu-screen/#startup","text":"Get a terminal on a remote host (or local) then run screen screen If you're not brave, try man screen to read more about. Once screen has started, you'll want to remember <C-a>? . That is how you get the screen options menu. It's typed literal hold CTRL and press a . To quit the screen app, type exit . To keep screen running, type <C-a>d to detach from the program. To reattach to that session try screen -x .","title":"Startup"},{"location":"blog/2017/gnu-screen/#options","text":"There are tons of options and they're best found by reading the man page or Googling gnu screen shortcuts . Here's some of my favorites.","title":"Options"},{"location":"blog/2017/gnu-screen/#startup-flags","text":"screen -DDR . Force others of the current session and reattach yourself. screen -x . Reattach yourself, but allow others to stay in. This is cooperative mode. Good for pairing and much faster than GUI screen sharing.","title":"Startup Flags"},{"location":"blog/2017/gnu-screen/#control-keys","text":"<C-a><C-c> . Create a \"tab\" to have multiple sessions. <C-a><C-a> . Toggle to previous session. <C-a><Space> . Switch next session. <C-a>a . Send a literal <C-a> back to shell.","title":"Control Keys"},{"location":"blog/2017/gnu-screen/#config-file-and-pretty-colors","text":"It's easy to get lost in screen without a status line. So creating this file in your home directory will help. ~/.screenrc hardstatus alwayslastline hardstatus string '%{= kG}[ %{G}%H %{g}][%= %{= kw}%?%-Lw%?%{r}(%{W}%n*%f%t%?(%u)%?%{r})%{w}%?%+Lw%?%?%= %{g}][%{B} %m-%d %{W}%c %{g}]' This should give you a pretty statusline at the bottom of your terminal. Here's what it looks like:","title":"Config File and Pretty Colors"},{"location":"blog/2017/gnu-screen/#tmux","text":"A strong competitor to screen is tmux . It has a more modern code base and is actively maintained. The reason I personally don't use it is out of habit and it's not installed everywhere. screen just works for my work flow.","title":"TMUX"},{"location":"blog/2017/gnu-screen/#references","text":"https://www.gnu.org/software/screen/ http://www.pixelbeat.org/lkdb/screen.html http://aperiodic.net/screen/quick_reference","title":"References"},{"location":"blog/2017/how-to-get-better-at-anything/","text":"How to Get Better At Anything \u00b6 RTFM \u00b6 WTFM, Write The Flip'n Manual Do a lightning talk about it :) Make it Fun \u00b6 Gamification Trophy anyone? If it can't be made fun, make it fun. Practice \u00b6 Slowly with intent Pressure cycles: none, some, actual, intolerable. The practice of practice deserves its own talk. Better not good \u00b6 Good is the killer of better. People tend to stop because good is unreachable. People tend to stop after they're good enough. If we aim to get better, we'll eventually be better than good. Progressive goals. OMG! I forgot goal setting! Learn, don't Memorize \u00b6 Learning is understanding Understanding is connecting the new thing to an old thing. Computers memorize. You're not a computer. Learn with others \u00b6 With the Internet you're never alone and always alone. Actually talk with people! Cheat \u00b6 If you're not cheating, you're not trying. Reverse engineer the cheat, don't actually cheat! How I got better at Vim \u00b6 RTFM - :help WTFM - Blogging, figure out other people's problems :/ Practice - Wrote stuff that wasn't needed immediately, my own notes. Don't Memorize - Vim has grammar like English. Oooh... Reconnection! Learn with Others - We have vim users, teach them (but don't let them know you're only one step ahead) Cheat - Look at other's Vimscript to figure out that cool thing they did. What do you want to get better at next?!? \u00b6 lightning talks? Shuffling cards? ( @devin ) SQL? Drawing? Piano?","title":"How to Get Better At Anything"},{"location":"blog/2017/how-to-get-better-at-anything/#how-to-get-better-at-anything","text":"","title":"How to Get Better At Anything"},{"location":"blog/2017/how-to-get-better-at-anything/#rtfm","text":"WTFM, Write The Flip'n Manual Do a lightning talk about it :)","title":"RTFM"},{"location":"blog/2017/how-to-get-better-at-anything/#make-it-fun","text":"Gamification Trophy anyone? If it can't be made fun, make it fun.","title":"Make it Fun"},{"location":"blog/2017/how-to-get-better-at-anything/#practice","text":"Slowly with intent Pressure cycles: none, some, actual, intolerable. The practice of practice deserves its own talk.","title":"Practice"},{"location":"blog/2017/how-to-get-better-at-anything/#better-not-good","text":"Good is the killer of better. People tend to stop because good is unreachable. People tend to stop after they're good enough. If we aim to get better, we'll eventually be better than good. Progressive goals. OMG! I forgot goal setting!","title":"Better not good"},{"location":"blog/2017/how-to-get-better-at-anything/#learn-dont-memorize","text":"Learning is understanding Understanding is connecting the new thing to an old thing. Computers memorize. You're not a computer.","title":"Learn, don't Memorize"},{"location":"blog/2017/how-to-get-better-at-anything/#learn-with-others","text":"With the Internet you're never alone and always alone. Actually talk with people!","title":"Learn with others"},{"location":"blog/2017/how-to-get-better-at-anything/#cheat","text":"If you're not cheating, you're not trying. Reverse engineer the cheat, don't actually cheat!","title":"Cheat"},{"location":"blog/2017/how-to-get-better-at-anything/#how-i-got-better-at-vim","text":"RTFM - :help WTFM - Blogging, figure out other people's problems :/ Practice - Wrote stuff that wasn't needed immediately, my own notes. Don't Memorize - Vim has grammar like English. Oooh... Reconnection! Learn with Others - We have vim users, teach them (but don't let them know you're only one step ahead) Cheat - Look at other's Vimscript to figure out that cool thing they did.","title":"How I got better at Vim"},{"location":"blog/2017/how-to-get-better-at-anything/#what-do-you-want-to-get-better-at-next","text":"lightning talks? Shuffling cards? ( @devin ) SQL? Drawing? Piano?","title":"What do you want to get better at next?!?"},{"location":"blog/2017/vim-send-text/","text":"Vim Send Text \u00b6 After pairing with some Sublime users, I noticed a neat feature. Or more accurately, they were rubbing it in my face that their cute editor was better than mine. The feature was SendText . Well, I couldn't let Sublime users have all the fun, and apparently neither could a few other people. History \u00b6 There have been a few other implementations at this feature. These implementations sent the text to a screen or tmux split. Since I don't use either, I couldn't use them a la carte. https://github.com/vim-scripts/tslime.vim https://github.com/jpalardy/vim-slime https://github.com/ervandew/screen This next implementation was good. It's only flaw, IMHO, was it's mappings and naming. The naming \"ISlime2\" is impossible for me to type on the first try. The mappings overlapped my existing mappings. ISlime2 did all the hard work AppleScript work and provides the Vim function to pass into the AppleScript. Enter vim-sendtext . vim-sendtext is a fork of ISlime2 . My fork removes all the mappings, exposes useful internal functions, and adds recommended mappings to the README.md. Recommended Mappings \u00b6 \" Send current line nnoremap < silent > < Leader > i < CR > :SendTextCurrentLine < CR > \" Send in/around text object - operation pending nnoremap < silent > < Leader > i : set opfunc = sendtext#iTermSendOperator < CR > g @ \" Send visual selection vnoremap < silent > < Leader > i : < C - u > call sendtext#iTermSendOperator ( visualmode (), 1 )< CR > \" Move to next line then send it nnoremap < silent > < Leader > ij :SendTextNextLine < CR > \" Move to previous line then send it nnoremap < silent > < Leader > ik :SendTextPreviousLine < CR > Vim Operator Pending \u00b6 One of the main reasons to use Vim is Operator pending. It's at the heart of vip , dip , ciw , etc. vim-sendtext provides an operator pending function so we can logically do {SEND}ap , {SEND}ip , {SEND}if , etc. The identical function works in visual mode to help build confidence in our text object targets. To read more about operator pending functions and how to create them try: : h map - operator Conclusion \u00b6 Hope vim-sendtext can remove some feature envy from Sublime. Happy console hacking!","title":"Vim Send Text"},{"location":"blog/2017/vim-send-text/#vim-send-text","text":"After pairing with some Sublime users, I noticed a neat feature. Or more accurately, they were rubbing it in my face that their cute editor was better than mine. The feature was SendText . Well, I couldn't let Sublime users have all the fun, and apparently neither could a few other people.","title":"Vim Send Text"},{"location":"blog/2017/vim-send-text/#history","text":"There have been a few other implementations at this feature. These implementations sent the text to a screen or tmux split. Since I don't use either, I couldn't use them a la carte. https://github.com/vim-scripts/tslime.vim https://github.com/jpalardy/vim-slime https://github.com/ervandew/screen This next implementation was good. It's only flaw, IMHO, was it's mappings and naming. The naming \"ISlime2\" is impossible for me to type on the first try. The mappings overlapped my existing mappings. ISlime2 did all the hard work AppleScript work and provides the Vim function to pass into the AppleScript. Enter vim-sendtext . vim-sendtext is a fork of ISlime2 . My fork removes all the mappings, exposes useful internal functions, and adds recommended mappings to the README.md.","title":"History"},{"location":"blog/2017/vim-send-text/#recommended-mappings","text":"\" Send current line nnoremap < silent > < Leader > i < CR > :SendTextCurrentLine < CR > \" Send in/around text object - operation pending nnoremap < silent > < Leader > i : set opfunc = sendtext#iTermSendOperator < CR > g @ \" Send visual selection vnoremap < silent > < Leader > i : < C - u > call sendtext#iTermSendOperator ( visualmode (), 1 )< CR > \" Move to next line then send it nnoremap < silent > < Leader > ij :SendTextNextLine < CR > \" Move to previous line then send it nnoremap < silent > < Leader > ik :SendTextPreviousLine < CR >","title":"Recommended Mappings"},{"location":"blog/2017/vim-send-text/#vim-operator-pending","text":"One of the main reasons to use Vim is Operator pending. It's at the heart of vip , dip , ciw , etc. vim-sendtext provides an operator pending function so we can logically do {SEND}ap , {SEND}ip , {SEND}if , etc. The identical function works in visual mode to help build confidence in our text object targets. To read more about operator pending functions and how to create them try: : h map - operator","title":"Vim Operator Pending"},{"location":"blog/2017/vim-send-text/#conclusion","text":"Hope vim-sendtext can remove some feature envy from Sublime. Happy console hacking!","title":"Conclusion"},{"location":"blog/2017/what-the-sql-lateral/","text":"What the SQL?!? Lateral Joins \u00b6 Today's \"What the SQL?!?\" features the keyword LATERAL . A prerequisite to understanding lateral joins are regular joins and subqueries. I'll explain those briefly to see how LATERAL can simplify a complicated SQL query. Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"lateral joins $DB_VENDOR_NAME\". Not all database vendors support the keyword LATERAL . A Problem to Solve \u00b6 We have a table with system uptimes. The table records a start timestamp and an end timestamp. If the service is still running, the end timestamp is left null because it hasn't ended. We want a query to display an overview this data. Our final solution will return a row per day and 24 columns containing an uptime percentage for each hour in the day. It will look like the following. cal_date | hour_0 | hour_1 | hour_2 | hour_3 | ... | hour_21 | hour_22 | hour_23 ------------+--------+--------+--------+--------+-----+---------+---------+--------- 2017-03-01 | 0 | 0.75 | 0.25 | 0 | ... | 0 | 0 | 0 2017-03-02 | 0 | 0 | 0 | 0 | ... | 1 | 1 | 1 (2 rows) Please note we'll use ... abbreviate some of the results. All queries are schema independent and should be copy/paste-able into any psql session. Sample Uptime Data \u00b6 The sample uptime data is derived from a virtual table built from the following query: SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) The data looks like: start_ts | end_ts ---------------------+--------------------- 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 08:00:00 | 2017-03-01 20:00:00 2017-03-02 19:00:00 | (3 rows) We want to plot the time against a time sliced table representing all the effective hours in the uptime window. We'll make use of another virtual table to build up all the time slices: SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) This we make use of PostgreSQL's generate_series to return all the hours between a time range. The data looks like: start_ts | end_ts ---------------------+--------------------- 2017-03-01 00:00:00 | 2017-03-01 01:00:00 2017-03-01 01:00:00 | 2017-03-01 02:00:00 2017-03-01 02:00:00 | 2017-03-01 03:00:00 -- ... many more rows ... 2017-03-01 03:00:00 | 2017-03-01 04:00:00 2017-03-02 22:00:00 | 2017-03-02 23:00:00 2017-03-02 23:00:00 | 2017-03-03 00:00:00 (48 rows) Left Join \u00b6 We use a left join to glue together overlapping time ranges between these two data sets. We want all the data on the LEFT side in the FROM clause to return regardless of an uptime record existing within its time slice. SELECT * FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) The result set shows we have some variety in our sample data. With 3 slices up time and 3 slices of downtime. start_ts | end_ts | start_ts | end_ts ---------------------+---------------------+---------------------+--------------------- 2017-03-01 00:00:00 | 2017-03-01 01:00:00 | | 2017-03-01 01:00:00 | 2017-03-01 02:00:00 | 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 02:00:00 | 2017-03-01 03:00:00 | 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 03:00:00 | 2017-03-01 04:00:00 | | ... 2017-03-01 07:00:00 | 2017-03-01 08:00:00 | | 2017-03-01 08:00:00 | 2017-03-01 09:00:00 | 2017-03-01 08:00:00 | 2017-03-01 20:00:00 ... 2017-03-01 20:00:00 | 2017-03-01 21:00:00 | 2017-03-01 08:00:00 | 2017-03-01 20:00:00 2017-03-01 21:00:00 | 2017-03-01 22:00:00 | | ... 2017-03-02 18:00:00 | 2017-03-02 19:00:00 | | 2017-03-02 19:00:00 | 2017-03-02 20:00:00 | 2017-03-02 19:00:00 | ... 2017-03-02 23:00:00 | 2017-03-03 00:00:00 | 2017-03-02 19:00:00 | (48 rows) If we try without the LEFT clause, we'll only see 20 rows containing the up slices. Time to compute some timing \u00b6 Let's add some times and sensible column names and replace the * SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) first_ts | last_ts | cal_date | cal_hour | cal_seconds ---------------------+---------------------+------------+----------+------------- | 2017-03-01 01:00:00 | 2017-03-01 | 0 | 3600 2017-03-01 01:15:00 | 2017-03-01 02:00:00 | 2017-03-01 | 1 | 3600 2017-03-01 02:00:00 | 2017-03-01 02:15:00 | 2017-03-01 | 2 | 3600 | 2017-03-01 04:00:00 | 2017-03-01 | 3 | 3600 | 2017-03-01 05:00:00 | 2017-03-01 | 4 | 3600 | 2017-03-01 06:00:00 | 2017-03-01 | 5 | 3600 | 2017-03-01 07:00:00 | 2017-03-01 | 6 | 3600 | 2017-03-01 08:00:00 | 2017-03-01 | 7 | 3600 2017-03-01 08:00:00 | 2017-03-01 09:00:00 | 2017-03-01 | 8 | 3600 ... 2017-03-01 20:00:00 | 2017-03-01 20:00:00 | 2017-03-01 | 20 | 3600 | 2017-03-01 22:00:00 | 2017-03-01 | 21 | 3600 ... | 2017-03-02 19:00:00 | 2017-03-02 | 18 | 3600 2017-03-02 19:00:00 | 2017-03-02 20:00:00 | 2017-03-02 | 19 | 3600 ... 2017-03-02 23:00:00 | 2017-03-03 00:00:00 | 2017-03-02 | 23 | 3600 (48 rows) Subquery, Subquery, What's the Worry? \u00b6 SQL is all about nested subqueries. It's hard to escape without creating views, but who has time to lookup that syntax and get their DBA's permission to run the DDL?!? Let's add some duration times to the result set. We'll use the traditional sub query for it. SELECT -- calculate uptime seconds coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds , * FROM ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) ) t1 up_seconds ------------ 0 2700 900 0 0 ... 3600 (48 rows) Without the subquery we'd be getting into even more nested function calls and would have to double compute values or have no visibility in the intermediate steps. We could have calculated up_seconds directly in the first query which introduced first_ts and last_ts . That would look like this: SELECT coalesce ( extract ( epoch FROM age ( least ( cal . end_ts , uptime . end_ts ), CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END ) ), 0 ) AS up_seconds FROM --- ... It's not for the weak stomach, but frankly speaking, neither is the subquery... Enough Nesting, LATERAL join save me! \u00b6 Lateral joins can give us the best of both worlds: reduced subquery nesting and traceable computed values. We're going to move the initial computed values like first_ts and last_ts , move them to a virtual table then JOIN LATERAL so they can get their own table alias. We'll do it again for up_seconds and use first_ts and last_ts from its sibling table. SELECT t2 . up_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) JOIN LATERAL ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds ) t1 ON true JOIN LATERAL ( -- calculate uptime seconds for the time slice SELECT coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds ) t2 ON true This gives us the same results but without the deep nesting. up_seconds ------------ 0 2700 900 0 0 3600 ... 3600 (48 rows) What's great about this strategy is we can quickly choose which columns to see as we build up the query. SELECT t2 . up_seconds ... -- or -- SELECT t2 . * , t1 . * Let's build up the final calculation using the same strategy: SELECT t2 . * , t3 . * FROM ... JOIN LATERAL ( -- calculate percentage between uptime seconds and available seconds -- within the time slice SELECT up_seconds / cal_seconds AS up_pct ) t3 ON true up_seconds | up_pct ------------+-------- 0 | 0 2700 | 0.75 900 | 0.25 0 | 0 ... 3600 | 1 (48 rows) Plot the Hours \u00b6 Now we have all the computed data we need. Let's plot it as a cross tab (but not actually use crosstab ) We'll need to consolidate the long list of data by cal_date and pivot the cal_hour as a column and up_pct as a value. In case of overlapping uptimes we'll be pessimists and choose the lowest or min uptime percentage. The final query looks like: SELECT cal_date , max ( CASE WHEN cal_hour = 0 THEN up_pct END ) AS hour_0 , max ( CASE WHEN cal_hour = 1 THEN up_pct END ) AS hour_1 , max ( CASE WHEN cal_hour = 2 THEN up_pct END ) AS hour_2 , max ( CASE WHEN cal_hour = 3 THEN up_pct END ) AS hour_3 , max ( CASE WHEN cal_hour = 4 THEN up_pct END ) AS hour_4 , max ( CASE WHEN cal_hour = 5 THEN up_pct END ) AS hour_5 , max ( CASE WHEN cal_hour = 6 THEN up_pct END ) AS hour_6 , max ( CASE WHEN cal_hour = 7 THEN up_pct END ) AS hour_7 , max ( CASE WHEN cal_hour = 8 THEN up_pct END ) AS hour_8 , max ( CASE WHEN cal_hour = 9 THEN up_pct END ) AS hour_9 , max ( CASE WHEN cal_hour = 10 THEN up_pct END ) AS hour_10 , max ( CASE WHEN cal_hour = 11 THEN up_pct END ) AS hour_11 , max ( CASE WHEN cal_hour = 12 THEN up_pct END ) AS hour_12 , max ( CASE WHEN cal_hour = 13 THEN up_pct END ) AS hour_13 , max ( CASE WHEN cal_hour = 14 THEN up_pct END ) AS hour_14 , max ( CASE WHEN cal_hour = 15 THEN up_pct END ) AS hour_15 , max ( CASE WHEN cal_hour = 16 THEN up_pct END ) AS hour_16 , max ( CASE WHEN cal_hour = 17 THEN up_pct END ) AS hour_17 , max ( CASE WHEN cal_hour = 18 THEN up_pct END ) AS hour_18 , max ( CASE WHEN cal_hour = 19 THEN up_pct END ) AS hour_19 , max ( CASE WHEN cal_hour = 20 THEN up_pct END ) AS hour_20 , max ( CASE WHEN cal_hour = 21 THEN up_pct END ) AS hour_21 , max ( CASE WHEN cal_hour = 22 THEN up_pct END ) AS hour_22 , max ( CASE WHEN cal_hour = 23 THEN up_pct END ) AS hour_23 FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) JOIN LATERAL ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds ) t1 ON true JOIN LATERAL ( SELECT coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds ) t2 ON true JOIN LATERAL ( -- calculate percentage between uptime seconds and available seconds -- within the time slice SELECT up_seconds / cal_seconds AS up_pct ) t3 ON true GROUP BY cal_date cal_date | hour_0 | hour_1 | hour_2 | hour_3 | ... | hour_23 ------------+--------+--------+--------+--------+ ... +--------- 2017-03-01 | 0 | 0.75 | 0.25 | 0 | ... | 0 2017-03-02 | 0 | 0 | 0 | 0 | ... | 1 (2 rows) More than CTE and Cross Join \u00b6 This example only scratches the surface of LATERAL s super powers. On the surface LATERAL can do things CTE , cross join, and WINDOW can do. PostgreSQL describe LATERAL as: Subqueries appearing in FROM can be preceded by the key word LATERAL. This allows them to reference columns provided by preceding FROM items. (Without LATERAL, each subquery is evaluated independently and so cannot cross-reference any other FROM item.) TL;DR - LATERAL allows subqueries to reference earlier tables. References \u00b6 Postgres Lateral Joins","title":"What the SQL?!? Lateral Joins"},{"location":"blog/2017/what-the-sql-lateral/#what-the-sql-lateral-joins","text":"Today's \"What the SQL?!?\" features the keyword LATERAL . A prerequisite to understanding lateral joins are regular joins and subqueries. I'll explain those briefly to see how LATERAL can simplify a complicated SQL query. Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"lateral joins $DB_VENDOR_NAME\". Not all database vendors support the keyword LATERAL .","title":"What the SQL?!? Lateral Joins"},{"location":"blog/2017/what-the-sql-lateral/#a-problem-to-solve","text":"We have a table with system uptimes. The table records a start timestamp and an end timestamp. If the service is still running, the end timestamp is left null because it hasn't ended. We want a query to display an overview this data. Our final solution will return a row per day and 24 columns containing an uptime percentage for each hour in the day. It will look like the following. cal_date | hour_0 | hour_1 | hour_2 | hour_3 | ... | hour_21 | hour_22 | hour_23 ------------+--------+--------+--------+--------+-----+---------+---------+--------- 2017-03-01 | 0 | 0.75 | 0.25 | 0 | ... | 0 | 0 | 0 2017-03-02 | 0 | 0 | 0 | 0 | ... | 1 | 1 | 1 (2 rows) Please note we'll use ... abbreviate some of the results. All queries are schema independent and should be copy/paste-able into any psql session.","title":"A Problem to Solve"},{"location":"blog/2017/what-the-sql-lateral/#sample-uptime-data","text":"The sample uptime data is derived from a virtual table built from the following query: SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) The data looks like: start_ts | end_ts ---------------------+--------------------- 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 08:00:00 | 2017-03-01 20:00:00 2017-03-02 19:00:00 | (3 rows) We want to plot the time against a time sliced table representing all the effective hours in the uptime window. We'll make use of another virtual table to build up all the time slices: SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) This we make use of PostgreSQL's generate_series to return all the hours between a time range. The data looks like: start_ts | end_ts ---------------------+--------------------- 2017-03-01 00:00:00 | 2017-03-01 01:00:00 2017-03-01 01:00:00 | 2017-03-01 02:00:00 2017-03-01 02:00:00 | 2017-03-01 03:00:00 -- ... many more rows ... 2017-03-01 03:00:00 | 2017-03-01 04:00:00 2017-03-02 22:00:00 | 2017-03-02 23:00:00 2017-03-02 23:00:00 | 2017-03-03 00:00:00 (48 rows)","title":"Sample Uptime Data"},{"location":"blog/2017/what-the-sql-lateral/#left-join","text":"We use a left join to glue together overlapping time ranges between these two data sets. We want all the data on the LEFT side in the FROM clause to return regardless of an uptime record existing within its time slice. SELECT * FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) The result set shows we have some variety in our sample data. With 3 slices up time and 3 slices of downtime. start_ts | end_ts | start_ts | end_ts ---------------------+---------------------+---------------------+--------------------- 2017-03-01 00:00:00 | 2017-03-01 01:00:00 | | 2017-03-01 01:00:00 | 2017-03-01 02:00:00 | 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 02:00:00 | 2017-03-01 03:00:00 | 2017-03-01 01:15:00 | 2017-03-01 02:15:00 2017-03-01 03:00:00 | 2017-03-01 04:00:00 | | ... 2017-03-01 07:00:00 | 2017-03-01 08:00:00 | | 2017-03-01 08:00:00 | 2017-03-01 09:00:00 | 2017-03-01 08:00:00 | 2017-03-01 20:00:00 ... 2017-03-01 20:00:00 | 2017-03-01 21:00:00 | 2017-03-01 08:00:00 | 2017-03-01 20:00:00 2017-03-01 21:00:00 | 2017-03-01 22:00:00 | | ... 2017-03-02 18:00:00 | 2017-03-02 19:00:00 | | 2017-03-02 19:00:00 | 2017-03-02 20:00:00 | 2017-03-02 19:00:00 | ... 2017-03-02 23:00:00 | 2017-03-03 00:00:00 | 2017-03-02 19:00:00 | (48 rows) If we try without the LEFT clause, we'll only see 20 rows containing the up slices.","title":"Left Join"},{"location":"blog/2017/what-the-sql-lateral/#time-to-compute-some-timing","text":"Let's add some times and sensible column names and replace the * SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) first_ts | last_ts | cal_date | cal_hour | cal_seconds ---------------------+---------------------+------------+----------+------------- | 2017-03-01 01:00:00 | 2017-03-01 | 0 | 3600 2017-03-01 01:15:00 | 2017-03-01 02:00:00 | 2017-03-01 | 1 | 3600 2017-03-01 02:00:00 | 2017-03-01 02:15:00 | 2017-03-01 | 2 | 3600 | 2017-03-01 04:00:00 | 2017-03-01 | 3 | 3600 | 2017-03-01 05:00:00 | 2017-03-01 | 4 | 3600 | 2017-03-01 06:00:00 | 2017-03-01 | 5 | 3600 | 2017-03-01 07:00:00 | 2017-03-01 | 6 | 3600 | 2017-03-01 08:00:00 | 2017-03-01 | 7 | 3600 2017-03-01 08:00:00 | 2017-03-01 09:00:00 | 2017-03-01 | 8 | 3600 ... 2017-03-01 20:00:00 | 2017-03-01 20:00:00 | 2017-03-01 | 20 | 3600 | 2017-03-01 22:00:00 | 2017-03-01 | 21 | 3600 ... | 2017-03-02 19:00:00 | 2017-03-02 | 18 | 3600 2017-03-02 19:00:00 | 2017-03-02 20:00:00 | 2017-03-02 | 19 | 3600 ... 2017-03-02 23:00:00 | 2017-03-03 00:00:00 | 2017-03-02 | 23 | 3600 (48 rows)","title":"Time to compute some timing"},{"location":"blog/2017/what-the-sql-lateral/#subquery-subquery-whats-the-worry","text":"SQL is all about nested subqueries. It's hard to escape without creating views, but who has time to lookup that syntax and get their DBA's permission to run the DDL?!? Let's add some duration times to the result set. We'll use the traditional sub query for it. SELECT -- calculate uptime seconds coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds , * FROM ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) ) t1 up_seconds ------------ 0 2700 900 0 0 ... 3600 (48 rows) Without the subquery we'd be getting into even more nested function calls and would have to double compute values or have no visibility in the intermediate steps. We could have calculated up_seconds directly in the first query which introduced first_ts and last_ts . That would look like this: SELECT coalesce ( extract ( epoch FROM age ( least ( cal . end_ts , uptime . end_ts ), CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END ) ), 0 ) AS up_seconds FROM --- ... It's not for the weak stomach, but frankly speaking, neither is the subquery...","title":"Subquery, Subquery, What's the Worry?"},{"location":"blog/2017/what-the-sql-lateral/#enough-nesting-lateral-join-save-me","text":"Lateral joins can give us the best of both worlds: reduced subquery nesting and traceable computed values. We're going to move the initial computed values like first_ts and last_ts , move them to a virtual table then JOIN LATERAL so they can get their own table alias. We'll do it again for up_seconds and use first_ts and last_ts from its sibling table. SELECT t2 . up_seconds FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) JOIN LATERAL ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds ) t1 ON true JOIN LATERAL ( -- calculate uptime seconds for the time slice SELECT coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds ) t2 ON true This gives us the same results but without the deep nesting. up_seconds ------------ 0 2700 900 0 0 3600 ... 3600 (48 rows) What's great about this strategy is we can quickly choose which columns to see as we build up the query. SELECT t2 . up_seconds ... -- or -- SELECT t2 . * , t1 . * Let's build up the final calculation using the same strategy: SELECT t2 . * , t3 . * FROM ... JOIN LATERAL ( -- calculate percentage between uptime seconds and available seconds -- within the time slice SELECT up_seconds / cal_seconds AS up_pct ) t3 ON true up_seconds | up_pct ------------+-------- 0 | 0 2700 | 0.75 900 | 0.25 0 | 0 ... 3600 | 1 (48 rows)","title":"Enough Nesting, LATERAL join save me!"},{"location":"blog/2017/what-the-sql-lateral/#plot-the-hours","text":"Now we have all the computed data we need. Let's plot it as a cross tab (but not actually use crosstab ) We'll need to consolidate the long list of data by cal_date and pivot the cal_hour as a column and up_pct as a value. In case of overlapping uptimes we'll be pessimists and choose the lowest or min uptime percentage. The final query looks like: SELECT cal_date , max ( CASE WHEN cal_hour = 0 THEN up_pct END ) AS hour_0 , max ( CASE WHEN cal_hour = 1 THEN up_pct END ) AS hour_1 , max ( CASE WHEN cal_hour = 2 THEN up_pct END ) AS hour_2 , max ( CASE WHEN cal_hour = 3 THEN up_pct END ) AS hour_3 , max ( CASE WHEN cal_hour = 4 THEN up_pct END ) AS hour_4 , max ( CASE WHEN cal_hour = 5 THEN up_pct END ) AS hour_5 , max ( CASE WHEN cal_hour = 6 THEN up_pct END ) AS hour_6 , max ( CASE WHEN cal_hour = 7 THEN up_pct END ) AS hour_7 , max ( CASE WHEN cal_hour = 8 THEN up_pct END ) AS hour_8 , max ( CASE WHEN cal_hour = 9 THEN up_pct END ) AS hour_9 , max ( CASE WHEN cal_hour = 10 THEN up_pct END ) AS hour_10 , max ( CASE WHEN cal_hour = 11 THEN up_pct END ) AS hour_11 , max ( CASE WHEN cal_hour = 12 THEN up_pct END ) AS hour_12 , max ( CASE WHEN cal_hour = 13 THEN up_pct END ) AS hour_13 , max ( CASE WHEN cal_hour = 14 THEN up_pct END ) AS hour_14 , max ( CASE WHEN cal_hour = 15 THEN up_pct END ) AS hour_15 , max ( CASE WHEN cal_hour = 16 THEN up_pct END ) AS hour_16 , max ( CASE WHEN cal_hour = 17 THEN up_pct END ) AS hour_17 , max ( CASE WHEN cal_hour = 18 THEN up_pct END ) AS hour_18 , max ( CASE WHEN cal_hour = 19 THEN up_pct END ) AS hour_19 , max ( CASE WHEN cal_hour = 20 THEN up_pct END ) AS hour_20 , max ( CASE WHEN cal_hour = 21 THEN up_pct END ) AS hour_21 , max ( CASE WHEN cal_hour = 22 THEN up_pct END ) AS hour_22 , max ( CASE WHEN cal_hour = 23 THEN up_pct END ) AS hour_23 FROM ( -- build virtual table of all hours between -- a date range SELECT start_ts , start_ts + interval '1 hour' AS end_ts FROM generate_series ( '2017-03-01' :: date , '2017-03-03' :: timestamp - interval '1 hour' , interval '1 hour' ) AS t ( start_ts ) ) AS cal LEFT JOIN ( -- build virtual table of uptimes SELECT * FROM ( VALUES ( '2017-03-01 01:15:00-06' :: timestamp , '2017-03-01 02:15:00-06' :: timestamp ), ( '2017-03-01 08:00:00-06' , '2017-03-01 20:00:00-06' ), ( '2017-03-02 19:00:00-06' , null ) ) AS t ( start_ts , end_ts ) ) AS uptime ON cal . end_ts > uptime . start_ts AND cal . start_ts <= coalesce ( uptime . end_ts , current_timestamp ) JOIN LATERAL ( SELECT -- will use `first_ts` and `last_ts` to calculate uptime duration CASE WHEN uptime . start_ts IS NOT NULL THEN greatest ( uptime . start_ts , cal . start_ts ) END AS first_ts , least ( cal . end_ts , uptime . end_ts ) AS last_ts , date_trunc ( 'day' , cal . start_ts ):: date AS cal_date , extract ( hour from cal . start_ts ) AS cal_hour , extract ( epoch from age ( cal . end_ts , cal . start_ts )) AS cal_seconds ) t1 ON true JOIN LATERAL ( SELECT coalesce ( extract ( epoch FROM age ( last_ts , first_ts )), 0 ) AS up_seconds ) t2 ON true JOIN LATERAL ( -- calculate percentage between uptime seconds and available seconds -- within the time slice SELECT up_seconds / cal_seconds AS up_pct ) t3 ON true GROUP BY cal_date cal_date | hour_0 | hour_1 | hour_2 | hour_3 | ... | hour_23 ------------+--------+--------+--------+--------+ ... +--------- 2017-03-01 | 0 | 0.75 | 0.25 | 0 | ... | 0 2017-03-02 | 0 | 0 | 0 | 0 | ... | 1 (2 rows)","title":"Plot the Hours"},{"location":"blog/2017/what-the-sql-lateral/#more-than-cte-and-cross-join","text":"This example only scratches the surface of LATERAL s super powers. On the surface LATERAL can do things CTE , cross join, and WINDOW can do. PostgreSQL describe LATERAL as: Subqueries appearing in FROM can be preceded by the key word LATERAL. This allows them to reference columns provided by preceding FROM items. (Without LATERAL, each subquery is evaluated independently and so cannot cross-reference any other FROM item.) TL;DR - LATERAL allows subqueries to reference earlier tables.","title":"More than CTE and Cross Join"},{"location":"blog/2017/what-the-sql-lateral/#references","text":"Postgres Lateral Joins","title":"References"},{"location":"blog/2017/what-the-sql-recursive/","text":"What the SQL?!? Recursive \u00b6 Today's \"What the SQL?!?\" features the keyword RECURSIVE . This clause allows us to elegantly select results from the previous results from the previous results from the previous results... Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"RECURSIVE queries $DB_VENDOR_NAME\". Not all database vendors support the keyword RECURSIVE . Fibonacci Sequence \u00b6 According to Wikipedia : In mathematics, the Fibonacci numbers are the numbers in the following integer sequence, called the Fibonacci sequence, and characterized by the fact that every number after the first two is the sum of the two preceding ones: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55 ... SQL Solution \u00b6 Our SQL solution will make use of the RECURSIVE CTE keyword. WITH RECURSIVE t ( i , fi , fib ) AS ( SELECT 1 , 0 :: NUMERIC , 1 :: NUMERIC UNION ALL SELECT i + 1 , fib , fi + fib FROM t WHERE i < 10 ) SELECT i , fib FROM t The Ins and Outs \u00b6 Here's some inline colorful comments to explain the sections: Maybe arrows will help a little more with the flow of data: Fibonacci Results \u00b6 When you run the query, you'll get the following results: i | fib ----+----- 1 | 1 2 | 1 3 | 2 4 | 3 5 | 5 6 | 8 7 | 13 8 | 21 9 | 34 10 | 55 (10 rows) If you want to see the results for a high number, update i < 10 to a higher value. If you go above i < 793 , Postgres gives up and returns Nan which means Not a number which means the computed value is larger than your computer can handle and still treat like a number. Sorry, get a new computer or work with numbers less than 166 digits long. A Real World Example with Hierarchical Data \u00b6 Fibonacci sequence is nice and all, but you have real data concerns. You're thinking, \"Show me the DATA!\". So here's the data... -- Build `sample_people` table CREATE TABLE sample_people AS SELECT column1 :: int AS id , column2 :: varchar AS name , column3 :: int AS parent_id FROM ( VALUES ( 0 , 'Root' , null ), ( 1 , 'Alice' , 0 ), ( 2 , 'Bob' , 1 ), ( 3 , 'Cat' , 1 ), ( 4 , 'Dan' , 3 ), ( 5 , 'Evan' , 0 ), ( 6 , 'Frank' , 5 ) ) as t ; SELECT * FROM sample_people ; -- id | name | parent_id -- ----+-------+----------- -- 0 | Root | -- 1 | Alice | 0 -- 2 | Bob | 1 -- 3 | Cat | 1 -- 4 | Dan | 3 -- 5 | Evan | 0 -- 6 | Frank | 5 Our sample_people table represents a person by name and that person may have a parent. The parent of all the parents is Root . And finally our recursive query to get a nice display of the hierarchy. WITH RECURSIVE tree -- `tree` is the table alias. -- It must be used as part of the `UNION` statement. AS ( -- 1) Initialize table with all the top level rows. -- Anything without a parent is a parent. Is that apparent? SELECT 0 AS level , -- 2) Set the level to 0. sample_people . * -- 3) Return the initial row FROM sample_people WHERE parent_id = 0 -- 4) Top level doesn't have a parent. UNION ALL -- 5) Union all the parents with their children. SELECT tree . level + 1 , -- 6) Increment the level every time we loop. sample_people . * -- 7) Return the current row - the child row. FROM tree -- 8) `tree` is populated with the previous results. -- Every loop gets a new record from current result. JOIN sample_people ON sample_people . parent_id = tree . id ) SELECT repeat ( ' ' , level * 4 ) || name AS display FROM tree ORDER BY level , name ; -- display -- ------------- -- Alice -- Evan -- Bob -- Cat -- Frank -- Dan -- (6 rows) Bait and Switch \u00b6 RECURSIVE is not actually recursive. It isn't a function calling itself. Sorry, not sorry. It's much closer to a while loop. Here's what Postgres has to say about it: Note: Strictly speaking, this process is iteration not recursion, but RECURSIVE is the terminology chosen by the SQL standards committee. [emphasis added] Closing \u00b6 So the next time you try to crawl a hierarchy of data, we hope RECURSIVE comes to mind. It's a great way to save round trips to the database and query what is needed based on the data's structure. Think of all the nested subqueries we can save together! References \u00b6 Postgres WITH Queries: https://www.postgresql.org/docs/9.3/static/queries-with.html Wikipedia Fibonacci number: https://en.wikipedia.org/wiki/Fibonacci_number","title":"What the SQL?!? Recursive"},{"location":"blog/2017/what-the-sql-recursive/#what-the-sql-recursive","text":"Today's \"What the SQL?!?\" features the keyword RECURSIVE . This clause allows us to elegantly select results from the previous results from the previous results from the previous results... Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"RECURSIVE queries $DB_VENDOR_NAME\". Not all database vendors support the keyword RECURSIVE .","title":"What the SQL?!? Recursive"},{"location":"blog/2017/what-the-sql-recursive/#fibonacci-sequence","text":"According to Wikipedia : In mathematics, the Fibonacci numbers are the numbers in the following integer sequence, called the Fibonacci sequence, and characterized by the fact that every number after the first two is the sum of the two preceding ones: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55 ...","title":"Fibonacci Sequence"},{"location":"blog/2017/what-the-sql-recursive/#sql-solution","text":"Our SQL solution will make use of the RECURSIVE CTE keyword. WITH RECURSIVE t ( i , fi , fib ) AS ( SELECT 1 , 0 :: NUMERIC , 1 :: NUMERIC UNION ALL SELECT i + 1 , fib , fi + fib FROM t WHERE i < 10 ) SELECT i , fib FROM t","title":"SQL Solution"},{"location":"blog/2017/what-the-sql-recursive/#the-ins-and-outs","text":"Here's some inline colorful comments to explain the sections: Maybe arrows will help a little more with the flow of data:","title":"The Ins and Outs"},{"location":"blog/2017/what-the-sql-recursive/#fibonacci-results","text":"When you run the query, you'll get the following results: i | fib ----+----- 1 | 1 2 | 1 3 | 2 4 | 3 5 | 5 6 | 8 7 | 13 8 | 21 9 | 34 10 | 55 (10 rows) If you want to see the results for a high number, update i < 10 to a higher value. If you go above i < 793 , Postgres gives up and returns Nan which means Not a number which means the computed value is larger than your computer can handle and still treat like a number. Sorry, get a new computer or work with numbers less than 166 digits long.","title":"Fibonacci Results"},{"location":"blog/2017/what-the-sql-recursive/#a-real-world-example-with-hierarchical-data","text":"Fibonacci sequence is nice and all, but you have real data concerns. You're thinking, \"Show me the DATA!\". So here's the data... -- Build `sample_people` table CREATE TABLE sample_people AS SELECT column1 :: int AS id , column2 :: varchar AS name , column3 :: int AS parent_id FROM ( VALUES ( 0 , 'Root' , null ), ( 1 , 'Alice' , 0 ), ( 2 , 'Bob' , 1 ), ( 3 , 'Cat' , 1 ), ( 4 , 'Dan' , 3 ), ( 5 , 'Evan' , 0 ), ( 6 , 'Frank' , 5 ) ) as t ; SELECT * FROM sample_people ; -- id | name | parent_id -- ----+-------+----------- -- 0 | Root | -- 1 | Alice | 0 -- 2 | Bob | 1 -- 3 | Cat | 1 -- 4 | Dan | 3 -- 5 | Evan | 0 -- 6 | Frank | 5 Our sample_people table represents a person by name and that person may have a parent. The parent of all the parents is Root . And finally our recursive query to get a nice display of the hierarchy. WITH RECURSIVE tree -- `tree` is the table alias. -- It must be used as part of the `UNION` statement. AS ( -- 1) Initialize table with all the top level rows. -- Anything without a parent is a parent. Is that apparent? SELECT 0 AS level , -- 2) Set the level to 0. sample_people . * -- 3) Return the initial row FROM sample_people WHERE parent_id = 0 -- 4) Top level doesn't have a parent. UNION ALL -- 5) Union all the parents with their children. SELECT tree . level + 1 , -- 6) Increment the level every time we loop. sample_people . * -- 7) Return the current row - the child row. FROM tree -- 8) `tree` is populated with the previous results. -- Every loop gets a new record from current result. JOIN sample_people ON sample_people . parent_id = tree . id ) SELECT repeat ( ' ' , level * 4 ) || name AS display FROM tree ORDER BY level , name ; -- display -- ------------- -- Alice -- Evan -- Bob -- Cat -- Frank -- Dan -- (6 rows)","title":"A Real World Example with Hierarchical Data"},{"location":"blog/2017/what-the-sql-recursive/#bait-and-switch","text":"RECURSIVE is not actually recursive. It isn't a function calling itself. Sorry, not sorry. It's much closer to a while loop. Here's what Postgres has to say about it: Note: Strictly speaking, this process is iteration not recursion, but RECURSIVE is the terminology chosen by the SQL standards committee. [emphasis added]","title":"Bait and Switch"},{"location":"blog/2017/what-the-sql-recursive/#closing","text":"So the next time you try to crawl a hierarchy of data, we hope RECURSIVE comes to mind. It's a great way to save round trips to the database and query what is needed based on the data's structure. Think of all the nested subqueries we can save together!","title":"Closing"},{"location":"blog/2017/what-the-sql-recursive/#references","text":"Postgres WITH Queries: https://www.postgresql.org/docs/9.3/static/queries-with.html Wikipedia Fibonacci number: https://en.wikipedia.org/wiki/Fibonacci_number","title":"References"},{"location":"blog/2017/what-the-sql-window/","text":"What the SQL?!? WINDOW \u00b6 Today's \"What the SQL?!?\" features the keyword WINDOW . This clause allows us to elegantly select results from the previous results from the previous results from the previous results... Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"WINDOW queries $DB_VENDOR_NAME\". Not all database vendors support the keyword WINDOW . Create Sample Data \u00b6 DROP TABLE IF EXISTS sample_moves ; CREATE TABLE sample_moves AS SELECT column1 :: int AS id , column2 :: varchar AS name , column3 :: varchar AS address , column4 :: date AS moved_at FROM ( VALUES ( 1 , 'Alice' , '1 Main St' , '2017-01-01' ), ( 2 , 'Bob' , '2 Main St' , '2017-02-01' ), ( 3 , 'Cat' , '2 Main St' , '2017-03-01' ), ( 4 , 'Dan Sr' , '3 Main St' , '1970-04-01' ), ( 5 , 'Dan Jr' , '3 Main St' , '2001-04-01' ), ( 6 , 'Dan 3rd' , '3 Main St' , '2017-04-01' ) ) as t ; CREATE INDEX ON sample_moves ( address ); SELECT * FROM sample_moves ; Results: \u00b6 id name address moved_at 1 Alice 1 Main St 2017-01-01 2 Bob 2 Main St 2017-02-01 3 Cat 2 Main St 2017-03-01 4 Dan Sr 3 Main St 1970-04-01 5 Dan Jr 3 Main St 2001-04-01 6 Dan 3 rd 3 Main St 2017-04-01 Life Without Windows \u00b6 A quick poem... Eyes big and wide, nothing seen inside. Feeling around nothing abound. This things wet, toxic I bet. Closing my eyes, still can't rest. Having a window, would be best. How many people live at each address? \u00b6 Using a standard GROUP BY with COUNT we consolidate the records and count how many rows belong to each address. Tip : COUNT(1) is more efficient than COUNT(*) . SELECT address , COUNT ( 1 ) total FROM sample_moves GROUP BY address ORDER BY address ; Results: \u00b6 address total 1 Main St 1 2 Main St 2 3 Main St 3 How many people live with each person? \u00b6 Enter subquery land. Life without windows is not exciting. SELECT * , ( SELECT -- everyone at the address, minus the person COUNT ( 1 ) - 1 FROM sample_moves t2 WHERE t2 . address = t1 . address ) AS others FROM sample_moves t1 ; Results: \u00b6 id name address moved_at others 1 Alice 1 Main St 2017-01-01 0 2 Bob 2 Main St 2017-02-01 1 3 Cat 2 Main St 2017-03-01 1 4 Dan Sr 3 Main St 1970-04-01 2 5 Dan Jr 3 Main St 2001-04-01 2 6 Dan 3 rd 3 Main St 2017-04-01 2 JOIN works, too \u00b6 SELECT t1 . * , t2 . others FROM sample_moves t1 JOIN ( SELECT address , COUNT ( 1 ) - 1 as others FROM sample_moves GROUP BY address ORDER BY address ) t2 USING ( address ); And so does JOIN LATERAL \u00b6 SELECT t1 . * , t2 . others FROM sample_moves t1 JOIN LATERAL ( SELECT address , COUNT ( 1 ) - 1 as others FROM sample_moves sub WHERE sub . address = t1 . address GROUP BY address ORDER BY address ) t2 ON true ; That's nice, but who moved in first? \u00b6 SELECT * , ( SELECT COUNT ( 1 ) - 1 FROM sample_moves t2 WHERE t2 . address = t1 . address ) AS others , ( SELECT name FROM sample_moves t3 WHERE t3 . address = t1 . address ORDER BY moved_at ASC LIMIT 1 ) AS first_person FROM sample_moves t1 ; Wait I thought this was about windows?!? \u00b6 The keyword OVER is the gateway drug into WINDOW functions. Using OVER with parenthesis is an inline window. The PARTITION BY keywords gives similar functionality to GROUP BY and JOIN ... USING all in one power packed statement. It can never reduce the number of records in a result set which is the same behavior expected of a correlated subquery. PARTITION BY is treated the same as the traditional GROUP BY . The ORDER BY also has the same behavior as its use in a standard query. SELECT * , ( count ( 1 ) OVER ( PARTITION BY address )) - 1 AS others , first_value ( name ) OVER ( PARTITION BY address ORDER BY moved_at ) AS first_moved FROM sample_moves ; Results \u00b6 id name address moved_at others first_moved 1 Alice 1 Main St 2017-01-01 0 Alice 2 Bob 2 Main St 2017-02-01 1 Bob 3 Cat 2 Main St 2017-03-01 1 Bob 4 Dan Sr 3 Main St 1970-04-01 2 Dan Sr 5 Dan Jr 3 Main St 2001-04-01 2 Dan Sr 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr A picture with arrows worth a thousand words: That doesn't look very DRY. Finally, a WINDOW \u00b6 The WINDOW keyword allows us to alias the options of the OVER clause. Namely the expression (...) between and including the parenthesis. In the following example we add the use of RANGE to provide additional direction to the windowing clause. SELECT * , ( count ( 1 ) OVER w ) - 1 AS others , first_value ( name ) OVER w AS first_moved , last_value ( name ) OVER w AS last_moved FROM sample_moves WINDOW w AS ( PARTITION BY address ORDER BY moved_at RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ); Results \u00b6 id name address moved_at others first_moved last_moved 1 Alice 1 Main St 2017-01-01 0 Alice Alice 2 Bob 2 Main St 2017-02-01 0 Bob Bob 3 Cat 2 Main St 2017-03-01 1 Bob Cat 4 Dan Sr 3 Main St 1970-04-01 0 Dan Sr Dan Sr 5 Dan Jr 3 Main St 2001-04-01 1 Dan Sr Dan Jr 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr Dan 3 rd -- Previous and Next Record SELECT * , ( count ( 1 ) OVER w ) - 1 AS others , first_value ( name ) OVER w AS first_moved , last_value ( name ) OVER w AS last_moved , lag ( id ) OVER ( ORDER BY id ) AS prev_id , lead ( id ) OVER ( ORDER BY id ) AS next_id FROM sample_moves WINDOW w AS ( PARTITION BY address ORDER BY moved_at RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) ORDER BY address ; Results \u00b6 id name address moved_at others first_moved last_moved prev_id next_id 1 Alice 1 Main St 2017-01-01 0 Alice Alice 2 2 Bob 2 Main St 2017-02-01 1 Bob Cat 1 3 3 Cat 2 Main St 2017-03-01 1 Bob Cat 2 4 4 Dan Sr 3 Main St 1970-04-01 2 Dan Sr Dan 3 rd 3 5 5 Dan Jr 3 Main St 2001-04-01 2 Dan Sr Dan 3 rd 4 6 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr Dan 3 rd 5 List Window Functions \u00b6 Here is a list from Postgres docs of all the window functions. In addition to these, any regular aggregate function can be use within a window. Function Description row_number() number of the current row within its partition, counting from 1 rank() rank of the current row with gaps; same as row_number of its first peer dense_rank() rank of the current row without gaps; this function counts peer groups percent_rank() relative rank of the current row: (rank - 1) / (total rows - 1) cume_dist() relative rank of the current row: (number of rows preceding or peer with current row) / (total rows) ntile integer ranging from 1 to the argument value, dividing the partition as equally as possible lag() returns value evaluated at the row that is offset rows before the current row within the partition; if there is no such row, instead return default (which must be of the same type as value). Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null lead() returns value evaluated at the row that is offset rows after the current row within the partition; if there is no such row, instead return default (which must be of the same type as value). Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null first_value() returns value evaluated at the row that is the first row of the window frame last_value() returns value evaluated at the row that is the last row of the window frame nth_value() returns value evaluated at the row that is the nth row of the window frame (counting from 1); null if no such row References \u00b6 Postgres Window Tutorial: https://www.postgresql.org/docs/9.3/static/tutorial-window.html Postgres Window Functions: https://www.postgresql.org/docs/9.3/static/functions-window.html Postgres Window Syntax: https://www.postgresql.org/docs/9.3/static/sql-expressions.html#SYNTAX-WINDOW-FUNCTIONS","title":"What the SQL?!? WINDOW"},{"location":"blog/2017/what-the-sql-window/#what-the-sql-window","text":"Today's \"What the SQL?!?\" features the keyword WINDOW . This clause allows us to elegantly select results from the previous results from the previous results from the previous results... Please note, our target database is PostgreSQL. These examples may work with other databases, but might need some massaging to get them to work properly. Search online for the specific vendor's documentation if errors pop up. Try searching for \"WINDOW queries $DB_VENDOR_NAME\". Not all database vendors support the keyword WINDOW .","title":"What the SQL?!? WINDOW"},{"location":"blog/2017/what-the-sql-window/#create-sample-data","text":"DROP TABLE IF EXISTS sample_moves ; CREATE TABLE sample_moves AS SELECT column1 :: int AS id , column2 :: varchar AS name , column3 :: varchar AS address , column4 :: date AS moved_at FROM ( VALUES ( 1 , 'Alice' , '1 Main St' , '2017-01-01' ), ( 2 , 'Bob' , '2 Main St' , '2017-02-01' ), ( 3 , 'Cat' , '2 Main St' , '2017-03-01' ), ( 4 , 'Dan Sr' , '3 Main St' , '1970-04-01' ), ( 5 , 'Dan Jr' , '3 Main St' , '2001-04-01' ), ( 6 , 'Dan 3rd' , '3 Main St' , '2017-04-01' ) ) as t ; CREATE INDEX ON sample_moves ( address ); SELECT * FROM sample_moves ;","title":"Create Sample Data"},{"location":"blog/2017/what-the-sql-window/#results","text":"id name address moved_at 1 Alice 1 Main St 2017-01-01 2 Bob 2 Main St 2017-02-01 3 Cat 2 Main St 2017-03-01 4 Dan Sr 3 Main St 1970-04-01 5 Dan Jr 3 Main St 2001-04-01 6 Dan 3 rd 3 Main St 2017-04-01","title":"Results:"},{"location":"blog/2017/what-the-sql-window/#life-without-windows","text":"A quick poem... Eyes big and wide, nothing seen inside. Feeling around nothing abound. This things wet, toxic I bet. Closing my eyes, still can't rest. Having a window, would be best.","title":"Life Without Windows"},{"location":"blog/2017/what-the-sql-window/#how-many-people-live-at-each-address","text":"Using a standard GROUP BY with COUNT we consolidate the records and count how many rows belong to each address. Tip : COUNT(1) is more efficient than COUNT(*) . SELECT address , COUNT ( 1 ) total FROM sample_moves GROUP BY address ORDER BY address ;","title":"How many people live at each address?"},{"location":"blog/2017/what-the-sql-window/#results_1","text":"address total 1 Main St 1 2 Main St 2 3 Main St 3","title":"Results:"},{"location":"blog/2017/what-the-sql-window/#how-many-people-live-with-each-person","text":"Enter subquery land. Life without windows is not exciting. SELECT * , ( SELECT -- everyone at the address, minus the person COUNT ( 1 ) - 1 FROM sample_moves t2 WHERE t2 . address = t1 . address ) AS others FROM sample_moves t1 ;","title":"How many people live with each person?"},{"location":"blog/2017/what-the-sql-window/#results_2","text":"id name address moved_at others 1 Alice 1 Main St 2017-01-01 0 2 Bob 2 Main St 2017-02-01 1 3 Cat 2 Main St 2017-03-01 1 4 Dan Sr 3 Main St 1970-04-01 2 5 Dan Jr 3 Main St 2001-04-01 2 6 Dan 3 rd 3 Main St 2017-04-01 2","title":"Results:"},{"location":"blog/2017/what-the-sql-window/#join-works-too","text":"SELECT t1 . * , t2 . others FROM sample_moves t1 JOIN ( SELECT address , COUNT ( 1 ) - 1 as others FROM sample_moves GROUP BY address ORDER BY address ) t2 USING ( address );","title":"JOIN works, too"},{"location":"blog/2017/what-the-sql-window/#and-so-does-join-lateral","text":"SELECT t1 . * , t2 . others FROM sample_moves t1 JOIN LATERAL ( SELECT address , COUNT ( 1 ) - 1 as others FROM sample_moves sub WHERE sub . address = t1 . address GROUP BY address ORDER BY address ) t2 ON true ;","title":"And so does JOIN LATERAL"},{"location":"blog/2017/what-the-sql-window/#thats-nice-but-who-moved-in-first","text":"SELECT * , ( SELECT COUNT ( 1 ) - 1 FROM sample_moves t2 WHERE t2 . address = t1 . address ) AS others , ( SELECT name FROM sample_moves t3 WHERE t3 . address = t1 . address ORDER BY moved_at ASC LIMIT 1 ) AS first_person FROM sample_moves t1 ;","title":"That's nice, but who moved in first?"},{"location":"blog/2017/what-the-sql-window/#wait-i-thought-this-was-about-windows","text":"The keyword OVER is the gateway drug into WINDOW functions. Using OVER with parenthesis is an inline window. The PARTITION BY keywords gives similar functionality to GROUP BY and JOIN ... USING all in one power packed statement. It can never reduce the number of records in a result set which is the same behavior expected of a correlated subquery. PARTITION BY is treated the same as the traditional GROUP BY . The ORDER BY also has the same behavior as its use in a standard query. SELECT * , ( count ( 1 ) OVER ( PARTITION BY address )) - 1 AS others , first_value ( name ) OVER ( PARTITION BY address ORDER BY moved_at ) AS first_moved FROM sample_moves ;","title":"Wait I thought this was about windows?!?"},{"location":"blog/2017/what-the-sql-window/#results_3","text":"id name address moved_at others first_moved 1 Alice 1 Main St 2017-01-01 0 Alice 2 Bob 2 Main St 2017-02-01 1 Bob 3 Cat 2 Main St 2017-03-01 1 Bob 4 Dan Sr 3 Main St 1970-04-01 2 Dan Sr 5 Dan Jr 3 Main St 2001-04-01 2 Dan Sr 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr A picture with arrows worth a thousand words:","title":"Results"},{"location":"blog/2017/what-the-sql-window/#that-doesnt-look-very-dry-finally-a-window","text":"The WINDOW keyword allows us to alias the options of the OVER clause. Namely the expression (...) between and including the parenthesis. In the following example we add the use of RANGE to provide additional direction to the windowing clause. SELECT * , ( count ( 1 ) OVER w ) - 1 AS others , first_value ( name ) OVER w AS first_moved , last_value ( name ) OVER w AS last_moved FROM sample_moves WINDOW w AS ( PARTITION BY address ORDER BY moved_at RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING );","title":"That doesn't look very DRY. Finally, a WINDOW"},{"location":"blog/2017/what-the-sql-window/#results_4","text":"id name address moved_at others first_moved last_moved 1 Alice 1 Main St 2017-01-01 0 Alice Alice 2 Bob 2 Main St 2017-02-01 0 Bob Bob 3 Cat 2 Main St 2017-03-01 1 Bob Cat 4 Dan Sr 3 Main St 1970-04-01 0 Dan Sr Dan Sr 5 Dan Jr 3 Main St 2001-04-01 1 Dan Sr Dan Jr 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr Dan 3 rd -- Previous and Next Record SELECT * , ( count ( 1 ) OVER w ) - 1 AS others , first_value ( name ) OVER w AS first_moved , last_value ( name ) OVER w AS last_moved , lag ( id ) OVER ( ORDER BY id ) AS prev_id , lead ( id ) OVER ( ORDER BY id ) AS next_id FROM sample_moves WINDOW w AS ( PARTITION BY address ORDER BY moved_at RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) ORDER BY address ;","title":"Results"},{"location":"blog/2017/what-the-sql-window/#results_5","text":"id name address moved_at others first_moved last_moved prev_id next_id 1 Alice 1 Main St 2017-01-01 0 Alice Alice 2 2 Bob 2 Main St 2017-02-01 1 Bob Cat 1 3 3 Cat 2 Main St 2017-03-01 1 Bob Cat 2 4 4 Dan Sr 3 Main St 1970-04-01 2 Dan Sr Dan 3 rd 3 5 5 Dan Jr 3 Main St 2001-04-01 2 Dan Sr Dan 3 rd 4 6 6 Dan 3 rd 3 Main St 2017-04-01 2 Dan Sr Dan 3 rd 5","title":"Results"},{"location":"blog/2017/what-the-sql-window/#list-window-functions","text":"Here is a list from Postgres docs of all the window functions. In addition to these, any regular aggregate function can be use within a window. Function Description row_number() number of the current row within its partition, counting from 1 rank() rank of the current row with gaps; same as row_number of its first peer dense_rank() rank of the current row without gaps; this function counts peer groups percent_rank() relative rank of the current row: (rank - 1) / (total rows - 1) cume_dist() relative rank of the current row: (number of rows preceding or peer with current row) / (total rows) ntile integer ranging from 1 to the argument value, dividing the partition as equally as possible lag() returns value evaluated at the row that is offset rows before the current row within the partition; if there is no such row, instead return default (which must be of the same type as value). Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null lead() returns value evaluated at the row that is offset rows after the current row within the partition; if there is no such row, instead return default (which must be of the same type as value). Both offset and default are evaluated with respect to the current row. If omitted, offset defaults to 1 and default to null first_value() returns value evaluated at the row that is the first row of the window frame last_value() returns value evaluated at the row that is the last row of the window frame nth_value() returns value evaluated at the row that is the nth row of the window frame (counting from 1); null if no such row","title":"List Window Functions"},{"location":"blog/2017/what-the-sql-window/#references","text":"Postgres Window Tutorial: https://www.postgresql.org/docs/9.3/static/tutorial-window.html Postgres Window Functions: https://www.postgresql.org/docs/9.3/static/functions-window.html Postgres Window Syntax: https://www.postgresql.org/docs/9.3/static/sql-expressions.html#SYNTAX-WINDOW-FUNCTIONS","title":"References"},{"location":"blog/2018/blog-setup/","text":"Dev Blog Tools :: A Quick Tour of My Setup \u00b6 I've been asked to share about my blogging setup a few times, so in the spirit of keeping things DRY , it's time to make a post about it. TL;DR -- Mac, iTerm, NeoVim, LICEcap, Octopress, Base16, Input Font, Skitch, OBS WARNING This is an atypical post. I normally prefer to go over a single feature, but this time I'm going to under explain a lot of features. Here's a short list of typical posts in case chaos is not your thing: https://ddrscott.github.io/blog/2017/vim-send-text/ https://ddrscott.github.io/blog/2017/what-the-sql-lateral/ https://ddrscott.github.io/blog/2016/negative-modulo/ Computer \u00b6 I do all my writing and coding on a MacBook Pro Retina 15 inch. It's pretty maxed out, but I don't think it needs to be that way. The only stats I really care about are the size and the clarity of the screen. Terminal \u00b6 I like to live in a terminal. I choose iTerm2 for it's split panes and independent font size per pane. At times I wish it was as fast as the native Terminal.app, but it doesn't support splits. I've been told many times that tmux supports splits, too, but I can't change the text size independently between splits. I'd also rather use GNU screen anyway. Old timers like old things\u2122 Editor \u00b6 NeoVim is always loaded in one of my terminal panes. It's the most efficient editor for me. I switched away from Vim 7 because it couldn't do background jobs. Prior to Vim I used RubyMine and IntelliJ which were great for code completion and navigating projects, but felt heavy for notes, free form writing, and editing system files. I'll save the rest of the Vim sermon for another post. When composing posts, I use vim-markdown to get syntax highlighting, folding, TOC, and other goodies. My entire NeoVim config can be found in its Github repository . I don't recommend folks using it outright, but borrow parts if it and slowly integrate it into their own setup. One size doesn't fit all. It barely fits me! Colors \u00b6 I lived in Solarized Dark for many years. It is so common place in development shops it became the new green screen of the 70's and 80's. So when folks see yellow and green highlights against an off-black chalkboard beaming from my terminal, there's pause and self reflection. They wonder how they were nestled into a monotonous monoculture. They ponder when they traded emotional delight for ocular comfort. They realize depression encroached silently on them like mold in a damp attic. But I digress\u2026 Here's how Base16 describes itself: An architecture for building themes based on carefully chosen syntax highlighting using a base of sixteen colours. Base16 provides a set of guidelines detailing how to style syntax and how to code a builder for compiling base16 schemes and templates. -- https://github.com/chriskempson/base16 base16-ocean is the color scheme I use. It's scheme #74 , type j or k to change the theme). The scheme is perfectly in sync between shell and Vim due to base16-shell and base16-vim . I wrote a longer post about using Base16 while back . Font \u00b6 I've been using the same code font for as long as I can remember: Input Mono Condensed. Input is a flexible system of fonts designed specifically for code by David Jonathan Ross. It offers both monospaced and proportional fonts, all with a large range of widths, weights, and styles for richer code formatting. -- Font Bureau I enjoy the fancy 'a' and 'g' characters along with easy to distinguish 'l', '1', and 'I'.(Helvetica can't do it justice.) It also has several different character width options so I can squeeze more code into one eye shot. Speaking of shots\u2026 Screenshots \u00b6 I have a few ways of taking screenshots and it's mainly the Mac way: To snap a small portion of the screen, I use \u21e7+\u2318+4 , then select region to snap. To snap a window with the shadow, I use \u21e7+\u2318+4 , then space and select a window. Apple's support page has the gruesome details on both. When I want to annotate a screenshot, I use Evernote's Skitch App . The featured image was created using a combination of OSX screenshot and then editing in Skitch . Animated Gifs and Videos \u00b6 For short demos, I like to use LICEcap to record an animated Gif. I wouldn't use Gifs for anything longer than a few seconds since it doesn't support video playback controls without extra magic. Here's an example LICEcap Gif: And here's a video of how I produced it: For full screen video record, I use OBS Studio . (You might have noticed me stopping the recording at the end of the video. Should have used a hotkey.) It produces small file sizes and has a lot of features including webcam overlays, filters, transforms, etc. It deserves a whole book of its own. Note to Self write book about OBS Studio retire Blog Generator \u00b6 I use Octopress to generate the static HTML pages you're reading now. I haven't updated it since 2014 ( SHA 71e4d40b ) and I'm terrified to do so. The setup Just Works\u2122. I write in Markdown and it does the rest. The source code for this exact post is here . That being said, I'm strongly considering switching to Mkdocs to have more structure and better search capabilities built-in. Closing \u00b6 You made it to the end! I hope at least one of these will benefit your daily computing life. Questions? Comments? Trolls?!? Let me know! Tweet Hacker News Links iTerm2 -- https://www.iterm2.com/ Tmux -- https://github.com/tmux/tmux/wiki GNU Screen -- https://www.gnu.org/software/screen/ RubyMine -- https://www.jetbrains.com/ruby/ IntelliJ -- https://www.jetbrains.com/idea/ Vim -- https://www.vim.org NeoVim -- https://neovim.io/ vim-markdown -- https://github.com/plasticboy/vim-markdown My NeoVim Config -- https://github.com/ddrscott/config-nvim base16-shell -- https://github.com/chriskempson/base16-shell base16-vim -- https://github.com/chriskempson/base16-vim base16-ocean -- http://chriskempson.com/projects/base16/ Input Font -- http://input.fontbureau.com/ Skitch -- https://evernote.com/products/skitch LICEcap -- https://www.cockos.com/licecap/ OBS Studio -- https://obsproject.com/ Octopress -- http://octopress.org/ Mkdocs -- http://www.mkdocs.org/ Edits added Hacker News link","title":"Dev Blog Tools :: A Quick Tour of My Setup"},{"location":"blog/2018/blog-setup/#dev-blog-tools-a-quick-tour-of-my-setup","text":"I've been asked to share about my blogging setup a few times, so in the spirit of keeping things DRY , it's time to make a post about it. TL;DR -- Mac, iTerm, NeoVim, LICEcap, Octopress, Base16, Input Font, Skitch, OBS WARNING This is an atypical post. I normally prefer to go over a single feature, but this time I'm going to under explain a lot of features. Here's a short list of typical posts in case chaos is not your thing: https://ddrscott.github.io/blog/2017/vim-send-text/ https://ddrscott.github.io/blog/2017/what-the-sql-lateral/ https://ddrscott.github.io/blog/2016/negative-modulo/","title":"Dev Blog Tools :: A Quick Tour of My Setup"},{"location":"blog/2018/blog-setup/#computer","text":"I do all my writing and coding on a MacBook Pro Retina 15 inch. It's pretty maxed out, but I don't think it needs to be that way. The only stats I really care about are the size and the clarity of the screen.","title":"Computer"},{"location":"blog/2018/blog-setup/#terminal","text":"I like to live in a terminal. I choose iTerm2 for it's split panes and independent font size per pane. At times I wish it was as fast as the native Terminal.app, but it doesn't support splits. I've been told many times that tmux supports splits, too, but I can't change the text size independently between splits. I'd also rather use GNU screen anyway. Old timers like old things\u2122","title":"Terminal"},{"location":"blog/2018/blog-setup/#editor","text":"NeoVim is always loaded in one of my terminal panes. It's the most efficient editor for me. I switched away from Vim 7 because it couldn't do background jobs. Prior to Vim I used RubyMine and IntelliJ which were great for code completion and navigating projects, but felt heavy for notes, free form writing, and editing system files. I'll save the rest of the Vim sermon for another post. When composing posts, I use vim-markdown to get syntax highlighting, folding, TOC, and other goodies. My entire NeoVim config can be found in its Github repository . I don't recommend folks using it outright, but borrow parts if it and slowly integrate it into their own setup. One size doesn't fit all. It barely fits me!","title":"Editor"},{"location":"blog/2018/blog-setup/#colors","text":"I lived in Solarized Dark for many years. It is so common place in development shops it became the new green screen of the 70's and 80's. So when folks see yellow and green highlights against an off-black chalkboard beaming from my terminal, there's pause and self reflection. They wonder how they were nestled into a monotonous monoculture. They ponder when they traded emotional delight for ocular comfort. They realize depression encroached silently on them like mold in a damp attic. But I digress\u2026 Here's how Base16 describes itself: An architecture for building themes based on carefully chosen syntax highlighting using a base of sixteen colours. Base16 provides a set of guidelines detailing how to style syntax and how to code a builder for compiling base16 schemes and templates. -- https://github.com/chriskempson/base16 base16-ocean is the color scheme I use. It's scheme #74 , type j or k to change the theme). The scheme is perfectly in sync between shell and Vim due to base16-shell and base16-vim . I wrote a longer post about using Base16 while back .","title":"Colors"},{"location":"blog/2018/blog-setup/#font","text":"I've been using the same code font for as long as I can remember: Input Mono Condensed. Input is a flexible system of fonts designed specifically for code by David Jonathan Ross. It offers both monospaced and proportional fonts, all with a large range of widths, weights, and styles for richer code formatting. -- Font Bureau I enjoy the fancy 'a' and 'g' characters along with easy to distinguish 'l', '1', and 'I'.(Helvetica can't do it justice.) It also has several different character width options so I can squeeze more code into one eye shot. Speaking of shots\u2026","title":"Font"},{"location":"blog/2018/blog-setup/#screenshots","text":"I have a few ways of taking screenshots and it's mainly the Mac way: To snap a small portion of the screen, I use \u21e7+\u2318+4 , then select region to snap. To snap a window with the shadow, I use \u21e7+\u2318+4 , then space and select a window. Apple's support page has the gruesome details on both. When I want to annotate a screenshot, I use Evernote's Skitch App . The featured image was created using a combination of OSX screenshot and then editing in Skitch .","title":"Screenshots"},{"location":"blog/2018/blog-setup/#animated-gifs-and-videos","text":"For short demos, I like to use LICEcap to record an animated Gif. I wouldn't use Gifs for anything longer than a few seconds since it doesn't support video playback controls without extra magic. Here's an example LICEcap Gif: And here's a video of how I produced it: For full screen video record, I use OBS Studio . (You might have noticed me stopping the recording at the end of the video. Should have used a hotkey.) It produces small file sizes and has a lot of features including webcam overlays, filters, transforms, etc. It deserves a whole book of its own. Note to Self write book about OBS Studio retire","title":"Animated Gifs and Videos"},{"location":"blog/2018/blog-setup/#blog-generator","text":"I use Octopress to generate the static HTML pages you're reading now. I haven't updated it since 2014 ( SHA 71e4d40b ) and I'm terrified to do so. The setup Just Works\u2122. I write in Markdown and it does the rest. The source code for this exact post is here . That being said, I'm strongly considering switching to Mkdocs to have more structure and better search capabilities built-in.","title":"Blog Generator"},{"location":"blog/2018/blog-setup/#closing","text":"You made it to the end! I hope at least one of these will benefit your daily computing life. Questions? Comments? Trolls?!? Let me know! Tweet Hacker News Links iTerm2 -- https://www.iterm2.com/ Tmux -- https://github.com/tmux/tmux/wiki GNU Screen -- https://www.gnu.org/software/screen/ RubyMine -- https://www.jetbrains.com/ruby/ IntelliJ -- https://www.jetbrains.com/idea/ Vim -- https://www.vim.org NeoVim -- https://neovim.io/ vim-markdown -- https://github.com/plasticboy/vim-markdown My NeoVim Config -- https://github.com/ddrscott/config-nvim base16-shell -- https://github.com/chriskempson/base16-shell base16-vim -- https://github.com/chriskempson/base16-vim base16-ocean -- http://chriskempson.com/projects/base16/ Input Font -- http://input.fontbureau.com/ Skitch -- https://evernote.com/products/skitch LICEcap -- https://www.cockos.com/licecap/ OBS Studio -- https://obsproject.com/ Octopress -- http://octopress.org/ Mkdocs -- http://www.mkdocs.org/ Edits added Hacker News link","title":"Closing"},{"location":"blog/2018/getting-rusty-with-vim/","text":"Getting Rusty with Vim \u00b6 After dabbing in Go and Crystal, I figured I'd give Rust a try. Of course I used Vim along the way. Here are some notes I compiled after my first session. Vim Setup \u00b6 There are 2 excellent Vim plugins which play nice with Rust. First is https://github.com/rust-lang/rust.vim which provides: ... Rust file detection, syntax highlighting, formatting, Syntastic integration, and more. It has nearly 1k stars, one of which is from me, and it's triple the stars of rust-mode for Emacs. The second plugin is https://github.com/racer-rust/vim-racer which provides omni-complete and jump to definition. Both features are good enough that I don't need to use ctags. I've in fact overridden several default Vim mappings with vim-racer implementations: au FileType rust nmap < silent > < C - ] > < Plug >( rust - def ) au FileType rust nmap < silent > < C - w >< C - ] > < Plug >( rust - def - vertical ) au FileType rust nmap < silent > < C - w > } < Plug >( rust - def - split ) au FileType rust nmap < silent > < C - k > < Plug >( rust - doc ) Rust Experience \u00b6 The featured image is an implementation of a number guessing game. The game is from the Rust Tutorial Guide at https://doc.rust-lang.org/book/first-edition/guessing-game.html . I followed the guide sentence by sentence, line by line, and everything worked without additional troubleshooting sessions. Good Job @rustlang ! I massaged the code a little more to fool around and came up with the code in the featured screen shot. The source is available in this gist . It's not the most exciting code I've ever written, but possibly the most painless of the new languages I've tried. When I came across some confusing language decisions. I posted a tweet about it: Rust has clever tuple indexing, but square brackets would have been fine. What's wrong with `tuple[0]`? #rustlang pic.twitter.com/E0VY70zxuV \u2014 Scott Pierce (@_ddrscott_) March 3, 2018 @rustlang responded quickly with insightful information. They're totally getting the Raving Fan Award this weekend! Conclusion \u00b6 Rust is worth pursing with or without Vim. The feedback from the compiler and runtime errors is clear. The racer-rust completion utility gives all IDE super powers. And finally, I hear it's a pretty good language, too. https://www.rust-lang.org","title":"Getting Rusty with Vim"},{"location":"blog/2018/getting-rusty-with-vim/#getting-rusty-with-vim","text":"After dabbing in Go and Crystal, I figured I'd give Rust a try. Of course I used Vim along the way. Here are some notes I compiled after my first session.","title":"Getting Rusty with Vim"},{"location":"blog/2018/getting-rusty-with-vim/#vim-setup","text":"There are 2 excellent Vim plugins which play nice with Rust. First is https://github.com/rust-lang/rust.vim which provides: ... Rust file detection, syntax highlighting, formatting, Syntastic integration, and more. It has nearly 1k stars, one of which is from me, and it's triple the stars of rust-mode for Emacs. The second plugin is https://github.com/racer-rust/vim-racer which provides omni-complete and jump to definition. Both features are good enough that I don't need to use ctags. I've in fact overridden several default Vim mappings with vim-racer implementations: au FileType rust nmap < silent > < C - ] > < Plug >( rust - def ) au FileType rust nmap < silent > < C - w >< C - ] > < Plug >( rust - def - vertical ) au FileType rust nmap < silent > < C - w > } < Plug >( rust - def - split ) au FileType rust nmap < silent > < C - k > < Plug >( rust - doc )","title":"Vim Setup"},{"location":"blog/2018/getting-rusty-with-vim/#rust-experience","text":"The featured image is an implementation of a number guessing game. The game is from the Rust Tutorial Guide at https://doc.rust-lang.org/book/first-edition/guessing-game.html . I followed the guide sentence by sentence, line by line, and everything worked without additional troubleshooting sessions. Good Job @rustlang ! I massaged the code a little more to fool around and came up with the code in the featured screen shot. The source is available in this gist . It's not the most exciting code I've ever written, but possibly the most painless of the new languages I've tried. When I came across some confusing language decisions. I posted a tweet about it: Rust has clever tuple indexing, but square brackets would have been fine. What's wrong with `tuple[0]`? #rustlang pic.twitter.com/E0VY70zxuV \u2014 Scott Pierce (@_ddrscott_) March 3, 2018 @rustlang responded quickly with insightful information. They're totally getting the Raving Fan Award this weekend!","title":"Rust Experience"},{"location":"blog/2018/getting-rusty-with-vim/#conclusion","text":"Rust is worth pursing with or without Vim. The feedback from the compiler and runtime errors is clear. The racer-rust completion utility gives all IDE super powers. And finally, I hear it's a pretty good language, too. https://www.rust-lang.org","title":"Conclusion"},{"location":"blog/2018/join-me-at-union-station/","text":"What the SQL?! JOIN me at UNION Station \u00b6 JOIN and UNION are staples in SQL. In English they're synonyms to each other, but in SQL they behave very differently. They work in different directions. TL;DR - Use JOIN to add columns. Use UNION to add rows. According to Wikipedia a JOIN is: An SQL join clause combines columns from one or more tables in a relational database. It creates a set that can be saved as a table or used as it is. A JOIN is a means for combining columns from one (self-join) or more tables by using values common to each. ANSI-standard SQL specifies five types of JOIN: INNER, LEFT OUTER, RIGHT OUTER, FULL OUTER and CROSS. As a special case, a table (base table, view, or joined table) can JOIN to itself in a self-join. -- https://en.wikipedia.org/wiki/Join_(SQL ) And here's their definition for UNION : In SQL the UNION clause combines the results of two SQL queries into a single table of all matching rows. The two queries must result in the same number of columns and compatible data types in order to unite -- https://en.wikipedia.org/wiki/Set_operations_(SQL)#UNION_operator Memory Tip UNION adds rows UNder the results. JOIN has not tip, but it's not a UNION . Data Setup \u00b6 We're going to use a 2 table database. People belong to a zip code and zip codes have a named region. Schema CREATE TABLE people AS SELECT * FROM ( VALUES ( 1 , 'Candy' , '60001' ), ( 2 , 'Mandy' , '70001' ), ( 3 , 'Randy' , '80001' ), ( 4 , 'Andy' , '89991' ) ) AS t ( id , name , zip_code ); CREATE TABLE zip_codes AS SELECT * FROM ( VALUES ( '60001' , 'North' ), ( '70001' , 'South' ), ( '80001' , 'East' ), ( '90001' , 'West' ) ) AS t ( code , region ); JOIN Problems \u00b6 The best time to use a JOIN is when we need to show a column from another table which correlates to a column from a previously declared table. Problem : The Sales Team would like a list of people's names with their regions. Create a query with each person correlated to the zip code region ? Solution SELECT people . id , people . name , people . zip_code , zip_codes . region FROM people JOIN zip_codes ON zip_codes . code = people . zip_code ; id name zip_code region 1 Candy 60001 North 2 Mandy 70001 South 3 Randy 80001 East Problem : List all the people who belong to an unknown zip code? Solution SELECT people . id , people . name , people . zip_code , zip_codes . region FROM people LEFT JOIN zip_codes ON zip_codes . code = people . zip_code WHERE zip_codes . code IS NULL ; id name zip_code region 4 Andy 89991 JOIN Notes \u00b6 INNER JOIN and JOIN are interpreted identically. The later saves typing 6 characters. INNER JOIN is great for finding correlation, but bad for finding unmatched records. LEFT JOIN tells the query engine we want to return all data on the LEFT or earlier tables even though the correlated value doesn't exist. RIGHT JOIN is the opposite of LEFT . They retain rows from tables mentioned later in the query. Mixing LEFT JOIN with RIGHT JOIN in the same query should be avoided. The WHERE condition states we only want the uncorrelated rows, the people missing a zip_codes record. UNION Problems \u00b6 The UNION clause allows us to conform 2 or more unrelated results into a single uniform results. Problem The search department wants a list of all keywords for their search index. Return a list of keywords from both the people and the zip code tables. Solution SELECT name AS keyword FROM people UNION SELECT region FROM zip_codes ; keyword East North South Mandy Candy Randy Andy West Problem The search department likes the results, but wants to be able to correlate the row back to its source table and row. Solution SELECT 'people' AS source , id :: varchar AS key , name AS keyword FROM people UNION SELECT 'zip_codes' , code , region FROM zip_codes ORDER BY 1 , 2 , 3 ; source key keyword people 1 Candy people 2 Mandy people 3 Randy people 4 Andy zip_codes 60001 North zip_codes 70001 South zip_codes 80001 East zip_codes 90001 West UNION Notes \u00b6 The UNION clause requires all the columns from its sub queries to be the same number and type. This is why ::varchar casting was added. UNION defaults to only returning distinct rows between the result sets. If you want all rows regardless of duplicates try UNION ALL . ORDER BY with UNION works on the final results. When ordering is needed within a sub query use parenthesis. Ex: UNION (SELECT ... ORDER BY ... LIMIT 1) Bonus Problem \u00b6 Return the people with invalid zip codes without using JOIN . Hints: EXCEPT is the inverse of a UNION . EXCEPT removes the results from the source query instead of appending them. IN can be used as a matching clause in a WHERE filter. Solution SELECT people . * FROM people WHERE zip_code IN ( SELECT zip_code FROM people EXCEPT SELECT code FROM zip_codes ); id name zip_code 4 Andy 89991 Closing \u00b6 Clean Up DROP TABLE people ; DROP TABLE zip_codes ; JOIN and UNION are an essential part of a SQL users tool belt. On a day to day basis, JOIN is used more often than UNION , so we would recommend understanding it first. UNION gets it power when we realize our data is more alike than originally intended. Both clauses should be withheld at dinner parties and other social events. Happy SQL-ing!","title":"What the SQL?! JOIN me at UNION Station"},{"location":"blog/2018/join-me-at-union-station/#what-the-sql-join-me-at-union-station","text":"JOIN and UNION are staples in SQL. In English they're synonyms to each other, but in SQL they behave very differently. They work in different directions. TL;DR - Use JOIN to add columns. Use UNION to add rows. According to Wikipedia a JOIN is: An SQL join clause combines columns from one or more tables in a relational database. It creates a set that can be saved as a table or used as it is. A JOIN is a means for combining columns from one (self-join) or more tables by using values common to each. ANSI-standard SQL specifies five types of JOIN: INNER, LEFT OUTER, RIGHT OUTER, FULL OUTER and CROSS. As a special case, a table (base table, view, or joined table) can JOIN to itself in a self-join. -- https://en.wikipedia.org/wiki/Join_(SQL ) And here's their definition for UNION : In SQL the UNION clause combines the results of two SQL queries into a single table of all matching rows. The two queries must result in the same number of columns and compatible data types in order to unite -- https://en.wikipedia.org/wiki/Set_operations_(SQL)#UNION_operator Memory Tip UNION adds rows UNder the results. JOIN has not tip, but it's not a UNION .","title":"What the SQL?! JOIN me at UNION Station"},{"location":"blog/2018/join-me-at-union-station/#data-setup","text":"We're going to use a 2 table database. People belong to a zip code and zip codes have a named region. Schema CREATE TABLE people AS SELECT * FROM ( VALUES ( 1 , 'Candy' , '60001' ), ( 2 , 'Mandy' , '70001' ), ( 3 , 'Randy' , '80001' ), ( 4 , 'Andy' , '89991' ) ) AS t ( id , name , zip_code ); CREATE TABLE zip_codes AS SELECT * FROM ( VALUES ( '60001' , 'North' ), ( '70001' , 'South' ), ( '80001' , 'East' ), ( '90001' , 'West' ) ) AS t ( code , region );","title":"Data Setup"},{"location":"blog/2018/join-me-at-union-station/#join-problems","text":"The best time to use a JOIN is when we need to show a column from another table which correlates to a column from a previously declared table. Problem : The Sales Team would like a list of people's names with their regions. Create a query with each person correlated to the zip code region ? Solution SELECT people . id , people . name , people . zip_code , zip_codes . region FROM people JOIN zip_codes ON zip_codes . code = people . zip_code ; id name zip_code region 1 Candy 60001 North 2 Mandy 70001 South 3 Randy 80001 East Problem : List all the people who belong to an unknown zip code? Solution SELECT people . id , people . name , people . zip_code , zip_codes . region FROM people LEFT JOIN zip_codes ON zip_codes . code = people . zip_code WHERE zip_codes . code IS NULL ; id name zip_code region 4 Andy 89991","title":"JOIN Problems"},{"location":"blog/2018/join-me-at-union-station/#join-notes","text":"INNER JOIN and JOIN are interpreted identically. The later saves typing 6 characters. INNER JOIN is great for finding correlation, but bad for finding unmatched records. LEFT JOIN tells the query engine we want to return all data on the LEFT or earlier tables even though the correlated value doesn't exist. RIGHT JOIN is the opposite of LEFT . They retain rows from tables mentioned later in the query. Mixing LEFT JOIN with RIGHT JOIN in the same query should be avoided. The WHERE condition states we only want the uncorrelated rows, the people missing a zip_codes record.","title":"JOIN Notes"},{"location":"blog/2018/join-me-at-union-station/#union-problems","text":"The UNION clause allows us to conform 2 or more unrelated results into a single uniform results. Problem The search department wants a list of all keywords for their search index. Return a list of keywords from both the people and the zip code tables. Solution SELECT name AS keyword FROM people UNION SELECT region FROM zip_codes ; keyword East North South Mandy Candy Randy Andy West Problem The search department likes the results, but wants to be able to correlate the row back to its source table and row. Solution SELECT 'people' AS source , id :: varchar AS key , name AS keyword FROM people UNION SELECT 'zip_codes' , code , region FROM zip_codes ORDER BY 1 , 2 , 3 ; source key keyword people 1 Candy people 2 Mandy people 3 Randy people 4 Andy zip_codes 60001 North zip_codes 70001 South zip_codes 80001 East zip_codes 90001 West","title":"UNION Problems"},{"location":"blog/2018/join-me-at-union-station/#union-notes","text":"The UNION clause requires all the columns from its sub queries to be the same number and type. This is why ::varchar casting was added. UNION defaults to only returning distinct rows between the result sets. If you want all rows regardless of duplicates try UNION ALL . ORDER BY with UNION works on the final results. When ordering is needed within a sub query use parenthesis. Ex: UNION (SELECT ... ORDER BY ... LIMIT 1)","title":"UNION Notes"},{"location":"blog/2018/join-me-at-union-station/#bonus-problem","text":"Return the people with invalid zip codes without using JOIN . Hints: EXCEPT is the inverse of a UNION . EXCEPT removes the results from the source query instead of appending them. IN can be used as a matching clause in a WHERE filter. Solution SELECT people . * FROM people WHERE zip_code IN ( SELECT zip_code FROM people EXCEPT SELECT code FROM zip_codes ); id name zip_code 4 Andy 89991","title":"Bonus Problem"},{"location":"blog/2018/join-me-at-union-station/#closing","text":"Clean Up DROP TABLE people ; DROP TABLE zip_codes ; JOIN and UNION are an essential part of a SQL users tool belt. On a day to day basis, JOIN is used more often than UNION , so we would recommend understanding it first. UNION gets it power when we realize our data is more alike than originally intended. Both clauses should be withheld at dinner parties and other social events. Happy SQL-ing!","title":"Closing"},{"location":"blog/2018/move-to-mkdocs/","text":"I've upgraded to MkDocs from Octopress . The Octopress installation I've been using was from 2014 (4 years old) and was missing features for search, long form writing, multi-part posts, and books. http://www.mkdocs.org/ MkDocs is a fast , simple and downright gorgeous static site generator that's geared towards building project documentation. Documentation source files are written in Markdown, and configured with a single YAML configuration file. Features \u00b6 To see all the features of MkDocs and mkdocs-material jump to their respective sites. Here's the features really care about: Transition \u00b6 The migration process wasn't as easy as I'd hoped. I wanted all the old posts to move over, but there wasn't an easy path for my content prior to 2014. That's because some of those posts are in pure html and MkDocs only wants to deal in Markdown. I tried Pandoc , but that created Markdown which isn't compatible with MkDocs . It'll take some time before all that old stuff gets through. Fortunately, because it's so old, most of the material isn't relevant anymore and gets very few hits. MkDocs doesn't build the site hierarchy automatically like Octopress . Octopress stores all article in a flat directory with file names prefixed with a date. MkDocs uses the file name as part of the URL, so I needed to rename the Octopress files and put them in a directory structure to match the URL format I had in the original site. Octopress Posts Directory : \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 _posts \u2502 \u2502 \u251c\u2500\u2500 2016-05-28-negative-modulo.markdown \u2502 \u2502 \u251c\u2500\u2500 2016-07-11-photography-lightening-talk.markdown \u2502 \u2502 \u251c\u2500\u2500 2016-07-26-ansi-codes-with-character.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-02-07-how-to-get-better-at-anything.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-08-what-the-sql-lateral.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-15-what-the-sql-recursive.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-22-what-the-sql-window.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-04-10-vim-send-text.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-04-13-base16-shell.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-06-01-gnu-screen.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-06-12-fzf-dictionary.markdown \u2502 \u2502 \u251c\u2500\u2500 2018-03-04-getting-rusty-with-vim.markdown \u2502 \u2502 \u251c\u2500\u2500 2018-03-12-stream-stats-in-rust.markdown \u2502 \u2502 \u2514\u2500\u2500 2018-03-22-blog-setup.markdown MkDocs Docs Directory : \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 blog \u2502 \u2502 \u251c\u2500\u2500 2016 \u2502 \u2502 \u2502 \u251c\u2500\u2500 negative-modulo.markdown \u2502 \u2502 \u2502 \u2514\u2500\u2500 yank-without-jank.markdown \u2502 \u2502 \u251c\u2500\u2500 2017 \u2502 \u2502 \u2502 \u251c\u2500\u2500 base16-shell.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 fzf-dictionary.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 gnu-screen.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 how-to-get-better-at-anything.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 vim-send-text.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 what-the-sql-lateral.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 what-the-sql-recursive.markdown \u2502 \u2502 \u2502 \u2514\u2500\u2500 what-the-sql-window.markdown \u2502 \u2502 \u2514\u2500\u2500 2018 \u2502 \u2502 \u251c\u2500\u2500 blog-setup.markdown \u2502 \u2502 \u251c\u2500\u2500 getting-rusty-with-vim.markdown \u2502 \u2502 \u251c\u2500\u2500 move-to-mkdocs.markdown \u2502 \u2502 \u2514\u2500\u2500 stream-stats-in-rust.markdown After getting the files to the correct directory, the site hierarchy needs to be configured in mkdocs.yml . That file contains much more than the page structure. You'll need to read more about it from their documentation . mkdocs.yml : # .. stuff before this section .. pages : - Home : index.md - Projects : projects.md - '2018' : - 'Move to MkDocs' : blog/2018/move-to-mkdocs.markdown - 'A Rustic Journey Through Stream Stats' : blog/2018/stream-stats-in-rust.markdown - 'Getting Rusty with Vim' : blog/2018/getting-rusty-with-vim.markdown - 'Dev Blog Tools :: A Quick Tour of My Setup' : blog/2018/blog-setup.markdown - '2017' : - 'Base16 Shell' : blog/2017/base16-shell.markdown - 'How to Get Better At Anything' : blog/2017/how-to-get-better-at-anything.markdown - 'FZF + WordNet = Dictionary' : blog/2017/fzf-dictionary.markdown - 'GNU Screen' : blog/2017/gnu-screen.markdown - 'What the SQL?!? Lateral Joins' : blog/2017/what-the-sql-lateral.markdown - 'What the SQL?!? WINDOW' : blog/2017/what-the-sql-window.markdown - 'What the SQL?!? Recursive' : blog/2017/what-the-sql-recursive.markdown - 'Vim Send Text' : blog/2017/vim-send-text.markdown # .. more stuff .. Once mkdocs.yml is configured we can run: # start a web server to preview the site mkdocs server # or generate the site files for deployment mkdocs build # or deploy to GitHub Pages mkdocs gh-deploy Conclusion \u00b6 Here's a breakdown of the pros and cons that I've experienced so far: Pros \u00b6 Full site search without using external service (Google, Angola, etc.) Site hierarchy. Automatic table of contents on all pages. Various code blocks and annotations. Less magic. Cons \u00b6 Older posts don't translate well, because they have to be in Markdown format. MkDocs is a Python project, a language I'm not familiar with, yet. Less magic. Hopefully this the catalyst to more content. Stay tuned! Questions? Comments? Trolls?!? Let me know! Tweet","title":"Move to MkDocs"},{"location":"blog/2018/move-to-mkdocs/#features","text":"To see all the features of MkDocs and mkdocs-material jump to their respective sites. Here's the features really care about:","title":"Features"},{"location":"blog/2018/move-to-mkdocs/#transition","text":"The migration process wasn't as easy as I'd hoped. I wanted all the old posts to move over, but there wasn't an easy path for my content prior to 2014. That's because some of those posts are in pure html and MkDocs only wants to deal in Markdown. I tried Pandoc , but that created Markdown which isn't compatible with MkDocs . It'll take some time before all that old stuff gets through. Fortunately, because it's so old, most of the material isn't relevant anymore and gets very few hits. MkDocs doesn't build the site hierarchy automatically like Octopress . Octopress stores all article in a flat directory with file names prefixed with a date. MkDocs uses the file name as part of the URL, so I needed to rename the Octopress files and put them in a directory structure to match the URL format I had in the original site. Octopress Posts Directory : \u251c\u2500\u2500 source \u2502 \u251c\u2500\u2500 _posts \u2502 \u2502 \u251c\u2500\u2500 2016-05-28-negative-modulo.markdown \u2502 \u2502 \u251c\u2500\u2500 2016-07-11-photography-lightening-talk.markdown \u2502 \u2502 \u251c\u2500\u2500 2016-07-26-ansi-codes-with-character.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-02-07-how-to-get-better-at-anything.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-08-what-the-sql-lateral.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-15-what-the-sql-recursive.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-03-22-what-the-sql-window.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-04-10-vim-send-text.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-04-13-base16-shell.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-06-01-gnu-screen.markdown \u2502 \u2502 \u251c\u2500\u2500 2017-06-12-fzf-dictionary.markdown \u2502 \u2502 \u251c\u2500\u2500 2018-03-04-getting-rusty-with-vim.markdown \u2502 \u2502 \u251c\u2500\u2500 2018-03-12-stream-stats-in-rust.markdown \u2502 \u2502 \u2514\u2500\u2500 2018-03-22-blog-setup.markdown MkDocs Docs Directory : \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 blog \u2502 \u2502 \u251c\u2500\u2500 2016 \u2502 \u2502 \u2502 \u251c\u2500\u2500 negative-modulo.markdown \u2502 \u2502 \u2502 \u2514\u2500\u2500 yank-without-jank.markdown \u2502 \u2502 \u251c\u2500\u2500 2017 \u2502 \u2502 \u2502 \u251c\u2500\u2500 base16-shell.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 fzf-dictionary.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 gnu-screen.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 how-to-get-better-at-anything.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 vim-send-text.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 what-the-sql-lateral.markdown \u2502 \u2502 \u2502 \u251c\u2500\u2500 what-the-sql-recursive.markdown \u2502 \u2502 \u2502 \u2514\u2500\u2500 what-the-sql-window.markdown \u2502 \u2502 \u2514\u2500\u2500 2018 \u2502 \u2502 \u251c\u2500\u2500 blog-setup.markdown \u2502 \u2502 \u251c\u2500\u2500 getting-rusty-with-vim.markdown \u2502 \u2502 \u251c\u2500\u2500 move-to-mkdocs.markdown \u2502 \u2502 \u2514\u2500\u2500 stream-stats-in-rust.markdown After getting the files to the correct directory, the site hierarchy needs to be configured in mkdocs.yml . That file contains much more than the page structure. You'll need to read more about it from their documentation . mkdocs.yml : # .. stuff before this section .. pages : - Home : index.md - Projects : projects.md - '2018' : - 'Move to MkDocs' : blog/2018/move-to-mkdocs.markdown - 'A Rustic Journey Through Stream Stats' : blog/2018/stream-stats-in-rust.markdown - 'Getting Rusty with Vim' : blog/2018/getting-rusty-with-vim.markdown - 'Dev Blog Tools :: A Quick Tour of My Setup' : blog/2018/blog-setup.markdown - '2017' : - 'Base16 Shell' : blog/2017/base16-shell.markdown - 'How to Get Better At Anything' : blog/2017/how-to-get-better-at-anything.markdown - 'FZF + WordNet = Dictionary' : blog/2017/fzf-dictionary.markdown - 'GNU Screen' : blog/2017/gnu-screen.markdown - 'What the SQL?!? Lateral Joins' : blog/2017/what-the-sql-lateral.markdown - 'What the SQL?!? WINDOW' : blog/2017/what-the-sql-window.markdown - 'What the SQL?!? Recursive' : blog/2017/what-the-sql-recursive.markdown - 'Vim Send Text' : blog/2017/vim-send-text.markdown # .. more stuff .. Once mkdocs.yml is configured we can run: # start a web server to preview the site mkdocs server # or generate the site files for deployment mkdocs build # or deploy to GitHub Pages mkdocs gh-deploy","title":"Transition"},{"location":"blog/2018/move-to-mkdocs/#conclusion","text":"Here's a breakdown of the pros and cons that I've experienced so far:","title":"Conclusion"},{"location":"blog/2018/move-to-mkdocs/#pros","text":"Full site search without using external service (Google, Angola, etc.) Site hierarchy. Automatic table of contents on all pages. Various code blocks and annotations. Less magic.","title":"Pros"},{"location":"blog/2018/move-to-mkdocs/#cons","text":"Older posts don't translate well, because they have to be in Markdown format. MkDocs is a Python project, a language I'm not familiar with, yet. Less magic. Hopefully this the catalyst to more content. Stay tuned! Questions? Comments? Trolls?!? Let me know! Tweet","title":"Cons"},{"location":"blog/2018/stream-stats-in-rust/","text":"A Rustic Journey Through Stream Stats \u00b6 After playing Guessing Game from the Rust Book a few times, it was time to make something a little more substantial. We're going to create stream_stats , a CLI program which prints throughput statistics from stdin while redirecting through stdout . Think tee + wc -l + watch all at the same time. TL;DR - cargo install stream_stats Here is a quick demo of the program: Today, I we'll build this program up in 6 steps smallish steps. The minimum requirement of this program was the live feedback as seen in the demo and minimal impact on the overall performance. Step 1 - Reproducing cat Inefficiently \u00b6 First step is to replicate cat . We'll do it as demonstrated by Rust's own documentation . use std :: io ; fn main () { let mut buffer = String :: new (); while io :: stdin (). read_line ( & mut buffer ). unwrap () > 0 { print! ( \"{}\" , buffer ); buffer . clear (); } } I'm using unwrap to keep our program short and sweet. Save the code as stream_stats.rs and build it using rustc -O stream_stats.rs . This will compile the program into stream_stats . We can now run the program with ./stream_stats < stream_stats.rs or cat stream_stats.rs | stream_stats . This should output the source code we just wrote. The program is sufficient for small streams, but will perform horribly on large files. Step 2 - Reproducing cat Efficiently with Buffering \u00b6 It can be excessively inefficient to work directly with a Read instance. For example, every call to read on TcpStream results in a system call. A BufReader performs large, infrequent reads on the underlying Read and maintains an in-memory buffer of the results. -- https://doc.rust-lang.org/std/io/struct.BufReader.html Lets add some buffer use to increase performance and get it near the speed of cat . Replace the contents of stream_stats.rs with the following, recompile, and run the program. use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; static READ_BUF_SIZE : usize = 1024 * 1024 ; fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); buffer . clear (); } writer . flush (). unwrap (); } The exact difference is viewable on Github . Here's a one-liner which to help with the build/run cycle: rustc -O ./stream_stats.rs && ./stream_stats < stream_stats.rs For a few extra lines, we get a lot of performance. There are ways to get even more performance, but it won't be worth the code complexity at this time. Step 3 - Count the Lines \u00b6 We're ready to start counting lines. We'll introduce a struct to hold a start time and line count. use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; struct Stats { started : Instant , lines : usize , } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats { started : Instant :: now (), lines : 0 , }; while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; buffer . clear (); } writer . flush (). unwrap (); eprintln! ( \"lines: {}, {:?}\" , stats . lines , stats . started . elapsed ()); } Again the exact difference is viewable on Github . Step 4 - Write to /dev/tty \u00b6 Using eprintln! is easy, but bad practice for non-error output. The next step is moving the output to /dev/tty . As a reminder, we're also not using println! because we're reserving it for the original content piped from stdin . use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; struct Stats { started : Instant , lines : usize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : 0 , tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats :: new ( \"/dev/tty\" ); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; buffer . clear (); } writer . flush (). unwrap (); writeln! ( stats . tty , \"lines: {}, {:?}\" , stats . lines , stats . started . elapsed () ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github . Step 5 - Beautify Stats Output \u00b6 The display logic is going to get a little more complex. We want to move the string formatting code to a fmt::Display trait. We'll also add the kilobytes to the displayed stats. use std :: fmt ; use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; static CLEAR_LINE : & str = \" \\x1B [1G \\x1B [2K\" ; struct Stats { started : Instant , lines : usize , bytes : usize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : 0 , bytes : 0 , tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } } impl fmt :: Display for Stats { fn fmt ( & self , f : & mut fmt :: Formatter ) -> fmt :: Result { let elapsed = self . started . elapsed (); let seconds : f64 = elapsed . as_secs () as f64 + elapsed . subsec_nanos () as f64 * 1e-9 ; if seconds == 0.0 { return write! ( f , \"\" ); } let kb = self . bytes as f64 / 1024 as f64 ; let kb_per_sec = kb / seconds ; let lines_per_sec = self . lines as f64 / seconds ; write! ( f , \"{}{:.1} sec | {:.0} kb [ {:.1}/s ] | {} lines [ {:.0}/s ]\" , CLEAR_LINE , seconds , kb , kb_per_sec , self . lines , lines_per_sec ) } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats :: new ( \"/dev/tty\" ); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; stats . bytes += & buffer . len (); buffer . clear (); } writer . flush (). unwrap (); writeln! ( & stats . tty , \"{}\" , & stats ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github . Step 6 - Display the stats 10 times per second \u00b6 We're finally at the most useful part of the program. Viewing the stats while the stream is still going. For this task, we introduce a thread which loops forever sleeping a little and waking to output the stats. Because of the thread, we need to use Arc to safely tell Rust another thread is going to have a pointer to the stats object. To be honest, I don't fully understand why I need to use AtomicUsize . I tried to keep the usize variables would get errors regarding mutability. If someone out there can remove the AtomicUsize without introducing unsafe please let me know! Here's the final code listing: use std :: fmt ; use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: sync :: Arc ; use std :: sync :: atomic :: { AtomicUsize , Ordering }; use std :: thread :: { self , sleep }; use std :: time :: { Duration , Instant }; static READ_BUF_SIZE : usize = 1024 * 1024 ; static CLEAR_LINE : & str = \" \\x1B [1G \\x1B [2K\" ; static UPDATE_INTERVAL_MS : u64 = 100 ; struct Stats { started : Instant , lines : AtomicUsize , bytes : AtomicUsize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : AtomicUsize :: new ( 0 ), bytes : AtomicUsize :: new ( 0 ), tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } fn add ( & self , buffer : & Vec < u8 > ) { self . lines . fetch_add ( 1 , Ordering :: Relaxed ); self . bytes . fetch_add ( buffer . len (), Ordering :: Relaxed ); } } impl fmt :: Display for Stats { fn fmt ( & self , f : & mut fmt :: Formatter ) -> fmt :: Result { let elapsed = self . started . elapsed (); let seconds : f64 = elapsed . as_secs () as f64 + elapsed . subsec_nanos () as f64 * 1e-9 ; if seconds == 0.0 { return write! ( f , \"\" ); } let bytes = self . bytes . load ( Ordering :: Relaxed ) as f64 ; let lines = self . lines . load ( Ordering :: Relaxed ) as f64 ; let kb = bytes / 1024 as f64 ; let kb_per_sec = kb / seconds ; let lines_per_sec = lines / seconds ; write! ( f , \"{}{:.1} sec | {:.0} kb [ {:.1}/s ] | {:.0} lines [ {:.0}/s ]\" , CLEAR_LINE , seconds , kb , kb_per_sec , lines , lines_per_sec ) } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let stats = Arc :: new ( Stats :: new ( \"/dev/tty\" )); let stats_clone = stats . clone (); thread :: spawn ( move || loop { sleep ( Duration :: from_millis ( UPDATE_INTERVAL_MS )); write! ( & stats_clone . tty , \"{}\" , & stats_clone ). expect ( \"Could not write to tty!\" ); }); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . add ( & buffer ); buffer . clear (); } writer . flush (). unwrap (); writeln! ( & stats . tty , \"{}\" , & stats ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github . Closing Thoughts \u00b6 I personally learned a lot assembling these steps and wish I did this before publishing the cargo crate of the same name. Any suggestions, comments, and corrections welcome on this post or the final crate are welcome. https://github.com/ddrscott/stream_stats Thanks for learning with me!","title":"A Rustic Journey Through Stream Stats"},{"location":"blog/2018/stream-stats-in-rust/#a-rustic-journey-through-stream-stats","text":"After playing Guessing Game from the Rust Book a few times, it was time to make something a little more substantial. We're going to create stream_stats , a CLI program which prints throughput statistics from stdin while redirecting through stdout . Think tee + wc -l + watch all at the same time. TL;DR - cargo install stream_stats Here is a quick demo of the program: Today, I we'll build this program up in 6 steps smallish steps. The minimum requirement of this program was the live feedback as seen in the demo and minimal impact on the overall performance.","title":"A Rustic Journey Through Stream Stats"},{"location":"blog/2018/stream-stats-in-rust/#step-1-reproducing-cat-inefficiently","text":"First step is to replicate cat . We'll do it as demonstrated by Rust's own documentation . use std :: io ; fn main () { let mut buffer = String :: new (); while io :: stdin (). read_line ( & mut buffer ). unwrap () > 0 { print! ( \"{}\" , buffer ); buffer . clear (); } } I'm using unwrap to keep our program short and sweet. Save the code as stream_stats.rs and build it using rustc -O stream_stats.rs . This will compile the program into stream_stats . We can now run the program with ./stream_stats < stream_stats.rs or cat stream_stats.rs | stream_stats . This should output the source code we just wrote. The program is sufficient for small streams, but will perform horribly on large files.","title":"Step 1 - Reproducing cat Inefficiently"},{"location":"blog/2018/stream-stats-in-rust/#step-2-reproducing-cat-efficiently-with-buffering","text":"It can be excessively inefficient to work directly with a Read instance. For example, every call to read on TcpStream results in a system call. A BufReader performs large, infrequent reads on the underlying Read and maintains an in-memory buffer of the results. -- https://doc.rust-lang.org/std/io/struct.BufReader.html Lets add some buffer use to increase performance and get it near the speed of cat . Replace the contents of stream_stats.rs with the following, recompile, and run the program. use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; static READ_BUF_SIZE : usize = 1024 * 1024 ; fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); buffer . clear (); } writer . flush (). unwrap (); } The exact difference is viewable on Github . Here's a one-liner which to help with the build/run cycle: rustc -O ./stream_stats.rs && ./stream_stats < stream_stats.rs For a few extra lines, we get a lot of performance. There are ways to get even more performance, but it won't be worth the code complexity at this time.","title":"Step 2 - Reproducing cat Efficiently with Buffering"},{"location":"blog/2018/stream-stats-in-rust/#step-3-count-the-lines","text":"We're ready to start counting lines. We'll introduce a struct to hold a start time and line count. use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; struct Stats { started : Instant , lines : usize , } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats { started : Instant :: now (), lines : 0 , }; while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; buffer . clear (); } writer . flush (). unwrap (); eprintln! ( \"lines: {}, {:?}\" , stats . lines , stats . started . elapsed ()); } Again the exact difference is viewable on Github .","title":"Step 3 - Count the Lines"},{"location":"blog/2018/stream-stats-in-rust/#step-4-write-to-devtty","text":"Using eprintln! is easy, but bad practice for non-error output. The next step is moving the output to /dev/tty . As a reminder, we're also not using println! because we're reserving it for the original content piped from stdin . use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; struct Stats { started : Instant , lines : usize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : 0 , tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats :: new ( \"/dev/tty\" ); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; buffer . clear (); } writer . flush (). unwrap (); writeln! ( stats . tty , \"lines: {}, {:?}\" , stats . lines , stats . started . elapsed () ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github .","title":"Step 4 - Write to /dev/tty"},{"location":"blog/2018/stream-stats-in-rust/#step-5-beautify-stats-output","text":"The display logic is going to get a little more complex. We want to move the string formatting code to a fmt::Display trait. We'll also add the kilobytes to the displayed stats. use std :: fmt ; use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: time :: Instant ; static READ_BUF_SIZE : usize = 1024 * 1024 ; static CLEAR_LINE : & str = \" \\x1B [1G \\x1B [2K\" ; struct Stats { started : Instant , lines : usize , bytes : usize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : 0 , bytes : 0 , tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } } impl fmt :: Display for Stats { fn fmt ( & self , f : & mut fmt :: Formatter ) -> fmt :: Result { let elapsed = self . started . elapsed (); let seconds : f64 = elapsed . as_secs () as f64 + elapsed . subsec_nanos () as f64 * 1e-9 ; if seconds == 0.0 { return write! ( f , \"\" ); } let kb = self . bytes as f64 / 1024 as f64 ; let kb_per_sec = kb / seconds ; let lines_per_sec = self . lines as f64 / seconds ; write! ( f , \"{}{:.1} sec | {:.0} kb [ {:.1}/s ] | {} lines [ {:.0}/s ]\" , CLEAR_LINE , seconds , kb , kb_per_sec , self . lines , lines_per_sec ) } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let mut stats = Stats :: new ( \"/dev/tty\" ); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . lines += 1 ; stats . bytes += & buffer . len (); buffer . clear (); } writer . flush (). unwrap (); writeln! ( & stats . tty , \"{}\" , & stats ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github .","title":"Step 5 - Beautify Stats Output"},{"location":"blog/2018/stream-stats-in-rust/#step-6-display-the-stats-10-times-per-second","text":"We're finally at the most useful part of the program. Viewing the stats while the stream is still going. For this task, we introduce a thread which loops forever sleeping a little and waking to output the stats. Because of the thread, we need to use Arc to safely tell Rust another thread is going to have a pointer to the stats object. To be honest, I don't fully understand why I need to use AtomicUsize . I tried to keep the usize variables would get errors regarding mutability. If someone out there can remove the AtomicUsize without introducing unsafe please let me know! Here's the final code listing: use std :: fmt ; use std :: fs :: { File , OpenOptions }; use std :: io :: { self , BufRead , BufReader , BufWriter , Write }; use std :: sync :: Arc ; use std :: sync :: atomic :: { AtomicUsize , Ordering }; use std :: thread :: { self , sleep }; use std :: time :: { Duration , Instant }; static READ_BUF_SIZE : usize = 1024 * 1024 ; static CLEAR_LINE : & str = \" \\x1B [1G \\x1B [2K\" ; static UPDATE_INTERVAL_MS : u64 = 100 ; struct Stats { started : Instant , lines : AtomicUsize , bytes : AtomicUsize , tty : File , } impl Stats { fn new ( tty : & str ) -> Stats { Stats { started : Instant :: now (), lines : AtomicUsize :: new ( 0 ), bytes : AtomicUsize :: new ( 0 ), tty : OpenOptions :: new () . write ( true ) . append ( true ) . open ( tty ) . expect ( \"Cannot open tty for writing!\" ), } } fn add ( & self , buffer : & Vec < u8 > ) { self . lines . fetch_add ( 1 , Ordering :: Relaxed ); self . bytes . fetch_add ( buffer . len (), Ordering :: Relaxed ); } } impl fmt :: Display for Stats { fn fmt ( & self , f : & mut fmt :: Formatter ) -> fmt :: Result { let elapsed = self . started . elapsed (); let seconds : f64 = elapsed . as_secs () as f64 + elapsed . subsec_nanos () as f64 * 1e-9 ; if seconds == 0.0 { return write! ( f , \"\" ); } let bytes = self . bytes . load ( Ordering :: Relaxed ) as f64 ; let lines = self . lines . load ( Ordering :: Relaxed ) as f64 ; let kb = bytes / 1024 as f64 ; let kb_per_sec = kb / seconds ; let lines_per_sec = lines / seconds ; write! ( f , \"{}{:.1} sec | {:.0} kb [ {:.1}/s ] | {:.0} lines [ {:.0}/s ]\" , CLEAR_LINE , seconds , kb , kb_per_sec , lines , lines_per_sec ) } } fn main () { let mut reader = BufReader :: with_capacity ( READ_BUF_SIZE , io :: stdin ()); let mut writer = BufWriter :: new ( io :: stdout ()); let mut buffer = vec! []; let stats = Arc :: new ( Stats :: new ( \"/dev/tty\" )); let stats_clone = stats . clone (); thread :: spawn ( move || loop { sleep ( Duration :: from_millis ( UPDATE_INTERVAL_MS )); write! ( & stats_clone . tty , \"{}\" , & stats_clone ). expect ( \"Could not write to tty!\" ); }); while reader . read_until ( b'\\n' , & mut buffer ). unwrap () > 0 { writer . write ( & buffer ). unwrap (); stats . add ( & buffer ); buffer . clear (); } writer . flush (). unwrap (); writeln! ( & stats . tty , \"{}\" , & stats ). expect ( \"Could not write to tty!\" ); } Exact difference is viewable on Github .","title":"Step 6 - Display the stats 10 times per second"},{"location":"blog/2018/stream-stats-in-rust/#closing-thoughts","text":"I personally learned a lot assembling these steps and wish I did this before publishing the cargo crate of the same name. Any suggestions, comments, and corrections welcome on this post or the final crate are welcome. https://github.com/ddrscott/stream_stats Thanks for learning with me!","title":"Closing Thoughts"},{"location":"blog/2020/sql-ninja/","text":"Slice and Dice SQL with SQL Ninja \u00b6 I write a lot of SQL. It's my primary language for various reasons which we won't get into at here, but even after using it for so long, SQL can still be a pain for some repetitive tasks. Problem \u00b6 Here's a SQL expression for pivoting some expenses by category: SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'katanas' THEN amount END ) AS katanas , SUM ( CASE WHEN category = 'shurikens' THEN amount END ) AS shurikens , SUM ( CASE WHEN category = 'hooks' THEN amount END ) AS hooks , SUM ( CASE WHEN category = 'shoes' THEN amount END ) AS shoes , SUM ( CASE WHEN category = 'disguises' THEN amount END ) AS disguises , SUM ( CASE WHEN category NOT IN ( 'katanas' , 'shurikens' , 'hooks' , 'shoes' , 'disguises' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM expenses ORDER BY year_month , total_amount Can we see the repetitive SQL going on? Here's a hint: SUM(CASE WHEN(...)) AS ... . Wouldn't it be nice to make a list of categories and have the SQL generated for you? Wouldn't it be nice to use generated SQL directly from command line? Solution \u00b6 SQL is a declarative language. HTML is a declarative language. HTML has so many template languages to choose from, but SQL has so few. Enter SQL Ninja. SQL Ninja uses the popular Jinja Templating Engine which typically generates HTML, but we can use it to generate SQL. pip install sql-ninja Now, let's create a simple SQL file: cat > hello.sql <<SQL SELECT 'world' SQL From here, we can use the sql command provided by sql-ninja to transform the SQL. sql hello.sql # => SELECT 'world' That wasn't very exciting. Let's try to template it: cat > hello.sql <<SQL SELECT '' SQL And render the template: sql hello.sql # => SELECT '' What happened? We got a blank message. This is because we didn't provide one to the template engine. Try this instead: sql hello.sql msg = 'World!!!' # => SELECT 'World!!!' We did it! Starting a New Project \u00b6 In the real world, we work with work with projects that have a lot of other files. We probably don't want our main projects root directory littered with *.sql files. SQL Ninja recommends putting templates in the following directory: . \u2514\u2500\u2500 sql \u2514\u2500\u2500 templates \u2514\u2500\u2500 hello.sql So let's do that with our hello.sql mkdir -p sql/templates mv hello.sql sql/templates/ And from here, we can run our exact sql command from before: sql hello.sql msg = 'World!!!' # => SELECT 'World!!!' It still works because SQL Ninja has sensible defaults. Files in current the current working directory and sql/templates are the default search paths. Default Searched Directories Current working directory sql/templates Please use one or the other, but not both. Build The Query \u00b6 Create sql/templates/expenses.sql DATEFORMAT(entry_dt, 'yyyy-mm') as year_month, SUM(CASE WHEN category = 'SQL' THEN amount END) AS SQL, SUM(CASE WHEN category = 'Python' THEN amount END) AS Python, SUM( CASE WHEN category NOT IN ('SQL','Python') THEN amount END ) AS other_amount, SUM(amount) AS total_amount FROM expenses ORDER BY year_month, total_amount Let's run it: sql expenses.sql categories = 'food transportation' #=> SELECT DATEFORMAT ( entry_dt, 'yyyy-mm' ) as year_month, SUM ( CASE WHEN category = 'food' THEN amount END ) AS food, SUM ( CASE WHEN category = 'transportation' THEN amount END ) AS transportation, SUM ( CASE WHEN category NOT IN ( 'food' , 'transportation' ) THEN amount END ) AS other_amount, SUM ( amount ) AS total_amount FROM expenses ORDER BY year_month, total_amount Subquery Workflow \u00b6 Jinja supports including templates in other templates. This is perfect for sub queries! Let's break up the expenses query into two: summaries by category pivot the results -- sql/templates/expenses/summary.sql SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , category , SUM ( amount ) AS amount FROM expenses ORDER BY year_month , category -- sql/templates/expenses/pivot.sqlSELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'SQL' THEN amount END ) AS SQL , SUM ( CASE WHEN category = 'Python' THEN amount END ) AS Python , SUM ( CASE WHEN category NOT IN ( 'SQL' , 'Python' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM ( { % include 'expenses/summary.sql' % } ) AS summary ORDER BY year_month , total_amount Render the new template with: sql expenses/pivot.sql and override categories or not: SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'katanas' THEN amount END ) AS katanas , SUM ( CASE WHEN category = 'shurikens' THEN amount END ) AS shurikens , SUM ( CASE WHEN category = 'hooks' THEN amount END ) AS hooks , SUM ( CASE WHEN category = 'shoes' THEN amount END ) AS shoes , SUM ( CASE WHEN category = 'disguises' THEN amount END ) AS disguises , SUM ( CASE WHEN category NOT IN ( 'katanas' , 'shurikens' , 'hooks' , 'shoes' , 'disguises' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM ( SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , category , SUM ( amount ) AS amount FROM expenses ORDER BY year_month , category ) AS summary ORDER BY year_month , total_amount Docker \u00b6 A docker image has been built if installing Python is a problem: docker pull ddrscott/sql-ninja Docker containers don't have access to local file system, so we need to mount the volume into the container. docker run --rm -v $PWD :/app -w /app ddrscott/sql-ninja expenses/pivot.sql # ^ ^ ^ ^ ^ # | | | | | # | | | | + the template # | | | | # | | | + the image # | | | # | | + start in /app path # | | # | + volume mount current path to /app # | # + remove container when complete Make an alias if ya want: # Pick one or name it whatever is most memorable to you: alias sql = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja' alias sqln = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja' alias sqlninja = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja' Why not Jinja SQL ? \u00b6 The jinjasql project has 452 stars as of this writing and it uses Jinja, too. The project requires the user to write they SQL as Python strings. If we're going to write SQL in Python strings, then we don't need a templating engine. Just format strings and use Python. With SQL Ninja we want to write SQL in .sql files. Period. https://hashedin.com/blog/introducing-jinjasql-generate-sql-using-jinja-templates/ ) Conclusion \u00b6 I'm currently using it in my day job and it has helped parameterize several aspects of some large SQL statements. Jinja's macro and include features really standout and make writing SQL almost dreamy. Almost. Please let us know how this project is working for you and how to make it better!","title":"SQL + Jinja = Templating Done Right\u2122"},{"location":"blog/2020/sql-ninja/#slice-and-dice-sql-with-sql-ninja","text":"I write a lot of SQL. It's my primary language for various reasons which we won't get into at here, but even after using it for so long, SQL can still be a pain for some repetitive tasks.","title":"Slice and Dice SQL with SQL Ninja"},{"location":"blog/2020/sql-ninja/#problem","text":"Here's a SQL expression for pivoting some expenses by category: SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'katanas' THEN amount END ) AS katanas , SUM ( CASE WHEN category = 'shurikens' THEN amount END ) AS shurikens , SUM ( CASE WHEN category = 'hooks' THEN amount END ) AS hooks , SUM ( CASE WHEN category = 'shoes' THEN amount END ) AS shoes , SUM ( CASE WHEN category = 'disguises' THEN amount END ) AS disguises , SUM ( CASE WHEN category NOT IN ( 'katanas' , 'shurikens' , 'hooks' , 'shoes' , 'disguises' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM expenses ORDER BY year_month , total_amount Can we see the repetitive SQL going on? Here's a hint: SUM(CASE WHEN(...)) AS ... . Wouldn't it be nice to make a list of categories and have the SQL generated for you? Wouldn't it be nice to use generated SQL directly from command line?","title":"Problem"},{"location":"blog/2020/sql-ninja/#solution","text":"SQL is a declarative language. HTML is a declarative language. HTML has so many template languages to choose from, but SQL has so few. Enter SQL Ninja. SQL Ninja uses the popular Jinja Templating Engine which typically generates HTML, but we can use it to generate SQL. pip install sql-ninja Now, let's create a simple SQL file: cat > hello.sql <<SQL SELECT 'world' SQL From here, we can use the sql command provided by sql-ninja to transform the SQL. sql hello.sql # => SELECT 'world' That wasn't very exciting. Let's try to template it: cat > hello.sql <<SQL SELECT '' SQL And render the template: sql hello.sql # => SELECT '' What happened? We got a blank message. This is because we didn't provide one to the template engine. Try this instead: sql hello.sql msg = 'World!!!' # => SELECT 'World!!!' We did it!","title":"Solution"},{"location":"blog/2020/sql-ninja/#starting-a-new-project","text":"In the real world, we work with work with projects that have a lot of other files. We probably don't want our main projects root directory littered with *.sql files. SQL Ninja recommends putting templates in the following directory: . \u2514\u2500\u2500 sql \u2514\u2500\u2500 templates \u2514\u2500\u2500 hello.sql So let's do that with our hello.sql mkdir -p sql/templates mv hello.sql sql/templates/ And from here, we can run our exact sql command from before: sql hello.sql msg = 'World!!!' # => SELECT 'World!!!' It still works because SQL Ninja has sensible defaults. Files in current the current working directory and sql/templates are the default search paths. Default Searched Directories Current working directory sql/templates Please use one or the other, but not both.","title":"Starting a New Project"},{"location":"blog/2020/sql-ninja/#build-the-query","text":"Create sql/templates/expenses.sql DATEFORMAT(entry_dt, 'yyyy-mm') as year_month, SUM(CASE WHEN category = 'SQL' THEN amount END) AS SQL, SUM(CASE WHEN category = 'Python' THEN amount END) AS Python, SUM( CASE WHEN category NOT IN ('SQL','Python') THEN amount END ) AS other_amount, SUM(amount) AS total_amount FROM expenses ORDER BY year_month, total_amount Let's run it: sql expenses.sql categories = 'food transportation' #=> SELECT DATEFORMAT ( entry_dt, 'yyyy-mm' ) as year_month, SUM ( CASE WHEN category = 'food' THEN amount END ) AS food, SUM ( CASE WHEN category = 'transportation' THEN amount END ) AS transportation, SUM ( CASE WHEN category NOT IN ( 'food' , 'transportation' ) THEN amount END ) AS other_amount, SUM ( amount ) AS total_amount FROM expenses ORDER BY year_month, total_amount","title":"Build The Query"},{"location":"blog/2020/sql-ninja/#subquery-workflow","text":"Jinja supports including templates in other templates. This is perfect for sub queries! Let's break up the expenses query into two: summaries by category pivot the results -- sql/templates/expenses/summary.sql SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , category , SUM ( amount ) AS amount FROM expenses ORDER BY year_month , category -- sql/templates/expenses/pivot.sqlSELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'SQL' THEN amount END ) AS SQL , SUM ( CASE WHEN category = 'Python' THEN amount END ) AS Python , SUM ( CASE WHEN category NOT IN ( 'SQL' , 'Python' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM ( { % include 'expenses/summary.sql' % } ) AS summary ORDER BY year_month , total_amount Render the new template with: sql expenses/pivot.sql and override categories or not: SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , SUM ( CASE WHEN category = 'katanas' THEN amount END ) AS katanas , SUM ( CASE WHEN category = 'shurikens' THEN amount END ) AS shurikens , SUM ( CASE WHEN category = 'hooks' THEN amount END ) AS hooks , SUM ( CASE WHEN category = 'shoes' THEN amount END ) AS shoes , SUM ( CASE WHEN category = 'disguises' THEN amount END ) AS disguises , SUM ( CASE WHEN category NOT IN ( 'katanas' , 'shurikens' , 'hooks' , 'shoes' , 'disguises' ) THEN amount END ) AS other_amount , SUM ( amount ) AS total_amount FROM ( SELECT DATEFORMAT ( entry_dt , 'yyyy-mm' ) as year_month , category , SUM ( amount ) AS amount FROM expenses ORDER BY year_month , category ) AS summary ORDER BY year_month , total_amount","title":"Subquery Workflow"},{"location":"blog/2020/sql-ninja/#docker","text":"A docker image has been built if installing Python is a problem: docker pull ddrscott/sql-ninja Docker containers don't have access to local file system, so we need to mount the volume into the container. docker run --rm -v $PWD :/app -w /app ddrscott/sql-ninja expenses/pivot.sql # ^ ^ ^ ^ ^ # | | | | | # | | | | + the template # | | | | # | | | + the image # | | | # | | + start in /app path # | | # | + volume mount current path to /app # | # + remove container when complete Make an alias if ya want: # Pick one or name it whatever is most memorable to you: alias sql = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja' alias sqln = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja' alias sqlninja = 'docker run --rm -v $PWD:/app -w /app ddrscott/sql-ninja'","title":"Docker"},{"location":"blog/2020/sql-ninja/#why-not-jinja-sql","text":"The jinjasql project has 452 stars as of this writing and it uses Jinja, too. The project requires the user to write they SQL as Python strings. If we're going to write SQL in Python strings, then we don't need a templating engine. Just format strings and use Python. With SQL Ninja we want to write SQL in .sql files. Period. https://hashedin.com/blog/introducing-jinjasql-generate-sql-using-jinja-templates/ )","title":"Why not Jinja SQL?"},{"location":"blog/2020/sql-ninja/#conclusion","text":"I'm currently using it in my day job and it has helped parameterize several aspects of some large SQL statements. Jinja's macro and include features really standout and make writing SQL almost dreamy. Almost. Please let us know how this project is working for you and how to make it better!","title":"Conclusion"},{"location":"blog/2021/i-heart-make/","text":"I Heart Make How to Convert CBR to PDF using a Makefile \u00b6 Good news: I got a shiny new e-ink reader. Bad news: It doesn't support CBR (Comic Book Reader) files. Good news: I recently read the manual on make because I had trouble sleeping. Bad news: It didn't put me to sleep. Problem \u00b6 I have a bunch of CBR ( Comic Book Reader ) files that I need to convert to PDF ( Portable Document Format ) files. The general step for a single file would look something like: rar x naruto-001.cbr .images # 1) unpack archive into .images/*.jpg magick convert .images/* naruto-001.pdf # 2) convert all the images into pdf file rm -rf .images # 3) remove the images. But we're not here to convert a single file. We're here to convert a ton of them. Without make , we could probably: extract the snippet to a bash script named foo.sh run the script on one file with ./foo.sh naruto-001.cbr run the script on all the files with find . -name '*.cbr' -exec ./foo.sh {} \\; . Then we'd curse when errors come up because: we forgot to make the script executable. chmod +x foo.sh we forget to add -e so the script stops when something goes wrong. #!/bin/bash -e something with find never works first try! file naruto-301.cbr failed, and we don't want to run naruto-{000-300}.cbr again! Solution \u00b6 Make way for make ! A Makefile can handle most of our iteration problems automatically. It already has the facilities to handle multiple files, error handling, and skipping finished files. A Full Makefile \u00b6 cbr_files = $( wildcard *.cbr ) pdf_files = $( cbr_files:.cbr = .pdf ) image_dir = .images-$< all : ${ pdf_files } @echo All done clean : rm ${ pdf_files } %.pdf : %. cbr @echo Building $< into $@ rar x $< ${ image_dir } / find ${ image_dir } / -size 0 -ls -delete magick convert ${ image_dir } /* $@ rm -rf ${ image_dir } @echo $@ is ready Makefile with in-Line Comments \u00b6 # 1. Get a list of all CBR files in the current directory cbr_files = $( wildcard *.cbr ) # 2. Get a list of all PDFs I want to build by renaming CBR list to PDF pdf_files = $( cbr_files:.cbr = .pdf ) # 3. Set where the unpacked images should go. We'll delete them after each build image_dir = .images-$< # 4. The first target specified is always the default when we run `make` without any arguments all : ${ pdf_files } @echo All done # 5. `make clean` will remove all the generated PDFs clean : rm ${ pdf_files } # 6. Use Pattern Rules to build an individual PDF file %.pdf : %. cbr # use @ to prevent `make` from printing the command it is executing @echo Building $< into $@ # ^ ^ # | | # | | # | +- foo.pdf # | # +- foo.cbr # rar x $< ${ image_dir } / # ^ ^ ^ # | | | # | | +- unpack to destination directory # | | # | +- foo.cbr # | # +- extract # find ${ image_dir } / -size 0 -ls -delete # ^ ^ ^ ^ # | | | | # | | | +- delete the file # | | | # | | +- print `ls -l` of the file # | | # | +- only files with zero size # +- find in image directory # magick convert ${ image_dir } /* $@ # ^ ^ # | | # | +- foo.pdf # | # +- all files in image directory # rm -rf ${ image_dir } # ^ # | # +- delete entire image director. We don't need it anymore. # @echo $@ is ready Code the contents of either snippet into a Makefile and put the Makefile in the same directory as all the cbr files. Then execute make and a pile of pdf files should get created. If we run with make -j 4 it will even run multiple files in parallel where 4 is the number of parallel jobs you'd like to run. Revel in the code we didn't have to write to enable parallelism! A Little Deeper \u00b6 The make magic occurs in step 6 with %.pdf: %.cbr . This is officially called a pattern rule according to the documentation. It tells make to build a target for any file suffixed with .pdf and set a dependency for the same file suffixed with .cbr . With the pattern rule in place and using $< to represent the first dependency and $@ to represent the target file, we can script out the remaining build. Another piece of magic is in step #3 . image_dir = .images-$< is a variable assignment referencing $< . The = assignment operator in make is a macro, meaning it won't get evaluated until the variable is referenced in a target. This can be surprising at first, but in this case, it provides a nice unique directory for our images to get unpacked. More details about Makefile variable use can be found in their docs . Conclusion \u00b6 make isn't the shinest build system around. Wikipedia says there are over 40 of them, but in my opinion, make get's the most value for the least amount of effort. make provides dependency checking, multiple job support, and simple bash-like syntax without the need to npm install the_world . Thanks for make ing it this far. Let me know how you make use of make in the comments below.","title":"I Heart Make"},{"location":"blog/2021/i-heart-make/#i-heart-makehow-to-convert-cbr-to-pdf-using-a-makefile","text":"Good news: I got a shiny new e-ink reader. Bad news: It doesn't support CBR (Comic Book Reader) files. Good news: I recently read the manual on make because I had trouble sleeping. Bad news: It didn't put me to sleep.","title":"I Heart MakeHow to Convert CBR to PDF using a Makefile"},{"location":"blog/2021/i-heart-make/#problem","text":"I have a bunch of CBR ( Comic Book Reader ) files that I need to convert to PDF ( Portable Document Format ) files. The general step for a single file would look something like: rar x naruto-001.cbr .images # 1) unpack archive into .images/*.jpg magick convert .images/* naruto-001.pdf # 2) convert all the images into pdf file rm -rf .images # 3) remove the images. But we're not here to convert a single file. We're here to convert a ton of them. Without make , we could probably: extract the snippet to a bash script named foo.sh run the script on one file with ./foo.sh naruto-001.cbr run the script on all the files with find . -name '*.cbr' -exec ./foo.sh {} \\; . Then we'd curse when errors come up because: we forgot to make the script executable. chmod +x foo.sh we forget to add -e so the script stops when something goes wrong. #!/bin/bash -e something with find never works first try! file naruto-301.cbr failed, and we don't want to run naruto-{000-300}.cbr again!","title":"Problem"},{"location":"blog/2021/i-heart-make/#solution","text":"Make way for make ! A Makefile can handle most of our iteration problems automatically. It already has the facilities to handle multiple files, error handling, and skipping finished files.","title":"Solution"},{"location":"blog/2021/i-heart-make/#a-full-makefile","text":"cbr_files = $( wildcard *.cbr ) pdf_files = $( cbr_files:.cbr = .pdf ) image_dir = .images-$< all : ${ pdf_files } @echo All done clean : rm ${ pdf_files } %.pdf : %. cbr @echo Building $< into $@ rar x $< ${ image_dir } / find ${ image_dir } / -size 0 -ls -delete magick convert ${ image_dir } /* $@ rm -rf ${ image_dir } @echo $@ is ready","title":"A Full Makefile"},{"location":"blog/2021/i-heart-make/#makefile-with-in-line-comments","text":"# 1. Get a list of all CBR files in the current directory cbr_files = $( wildcard *.cbr ) # 2. Get a list of all PDFs I want to build by renaming CBR list to PDF pdf_files = $( cbr_files:.cbr = .pdf ) # 3. Set where the unpacked images should go. We'll delete them after each build image_dir = .images-$< # 4. The first target specified is always the default when we run `make` without any arguments all : ${ pdf_files } @echo All done # 5. `make clean` will remove all the generated PDFs clean : rm ${ pdf_files } # 6. Use Pattern Rules to build an individual PDF file %.pdf : %. cbr # use @ to prevent `make` from printing the command it is executing @echo Building $< into $@ # ^ ^ # | | # | | # | +- foo.pdf # | # +- foo.cbr # rar x $< ${ image_dir } / # ^ ^ ^ # | | | # | | +- unpack to destination directory # | | # | +- foo.cbr # | # +- extract # find ${ image_dir } / -size 0 -ls -delete # ^ ^ ^ ^ # | | | | # | | | +- delete the file # | | | # | | +- print `ls -l` of the file # | | # | +- only files with zero size # +- find in image directory # magick convert ${ image_dir } /* $@ # ^ ^ # | | # | +- foo.pdf # | # +- all files in image directory # rm -rf ${ image_dir } # ^ # | # +- delete entire image director. We don't need it anymore. # @echo $@ is ready Code the contents of either snippet into a Makefile and put the Makefile in the same directory as all the cbr files. Then execute make and a pile of pdf files should get created. If we run with make -j 4 it will even run multiple files in parallel where 4 is the number of parallel jobs you'd like to run. Revel in the code we didn't have to write to enable parallelism!","title":"Makefile with in-Line Comments"},{"location":"blog/2021/i-heart-make/#a-little-deeper","text":"The make magic occurs in step 6 with %.pdf: %.cbr . This is officially called a pattern rule according to the documentation. It tells make to build a target for any file suffixed with .pdf and set a dependency for the same file suffixed with .cbr . With the pattern rule in place and using $< to represent the first dependency and $@ to represent the target file, we can script out the remaining build. Another piece of magic is in step #3 . image_dir = .images-$< is a variable assignment referencing $< . The = assignment operator in make is a macro, meaning it won't get evaluated until the variable is referenced in a target. This can be surprising at first, but in this case, it provides a nice unique directory for our images to get unpacked. More details about Makefile variable use can be found in their docs .","title":"A Little Deeper"},{"location":"blog/2021/i-heart-make/#conclusion","text":"make isn't the shinest build system around. Wikipedia says there are over 40 of them, but in my opinion, make get's the most value for the least amount of effort. make provides dependency checking, multiple job support, and simple bash-like syntax without the need to npm install the_world . Thanks for make ing it this far. Let me know how you make use of make in the comments below.","title":"Conclusion"},{"location":"blog/2022/how-to-airflow-with-helm/","text":"How to Setup Airflow in its own Kubernetes namespace using Helm \u00b6 Create a Helm values file to contain settings specific to your needs. The main settings we listed demonstrate a few things: pull dags from a git repository enable Airflow API endpoints enable Airflow to use KubernetesPodOperator on itself use simple database setup disable Redis and enable KubernetesExecutor git : dags : enabled : true repositories : - repository : https://ro_user:seeeecret@bitbucket.org/some-project/dags-repo.git name : some-project branch : main scheduler : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags web : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags - name : AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX value : \"True\" - name : AIRFLOW_BASE_URL value : https://airflow.example.com - name : AIRFLOW__API__AUTH_BACKEND value : \"airflow.api.auth.backend.default\" - name : AIRFLOW__API__ENABLE_EXPERIMENTAL_API value : \"True\" worker : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags # begin https://artifacthub.io/packages/helm/bitnami/airflow#kubernetesexecutor executor : KubernetesExecutor redis : endable : false serviceAccount : create : true rbac : create : true # end https://artifacthub.io/packages/helm/bitnami/airflow#kubernetesexecutor postgresql : # standalone is default, but its nice to call it out in case we forget. architecture : standalone Install it using Helm helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm upgrade --install --namespace funland \\ airflow bitnami/airflow \\ --version 12 .0.14 \\ --values deploy/h2m-airflow-prod.yml Get the admin password echo $( kubectl get secret --namespace \"ilabs\" airflow -o jsonpath = \"{.data.airflow-password}\" | base64 --decode ) References \u00b6 https://docs.bitnami.com/kubernetes/infrastructure/apache-airflow/ https://artifacthub.io/packages/helm/bitnami/airflow","title":"How to Setup Airflow in its own Kubernetes namespace using Helm"},{"location":"blog/2022/how-to-airflow-with-helm/#how-to-setup-airflow-in-its-own-kubernetes-namespace-using-helm","text":"Create a Helm values file to contain settings specific to your needs. The main settings we listed demonstrate a few things: pull dags from a git repository enable Airflow API endpoints enable Airflow to use KubernetesPodOperator on itself use simple database setup disable Redis and enable KubernetesExecutor git : dags : enabled : true repositories : - repository : https://ro_user:seeeecret@bitbucket.org/some-project/dags-repo.git name : some-project branch : main scheduler : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags web : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags - name : AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX value : \"True\" - name : AIRFLOW_BASE_URL value : https://airflow.example.com - name : AIRFLOW__API__AUTH_BACKEND value : \"airflow.api.auth.backend.default\" - name : AIRFLOW__API__ENABLE_EXPERIMENTAL_API value : \"True\" worker : extraEnvVars : - name : PYTHONPATH value : /opt/bitnami/airflow/dags/git_some-project/dags # begin https://artifacthub.io/packages/helm/bitnami/airflow#kubernetesexecutor executor : KubernetesExecutor redis : endable : false serviceAccount : create : true rbac : create : true # end https://artifacthub.io/packages/helm/bitnami/airflow#kubernetesexecutor postgresql : # standalone is default, but its nice to call it out in case we forget. architecture : standalone Install it using Helm helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm upgrade --install --namespace funland \\ airflow bitnami/airflow \\ --version 12 .0.14 \\ --values deploy/h2m-airflow-prod.yml Get the admin password echo $( kubectl get secret --namespace \"ilabs\" airflow -o jsonpath = \"{.data.airflow-password}\" | base64 --decode )","title":"How to Setup Airflow in its own Kubernetes namespace using Helm"},{"location":"blog/2022/how-to-airflow-with-helm/#references","text":"https://docs.bitnami.com/kubernetes/infrastructure/apache-airflow/ https://artifacthub.io/packages/helm/bitnami/airflow","title":"References"},{"location":"blog/2022/how-to-k8s-service-account/","text":"How to use Kubernetes Namespaces and Service Accounts for Fun and Profit \u00b6 We'll create a namespace named funland and show how to use a token to access it. Create a Namespace \u00b6 kubectl create namespace funland Create a Service Account \u00b6 This creates a new service account, an \"owner\" role, and assigns the owner to the new service account and to the default service account. kubectl -n funland apply -f- <<YAML --- apiVersion: v1 kind: ServiceAccount metadata: name: funland-sa namespace: funland --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: funland-owner namespace: funland rules: - apiGroups: [\"*\"] resources: [\"*\"] verbs: [\"*\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: funland-binding namespace: funland roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: funland-owner subjects: - kind: ServiceAccount name: default namespace: funland - kind: ServiceAccount name: funland-sa namespace: funland YAML Get the token for the team \u00b6 # Step by Step SECRET_NAME = $( kubectl -n funland get secrets | awk '/funland-sa/ {print $1}' ) TOKEN = $( kubectl -n funland get secrets ${ SECRET_NAME } -o jsonpath = '{.data.token}' | base64 --decode ) # ** OR ** All at once TOKEN = $( kubectl -n funland get secrets $( kubectl -n funland get secrets | awk '/funland-sa/ {print $1}' ) -o jsonpath = '{.data.token}' | base64 --decode ) Use the Token from another host \u00b6 The $TOKEN variable is confidential and should be treated with care. Transfer it carefully to the target client or user. kubectl config set-credentials funland-sa --token = \" ${ TOKEN } \" kubectl config set-cluster funland --server = https://1.2.3.4 --insecure-skip-tls-verify kubectl config set-context funland --user funland-sa --cluster funland --namespace = funland kubectl config use-context funland Take it for a Spins \u00b6 Verify it has nothing installed kubectl get all Check the weather from inside namespace kubectl run weather --rm -it --restart='Never' --image curlimages/curl -- wttr.in Add Certificate Authority \u00b6 Get certificate-authority-data from the cluster entry for the target server. kubectl config view --flatten --minify Edit ~/.kube/config and replace insecure-skip-tls-verify with the certificate-authority-data from the previous step. We could use the --certificate option in kubectl config set-cluster , but we find this is easier than juggling additional variables. Here is the kubectl config set-cluster method: kubectl config set-cluster funland --server = https://1.2.3.4 --certificate-authority = \" ${ CERT_CA_DATA } \" Cleanup \u00b6 kubectl delete namespace funland kubectl config delete-context funland kubectl config delete-cluster funland kubectl config delete-user funland-sa","title":"How to use Kubernetes Namespaces and Service Accounts for Fun and Profit"},{"location":"blog/2022/how-to-k8s-service-account/#how-to-use-kubernetes-namespaces-and-service-accounts-for-fun-and-profit","text":"We'll create a namespace named funland and show how to use a token to access it.","title":"How to use Kubernetes Namespaces and Service Accounts for Fun and Profit"},{"location":"blog/2022/how-to-k8s-service-account/#create-a-namespace","text":"kubectl create namespace funland","title":"Create a Namespace"},{"location":"blog/2022/how-to-k8s-service-account/#create-a-service-account","text":"This creates a new service account, an \"owner\" role, and assigns the owner to the new service account and to the default service account. kubectl -n funland apply -f- <<YAML --- apiVersion: v1 kind: ServiceAccount metadata: name: funland-sa namespace: funland --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: funland-owner namespace: funland rules: - apiGroups: [\"*\"] resources: [\"*\"] verbs: [\"*\"] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: funland-binding namespace: funland roleRef: apiGroup: rbac.authorization.k8s.io kind: Role name: funland-owner subjects: - kind: ServiceAccount name: default namespace: funland - kind: ServiceAccount name: funland-sa namespace: funland YAML","title":"Create a Service Account"},{"location":"blog/2022/how-to-k8s-service-account/#get-the-token-for-the-team","text":"# Step by Step SECRET_NAME = $( kubectl -n funland get secrets | awk '/funland-sa/ {print $1}' ) TOKEN = $( kubectl -n funland get secrets ${ SECRET_NAME } -o jsonpath = '{.data.token}' | base64 --decode ) # ** OR ** All at once TOKEN = $( kubectl -n funland get secrets $( kubectl -n funland get secrets | awk '/funland-sa/ {print $1}' ) -o jsonpath = '{.data.token}' | base64 --decode )","title":"Get the token for the team"},{"location":"blog/2022/how-to-k8s-service-account/#use-the-token-from-another-host","text":"The $TOKEN variable is confidential and should be treated with care. Transfer it carefully to the target client or user. kubectl config set-credentials funland-sa --token = \" ${ TOKEN } \" kubectl config set-cluster funland --server = https://1.2.3.4 --insecure-skip-tls-verify kubectl config set-context funland --user funland-sa --cluster funland --namespace = funland kubectl config use-context funland","title":"Use the Token from another host"},{"location":"blog/2022/how-to-k8s-service-account/#take-it-for-a-spins","text":"Verify it has nothing installed kubectl get all Check the weather from inside namespace kubectl run weather --rm -it --restart='Never' --image curlimages/curl -- wttr.in","title":"Take it for a Spins"},{"location":"blog/2022/how-to-k8s-service-account/#add-certificate-authority","text":"Get certificate-authority-data from the cluster entry for the target server. kubectl config view --flatten --minify Edit ~/.kube/config and replace insecure-skip-tls-verify with the certificate-authority-data from the previous step. We could use the --certificate option in kubectl config set-cluster , but we find this is easier than juggling additional variables. Here is the kubectl config set-cluster method: kubectl config set-cluster funland --server = https://1.2.3.4 --certificate-authority = \" ${ CERT_CA_DATA } \"","title":"Add Certificate Authority"},{"location":"blog/2022/how-to-k8s-service-account/#cleanup","text":"kubectl delete namespace funland kubectl config delete-context funland kubectl config delete-cluster funland kubectl config delete-user funland-sa","title":"Cleanup"},{"location":"blog/2022/instant-replay-live/","text":"Instant Replay Live \u00b6 See yourself from 2 seconds ago. https://ddrscott.github.io/delayed-feed/ https://gist.github.com/ddrscott/78ac23e92abd0852f92ddae7ba5990c9 Premise \u00b6 Analyzing yourself during activities is best done by coaches. When a coach isn't available or affordable, using a mirror or video recordings are common substitutes. Unfortunately, the act of looking at a mirror and adjusting your position to get the correct angle interfers with the action. Using a video device to record and playback is also tiresome because it takes away time from repeating target technique. Instant Replay Live is set it and forget it. It shows the user what happened just moments ago. Period. It's always on. It won't fill up your disk space. There's nothing to download and it only has 1 setting: changing the delay. In this way, the trainee can perform their action, glance at the screen to see how the did, do the action again, glance at the screen again, and repeat until the desired outcome is performed. QRCode \u00b6 https://qr-code-styling.com { \"width\" : 255 , \"height\" : 255 , \"data\" : \"https://rtcxntbe.vercel.app\" , \"margin\" : 10 , \"qrOptions\" :{ \"typeNumber\" : \"0\" , \"mode\" : \"Byte\" , \"errorCorrectionLevel\" : \"Q\" }, \"imageOptions\" :{ \"hideBackgroundDots\" : true , \"imageSize\" : 0.4 , \"margin\" : 0 }, \"dotsOptions\" :{ \"type\" : \"rounded\" , \"color\" : \"#6a1a4c\" , \"gradient\" :{ \"type\" : \"linear\" , \"rotation\" : 0.15707963267948966 , \"colorStops\" :[{ \"offset\" : 0 , \"color\" : \"#ff677e\" },{ \"offset\" : 1 , \"color\" : \"#6d6265\" }]}}, \"backgroundOptions\" :{ \"color\" : \"#111111\" }, \"image\" : null , \"dotsOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#6a1a4c\" , \"color2\" : \"#6a1a4c\" , \"rotation\" : \"0\" }}, \"cornersSquareOptions\" :{ \"type\" : \"extra-rounded\" , \"color\" : \"#ff677e\" }, \"cornersSquareOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#000000\" , \"color2\" : \"#000000\" , \"rotation\" : \"0\" }}, \"cornersDotOptions\" :{ \"type\" : \"\" , \"color\" : \"#6d6265\" }, \"cornersDotOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#000000\" , \"color2\" : \"#000000\" , \"rotation\" : \"0\" }}, \"backgroundOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#ffffff\" , \"color2\" : \"#ffffff\" , \"rotation\" : \"0\" }}} Use Cases \u00b6 Improve your golf/tennis/baseball swing. Improve your dramatic facial expressions. Improve bowling approach. How does your hair look from behind? Branding: \u00b6 https://looka.com/editor/86626287 Instant Feedback : You're Welcome https://looka.com/editor/86772106","title":"Instant Replay Live"},{"location":"blog/2022/instant-replay-live/#instant-replay-live","text":"See yourself from 2 seconds ago. https://ddrscott.github.io/delayed-feed/ https://gist.github.com/ddrscott/78ac23e92abd0852f92ddae7ba5990c9","title":"Instant Replay Live"},{"location":"blog/2022/instant-replay-live/#premise","text":"Analyzing yourself during activities is best done by coaches. When a coach isn't available or affordable, using a mirror or video recordings are common substitutes. Unfortunately, the act of looking at a mirror and adjusting your position to get the correct angle interfers with the action. Using a video device to record and playback is also tiresome because it takes away time from repeating target technique. Instant Replay Live is set it and forget it. It shows the user what happened just moments ago. Period. It's always on. It won't fill up your disk space. There's nothing to download and it only has 1 setting: changing the delay. In this way, the trainee can perform their action, glance at the screen to see how the did, do the action again, glance at the screen again, and repeat until the desired outcome is performed.","title":"Premise"},{"location":"blog/2022/instant-replay-live/#qrcode","text":"https://qr-code-styling.com { \"width\" : 255 , \"height\" : 255 , \"data\" : \"https://rtcxntbe.vercel.app\" , \"margin\" : 10 , \"qrOptions\" :{ \"typeNumber\" : \"0\" , \"mode\" : \"Byte\" , \"errorCorrectionLevel\" : \"Q\" }, \"imageOptions\" :{ \"hideBackgroundDots\" : true , \"imageSize\" : 0.4 , \"margin\" : 0 }, \"dotsOptions\" :{ \"type\" : \"rounded\" , \"color\" : \"#6a1a4c\" , \"gradient\" :{ \"type\" : \"linear\" , \"rotation\" : 0.15707963267948966 , \"colorStops\" :[{ \"offset\" : 0 , \"color\" : \"#ff677e\" },{ \"offset\" : 1 , \"color\" : \"#6d6265\" }]}}, \"backgroundOptions\" :{ \"color\" : \"#111111\" }, \"image\" : null , \"dotsOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#6a1a4c\" , \"color2\" : \"#6a1a4c\" , \"rotation\" : \"0\" }}, \"cornersSquareOptions\" :{ \"type\" : \"extra-rounded\" , \"color\" : \"#ff677e\" }, \"cornersSquareOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#000000\" , \"color2\" : \"#000000\" , \"rotation\" : \"0\" }}, \"cornersDotOptions\" :{ \"type\" : \"\" , \"color\" : \"#6d6265\" }, \"cornersDotOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#000000\" , \"color2\" : \"#000000\" , \"rotation\" : \"0\" }}, \"backgroundOptionsHelper\" :{ \"colorType\" :{ \"single\" : true , \"gradient\" : false }, \"gradient\" :{ \"linear\" : true , \"radial\" : false , \"color1\" : \"#ffffff\" , \"color2\" : \"#ffffff\" , \"rotation\" : \"0\" }}}","title":"QRCode"},{"location":"blog/2022/instant-replay-live/#use-cases","text":"Improve your golf/tennis/baseball swing. Improve your dramatic facial expressions. Improve bowling approach. How does your hair look from behind?","title":"Use Cases"},{"location":"blog/2022/instant-replay-live/#branding","text":"https://looka.com/editor/86626287 Instant Feedback : You're Welcome https://looka.com/editor/86772106","title":"Branding:"},{"location":"blog/2023/how-to-make-a-website-via-github/","text":"How to Make a Website from scratch in 7:59 seconds with Github \u00b6 Wordpress? Squarespace? Wix? Not today. Those are great products for hosting articles and marketing, but you want to make an application. You want to make something the old-fashioned way. You want to know what's under the hood, and you want to make it easy for others to help you along the way. TL;DR - The goal is to ~understand how~ make a website. Enter Github and Codespaces! Steps \u00b6 Create a Github Account \u00b6 I made one for my friend: TheChickenCow. Start a Codespaces \u00b6 Use Codespaces instead of Create Respository . We'll eventually use Codespaces to push to the repository. Otherwise, it'll take more steps to import the repository into Codespaces. Trust us! Create the Content for the Website \u00b6 docs/index.html \u00b6 This is the primary content of the webpage. <!doctype html> < html lang = \"en\" class = \"no-js\" > < head > < meta charset = \"utf-8\" > < meta name = \"viewport\" content = \"width=device-width,initial-scale=1\" > < link rel = \"manifest\" href = \"manifest.json\" > < link rel = \"canonical\" href = \"https://thechickencow.github.com/dune-scroller\" > < title > Dune by Frank Herbert 1965 </ title > < meta property = \"og:title\" content = \"Dune by Frank Herbert\" > < meta property = \"og:description\" content = \"A young man's journey through political conflict on a desert planet that holds the key to the universe's most valuable substance\" > < meta property = \"og:image\" content = \"https://upload.wikimedia.org/wikipedia/en/d/de/Dune-Frank_Herbert_%281965%29_First_edition.jpg\" > < meta property = \"og:url\" content = \"https://thechickencow.github.com/dune-scroller\" > < script src = \"app.js\" async ></ script > < link rel = \"stylesheet\" href = \"app.css\" > </ head > < body dir = \"ltr\" > < h1 > < img src = 'https://upload.wikimedia.org/wikipedia/en/d/de/Dune-Frank_Herbert_%281965%29_First_edition.jpg' alt = \"Book Cover\" /> </ h1 > < div class = \"content\" ></ div > </ body > </ html > docs/app.css \u00b6 This provides the styling and coloring. : root { /* https://paletton.com/#uid=30A0u0k4ftn0mRD1TBP7no+bil4 */ --base-color : #EADBCB ; --text-color : #4F5573 ; --highlight-color : #70927C ; } body { background-color : var ( --base-color ); color : var ( --text-color ); padding : 0 10 vw ; margin : 0 ; font-family : serif ; font-size : 18 px ; border-left : 10 px solid var ( --highlight-color ); } h1 { margin-top : 0 ; } . content { white-space : pre-line ; line-height : 2 ; text-align : justify ; } docs/app.js \u00b6 This defines the behavior which fetches the book contents from a different Github page to display it on our website. This is for demonstration purposes only. Do this at your own risk. const book_url = 'https://raw.githubusercontent.com/ganesh-k13/shell/master/test_search/www.glozman.com/TextPages/Frank%20Herbert%20-%20Dune.txt' ; fetch ( book_url ). then ( function ( response ) { return response . text (); }). then ( function ( html ) { document . querySelector ( '.content' ). innerHTML = html . replace ( /\\n\\n/g , '<br/>' ); }). catch ( function ( err ) { console . warn ( 'Something went wrong.' , err ); }); README.md \u00b6 # Dune Scroller _____________________ < Yep. We went there. > --------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || || Read Dune by Frank Herbert via scrolling the whole freaking thing. ## Future Features As an exercise to do at home: - Pick up were you left off, because no one can finish this book in a single sitting. - Auto-scroll based on momentum of initial drag scroll. - Change font size. ## Thanks - [ ganesh-k13 ]( https://github.com/ganesh-k13/shell/blob/master/test_search/www.glozman.com/TextPages/Frank%20Herbert%20-%20Dune.txt ) for the Dune text - [ Wikipedia ]( https://en.wikipedia.org/wiki/Dune_(novel\\ )) for the book cover Publish to Github \u00b6 Select the Branch Tab on the far left side. Select Publish to Github Rename codespaces-blank to dune-scroller Select Publish to Github public (not private) All files in the project will get automatically selected and hit OK to confirm the upload. Open on Github \u00b6 Notice the notifications at the bottom of Codespaces. It will show the repository has been published to Github. Select Open on Github to see the source code. Publish the Final Site \u00b6 Select the Settings tab near the top. Select the Pages tab in the left sidebar. In the Branch section, choose main Next to it, choose /docs Finally, click Save The publish will kick off a deployment Action. Wait about 2-minute \u00b6 The initial deployment of the site take about 2 minutes. Actions are observable in the top Actions tab. 1. Select Actions from the tab tab. 2. Select pages build and deployment Get the Link \u00b6 When the deployment is finished, the deploy step will reveal the final website link that you can share with friends and family or the rest of the Internet. https://ddrscott.github.io/dune-scroller/ Conclusion \u00b6 We hope this step by step tutorial helped give you a start on your web development journey. We know this probably gave you more questions than answers, but the goal was to get you started and have a site at the end. To learn more about Codespaces try their documentation: https://docs.github.com/en/codespaces Languages Used \u00b6 html css javascript Learn about all 3 from https://www.w3schools.com/default.asp Connect \u00b6 Let us know what you're working on or publish or stuck on in the comments below. Happy coding!","title":"How to Make a Website from Scratch via Github"},{"location":"blog/2023/how-to-make-a-website-via-github/#how-to-make-a-website-from-scratch-in-759-seconds-with-github","text":"Wordpress? Squarespace? Wix? Not today. Those are great products for hosting articles and marketing, but you want to make an application. You want to make something the old-fashioned way. You want to know what's under the hood, and you want to make it easy for others to help you along the way. TL;DR - The goal is to ~understand how~ make a website. Enter Github and Codespaces!","title":"How to Make a Website from scratch in 7:59 seconds with Github"},{"location":"blog/2023/how-to-make-a-website-via-github/#steps","text":"","title":"Steps"},{"location":"blog/2023/how-to-make-a-website-via-github/#create-a-github-account","text":"I made one for my friend: TheChickenCow.","title":"Create a Github Account"},{"location":"blog/2023/how-to-make-a-website-via-github/#start-a-codespaces","text":"Use Codespaces instead of Create Respository . We'll eventually use Codespaces to push to the repository. Otherwise, it'll take more steps to import the repository into Codespaces. Trust us!","title":"Start a Codespaces"},{"location":"blog/2023/how-to-make-a-website-via-github/#create-the-content-for-the-website","text":"","title":"Create the Content for the Website"},{"location":"blog/2023/how-to-make-a-website-via-github/#docsindexhtml","text":"This is the primary content of the webpage. <!doctype html> < html lang = \"en\" class = \"no-js\" > < head > < meta charset = \"utf-8\" > < meta name = \"viewport\" content = \"width=device-width,initial-scale=1\" > < link rel = \"manifest\" href = \"manifest.json\" > < link rel = \"canonical\" href = \"https://thechickencow.github.com/dune-scroller\" > < title > Dune by Frank Herbert 1965 </ title > < meta property = \"og:title\" content = \"Dune by Frank Herbert\" > < meta property = \"og:description\" content = \"A young man's journey through political conflict on a desert planet that holds the key to the universe's most valuable substance\" > < meta property = \"og:image\" content = \"https://upload.wikimedia.org/wikipedia/en/d/de/Dune-Frank_Herbert_%281965%29_First_edition.jpg\" > < meta property = \"og:url\" content = \"https://thechickencow.github.com/dune-scroller\" > < script src = \"app.js\" async ></ script > < link rel = \"stylesheet\" href = \"app.css\" > </ head > < body dir = \"ltr\" > < h1 > < img src = 'https://upload.wikimedia.org/wikipedia/en/d/de/Dune-Frank_Herbert_%281965%29_First_edition.jpg' alt = \"Book Cover\" /> </ h1 > < div class = \"content\" ></ div > </ body > </ html >","title":"docs/index.html"},{"location":"blog/2023/how-to-make-a-website-via-github/#docsappcss","text":"This provides the styling and coloring. : root { /* https://paletton.com/#uid=30A0u0k4ftn0mRD1TBP7no+bil4 */ --base-color : #EADBCB ; --text-color : #4F5573 ; --highlight-color : #70927C ; } body { background-color : var ( --base-color ); color : var ( --text-color ); padding : 0 10 vw ; margin : 0 ; font-family : serif ; font-size : 18 px ; border-left : 10 px solid var ( --highlight-color ); } h1 { margin-top : 0 ; } . content { white-space : pre-line ; line-height : 2 ; text-align : justify ; }","title":"docs/app.css"},{"location":"blog/2023/how-to-make-a-website-via-github/#docsappjs","text":"This defines the behavior which fetches the book contents from a different Github page to display it on our website. This is for demonstration purposes only. Do this at your own risk. const book_url = 'https://raw.githubusercontent.com/ganesh-k13/shell/master/test_search/www.glozman.com/TextPages/Frank%20Herbert%20-%20Dune.txt' ; fetch ( book_url ). then ( function ( response ) { return response . text (); }). then ( function ( html ) { document . querySelector ( '.content' ). innerHTML = html . replace ( /\\n\\n/g , '<br/>' ); }). catch ( function ( err ) { console . warn ( 'Something went wrong.' , err ); });","title":"docs/app.js"},{"location":"blog/2023/how-to-make-a-website-via-github/#readmemd","text":"# Dune Scroller _____________________ < Yep. We went there. > --------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || || Read Dune by Frank Herbert via scrolling the whole freaking thing. ## Future Features As an exercise to do at home: - Pick up were you left off, because no one can finish this book in a single sitting. - Auto-scroll based on momentum of initial drag scroll. - Change font size. ## Thanks - [ ganesh-k13 ]( https://github.com/ganesh-k13/shell/blob/master/test_search/www.glozman.com/TextPages/Frank%20Herbert%20-%20Dune.txt ) for the Dune text - [ Wikipedia ]( https://en.wikipedia.org/wiki/Dune_(novel\\ )) for the book cover","title":"README.md"},{"location":"blog/2023/how-to-make-a-website-via-github/#publish-to-github","text":"Select the Branch Tab on the far left side. Select Publish to Github Rename codespaces-blank to dune-scroller Select Publish to Github public (not private) All files in the project will get automatically selected and hit OK to confirm the upload.","title":"Publish to Github"},{"location":"blog/2023/how-to-make-a-website-via-github/#open-on-github","text":"Notice the notifications at the bottom of Codespaces. It will show the repository has been published to Github. Select Open on Github to see the source code.","title":"Open on Github"},{"location":"blog/2023/how-to-make-a-website-via-github/#publish-the-final-site","text":"Select the Settings tab near the top. Select the Pages tab in the left sidebar. In the Branch section, choose main Next to it, choose /docs Finally, click Save The publish will kick off a deployment Action.","title":"Publish the Final Site"},{"location":"blog/2023/how-to-make-a-website-via-github/#wait-about-2-minute","text":"The initial deployment of the site take about 2 minutes. Actions are observable in the top Actions tab. 1. Select Actions from the tab tab. 2. Select pages build and deployment","title":"Wait about 2-minute"},{"location":"blog/2023/how-to-make-a-website-via-github/#get-the-link","text":"When the deployment is finished, the deploy step will reveal the final website link that you can share with friends and family or the rest of the Internet. https://ddrscott.github.io/dune-scroller/","title":"Get the Link"},{"location":"blog/2023/how-to-make-a-website-via-github/#conclusion","text":"We hope this step by step tutorial helped give you a start on your web development journey. We know this probably gave you more questions than answers, but the goal was to get you started and have a site at the end. To learn more about Codespaces try their documentation: https://docs.github.com/en/codespaces","title":"Conclusion"},{"location":"blog/2023/how-to-make-a-website-via-github/#languages-used","text":"html css javascript Learn about all 3 from https://www.w3schools.com/default.asp","title":"Languages Used"},{"location":"blog/2023/how-to-make-a-website-via-github/#connect","text":"Let us know what you're working on or publish or stuck on in the comments below. Happy coding!","title":"Connect"},{"location":"blog/2023/larry-pierce-aka-dad/","text":"Larry Pierce, aka Dad \u00b6 cowsay \"Best Dad I ever had. I'll miss you\" # ____________________________________ # < Best Dad I ever had. I'll miss you > # ------------------------------------ # \\ ^__^ # \\ (oo)\\_______ # (__)\\ )\\/\\ # ||----w | # || || Computers Are Easy, Feelings Are Hard \u00b6 Today, I received the news my Dad had passed away. Two days ago he was hospitalized for falling. Yesterday, I called to check up. Today, he's gone. My last phone call with him while he was in the hospital he told me, \"I'm fine. Just really tired from the medicine. How's Karen's parents in China?\" I told him, \"they're okay and thanks for asking! Get some rest. We'll call tomorrow\" Rest he did. The first and last time he took my advice. Not a Tech Person \u00b6 My Dad was not a tech person. He still preferred his 10 year old Garmin GPS and refused to have a phone smarter than him. When he retired 10 years ago, he got his first computer and a non-work email address so we could email him pictures from time to time. He stayed on top of the news and current events through the TV and was just getting use to reading articles on MSN . He used a landline as his primary number and had a voicemail machine. His favorite feature of the landline was how the Caller-ID showed up on the TV before he answered it. He always knew where the phone was located because it was attached to the wall. Phones maybe smart, but no phone is wiser than Dad. Humor \u00b6 My Dad loved to laugh, but couldn't tell a joke. He had a boisterous one-of-a-kind laugh that went higher pitch during the inhale phase. (Note to self: turn his laugh into a ringtone) He was a literal person that kept things simple. All my jokes would go over his head. Sometimes he would look up to catch them. Adoption \u00b6 We can't choose our parents, but my Dad chose me. I was 4 years old at the time, and after logistics, I finally came over at 5. He chose my sister, too. Here we are around 1985. He would take us bike riding around Lake Opeka in Des Plaines, IL . We would feed the ducks with stale bread. He'd encourage us to be outside by being outside with us. Fiscally Responsible \u00b6 My Dad loved to save money. He kept the same wardrobe from his 40s and would only replace articles when they were overwarn, never to have more than what could fit into a small closet. I believe his only real source of new clothing were from gifts. He would try to fix everything himself and with moderate success. Our Internet was \"The Readers Digest Fix-It Yourself Manual\" and \"Complete Do-It Yourself Manual\". Our Youtube was This Old House hosted by Bob Vila . Hard Worker \u00b6 My Dad was a hard worker. He got early and came home late. He went back to school after realizing a B.A. in Political Science was a dead end. We worked at companies until they closed down or he retired . Loyal to the end, he even came out of retirement to help train the next generation. Retirement \u00b6 In his retirement, he preferred to stay around town, visit grand kids, make sandwiches, and catch up on TV shows, movies, and the news. A simple man with simple pleasure. Here we are 30+ years later in Harvard, IL: And here's the final picture I have with him and Morgan. Timeline \u00b6 1946-11-15 - Born 2002-12-31 - Baptized in the name of the Father, Son, and Holy Spirit 2023-02-01 - Meets Jesus Official Obituary \u00b6 Lawrence Roy \"Larry\" Pierce age 76, of Lake in the Hills, Illinois passed away on February 1, 2023, at Northwestern Medicine \u2013 Huntley Hospital. Larry was a supportive loving father that enjoyed hikes, bike riding and traveling. He lived a simple life and indulged in simple pleasures like books and movies. Although he couldn't tell a joke, he had a one-of-a-kind laugh. He was born in Chicago, Illinois on November 15, 1946, the loving son of Archie Roy and Grace (Thoring) Pierce. Larry is survived by his children, Scott (Karen) Pierce, Mark Pierce, and Julie Pierce; his grandchildren, Nathan, Morgan, Jeremy, and Kaili; his brother, Steve (Nancy) Pierce. Not The End \u00b6 This is only one side of my Dad's story and from one narrow perspective. I'm planning on having a more historical/objective write up soon. But in the meantime, please comment if Larry has impacted your life in anyway. Cheers to the best Dad I ever had!","title":"Larry Pierce, aka Dad"},{"location":"blog/2023/larry-pierce-aka-dad/#larry-pierce-aka-dad","text":"cowsay \"Best Dad I ever had. I'll miss you\" # ____________________________________ # < Best Dad I ever had. I'll miss you > # ------------------------------------ # \\ ^__^ # \\ (oo)\\_______ # (__)\\ )\\/\\ # ||----w | # || ||","title":"Larry Pierce, aka Dad"},{"location":"blog/2023/larry-pierce-aka-dad/#computers-are-easy-feelings-are-hard","text":"Today, I received the news my Dad had passed away. Two days ago he was hospitalized for falling. Yesterday, I called to check up. Today, he's gone. My last phone call with him while he was in the hospital he told me, \"I'm fine. Just really tired from the medicine. How's Karen's parents in China?\" I told him, \"they're okay and thanks for asking! Get some rest. We'll call tomorrow\" Rest he did. The first and last time he took my advice.","title":"Computers Are Easy, Feelings Are Hard"},{"location":"blog/2023/larry-pierce-aka-dad/#not-a-tech-person","text":"My Dad was not a tech person. He still preferred his 10 year old Garmin GPS and refused to have a phone smarter than him. When he retired 10 years ago, he got his first computer and a non-work email address so we could email him pictures from time to time. He stayed on top of the news and current events through the TV and was just getting use to reading articles on MSN . He used a landline as his primary number and had a voicemail machine. His favorite feature of the landline was how the Caller-ID showed up on the TV before he answered it. He always knew where the phone was located because it was attached to the wall. Phones maybe smart, but no phone is wiser than Dad.","title":"Not a Tech Person"},{"location":"blog/2023/larry-pierce-aka-dad/#humor","text":"My Dad loved to laugh, but couldn't tell a joke. He had a boisterous one-of-a-kind laugh that went higher pitch during the inhale phase. (Note to self: turn his laugh into a ringtone) He was a literal person that kept things simple. All my jokes would go over his head. Sometimes he would look up to catch them.","title":"Humor"},{"location":"blog/2023/larry-pierce-aka-dad/#adoption","text":"We can't choose our parents, but my Dad chose me. I was 4 years old at the time, and after logistics, I finally came over at 5. He chose my sister, too. Here we are around 1985. He would take us bike riding around Lake Opeka in Des Plaines, IL . We would feed the ducks with stale bread. He'd encourage us to be outside by being outside with us.","title":"Adoption"},{"location":"blog/2023/larry-pierce-aka-dad/#fiscally-responsible","text":"My Dad loved to save money. He kept the same wardrobe from his 40s and would only replace articles when they were overwarn, never to have more than what could fit into a small closet. I believe his only real source of new clothing were from gifts. He would try to fix everything himself and with moderate success. Our Internet was \"The Readers Digest Fix-It Yourself Manual\" and \"Complete Do-It Yourself Manual\". Our Youtube was This Old House hosted by Bob Vila .","title":"Fiscally Responsible"},{"location":"blog/2023/larry-pierce-aka-dad/#hard-worker","text":"My Dad was a hard worker. He got early and came home late. He went back to school after realizing a B.A. in Political Science was a dead end. We worked at companies until they closed down or he retired . Loyal to the end, he even came out of retirement to help train the next generation.","title":"Hard Worker"},{"location":"blog/2023/larry-pierce-aka-dad/#retirement","text":"In his retirement, he preferred to stay around town, visit grand kids, make sandwiches, and catch up on TV shows, movies, and the news. A simple man with simple pleasure. Here we are 30+ years later in Harvard, IL: And here's the final picture I have with him and Morgan.","title":"Retirement"},{"location":"blog/2023/larry-pierce-aka-dad/#timeline","text":"1946-11-15 - Born 2002-12-31 - Baptized in the name of the Father, Son, and Holy Spirit 2023-02-01 - Meets Jesus","title":"Timeline"},{"location":"blog/2023/larry-pierce-aka-dad/#official-obituary","text":"Lawrence Roy \"Larry\" Pierce age 76, of Lake in the Hills, Illinois passed away on February 1, 2023, at Northwestern Medicine \u2013 Huntley Hospital. Larry was a supportive loving father that enjoyed hikes, bike riding and traveling. He lived a simple life and indulged in simple pleasures like books and movies. Although he couldn't tell a joke, he had a one-of-a-kind laugh. He was born in Chicago, Illinois on November 15, 1946, the loving son of Archie Roy and Grace (Thoring) Pierce. Larry is survived by his children, Scott (Karen) Pierce, Mark Pierce, and Julie Pierce; his grandchildren, Nathan, Morgan, Jeremy, and Kaili; his brother, Steve (Nancy) Pierce.","title":"Official Obituary"},{"location":"blog/2023/larry-pierce-aka-dad/#not-the-end","text":"This is only one side of my Dad's story and from one narrow perspective. I'm planning on having a more historical/objective write up soon. But in the meantime, please comment if Larry has impacted your life in anyway. Cheers to the best Dad I ever had!","title":"Not The End"},{"location":"blog/2023/wordy-passwords/","text":"How to Generate a Wordy Password \u00b6 TL;DR \u00b6 grep -E '^[a-z]{3,}$' /usr/share/dict/words | shuf -n4 | paste -sd- - Intro \u00b6 It is 2023 and passwords are still a thing. They are hard to remember and easy to crack. Many sites talk about using words instead of letters, numbers and symbols: https://www.useapassphrase.com/ https://www.nexcess.net/web-tools/secure-password-generator/ https://xkpasswd.net/s/ Most of them were inspired by this comic: We recently needed to generate hard to guess, but recognizable URLs to share some data analysis with clients. We also planned to speak the URLs to our clients via video conferencing. GUIDs (Globally Unique Identifiers) are nearly impossible to comprehend and speak accurately: f95b9390f8fe5d7a6aecd9d563b5f8a5 and b987370e-6906-498b-a5d4-84c1c92c6e64 , so Wordy Passwords\u2122 (TM cause you heard it here first!) came to mind to meet all the requirements. There are sites that can generate these things which we could scrape as needed, but we thought there's got to be a simpler way. Simpler Way \u00b6 If you're on Mac or Linux, the simpler way is already in your terminal. grep -E '^[a-z]{3,}$' /usr/share/dict/words | shuf -n4 | paste -sd- - Let's explain: /usr/share/dict/words is a file with a list of all English words, about 100k of them. grep -E '^[a-z]{3,}$' /usr/share/dict/words filters for lowercase words with 3 or more letters. shuf -n4 picks 4 random entries from the filtered list. Change 4 to whatever is needed for your use case. paste -sd- - joins all the lines with - symbol. This can also be changed to -sd ' ' for spaces or -sd ',' for commas, etc. Note, the last - tells the command to read from /dev/stdin and is necessary on Mac. Use man grep , man shuf , or man paste to get additional details about each command. Example Output: mentions-grouses-datelines-mouses cellulite-sukiyaki-ardner-rusted naturalness-indicate-dependent-beset irony-excursion-flashily-crawl We can then use these in our data generation URLs to get something like: https://your.dataturd.com/mentions-grouses-datelines-mouses https://your.dataturd.com/cellulite-sukiyaki-ardner-rusted https://your.dataturd.com/naturalness-indicate-dependent-beset https://your.dataturd.com/irony-excursion-flashily-crawl In case /usr/share/dict/words doesn't exist, try installing with apt install wamerican . To pick another language try apt search wordlist which will return a bunch of other options for specific languages. Windows PC \u00b6 If you're in Windows, we'd recommend using WSL . This will provide access to a Linux shell which has all the aforementioned commands. If you're not sure where to type in these fancy commands, try searching for \"learn linux terminal\". We'll eventually post additional articles regarding our love for the terminal and why commands like these keep us in it. Alternative Word List \u00b6 We experimented with other word lists. doyle.txt contains words extracted from books featuring Sherlock Holmes. Source code for how the word list was built is located at https://github.com/ddrscott/wordy-passwords . Feel free to search the Internet for other word lists. Closing \u00b6 The terminal is a magical place where mountains of code can be replaced with a few razor sharp commands. shuf and paste can make short work of many tasks. Let us know what you come up with in the comments below!","title":"Wordy Passwords"},{"location":"blog/2023/wordy-passwords/#how-to-generate-a-wordy-password","text":"","title":"How to Generate a Wordy Password"},{"location":"blog/2023/wordy-passwords/#tldr","text":"grep -E '^[a-z]{3,}$' /usr/share/dict/words | shuf -n4 | paste -sd- -","title":"TL;DR"},{"location":"blog/2023/wordy-passwords/#intro","text":"It is 2023 and passwords are still a thing. They are hard to remember and easy to crack. Many sites talk about using words instead of letters, numbers and symbols: https://www.useapassphrase.com/ https://www.nexcess.net/web-tools/secure-password-generator/ https://xkpasswd.net/s/ Most of them were inspired by this comic: We recently needed to generate hard to guess, but recognizable URLs to share some data analysis with clients. We also planned to speak the URLs to our clients via video conferencing. GUIDs (Globally Unique Identifiers) are nearly impossible to comprehend and speak accurately: f95b9390f8fe5d7a6aecd9d563b5f8a5 and b987370e-6906-498b-a5d4-84c1c92c6e64 , so Wordy Passwords\u2122 (TM cause you heard it here first!) came to mind to meet all the requirements. There are sites that can generate these things which we could scrape as needed, but we thought there's got to be a simpler way.","title":"Intro"},{"location":"blog/2023/wordy-passwords/#simpler-way","text":"If you're on Mac or Linux, the simpler way is already in your terminal. grep -E '^[a-z]{3,}$' /usr/share/dict/words | shuf -n4 | paste -sd- - Let's explain: /usr/share/dict/words is a file with a list of all English words, about 100k of them. grep -E '^[a-z]{3,}$' /usr/share/dict/words filters for lowercase words with 3 or more letters. shuf -n4 picks 4 random entries from the filtered list. Change 4 to whatever is needed for your use case. paste -sd- - joins all the lines with - symbol. This can also be changed to -sd ' ' for spaces or -sd ',' for commas, etc. Note, the last - tells the command to read from /dev/stdin and is necessary on Mac. Use man grep , man shuf , or man paste to get additional details about each command. Example Output: mentions-grouses-datelines-mouses cellulite-sukiyaki-ardner-rusted naturalness-indicate-dependent-beset irony-excursion-flashily-crawl We can then use these in our data generation URLs to get something like: https://your.dataturd.com/mentions-grouses-datelines-mouses https://your.dataturd.com/cellulite-sukiyaki-ardner-rusted https://your.dataturd.com/naturalness-indicate-dependent-beset https://your.dataturd.com/irony-excursion-flashily-crawl In case /usr/share/dict/words doesn't exist, try installing with apt install wamerican . To pick another language try apt search wordlist which will return a bunch of other options for specific languages.","title":"Simpler Way"},{"location":"blog/2023/wordy-passwords/#windows-pc","text":"If you're in Windows, we'd recommend using WSL . This will provide access to a Linux shell which has all the aforementioned commands. If you're not sure where to type in these fancy commands, try searching for \"learn linux terminal\". We'll eventually post additional articles regarding our love for the terminal and why commands like these keep us in it.","title":"Windows PC"},{"location":"blog/2023/wordy-passwords/#alternative-word-list","text":"We experimented with other word lists. doyle.txt contains words extracted from books featuring Sherlock Holmes. Source code for how the word list was built is located at https://github.com/ddrscott/wordy-passwords . Feel free to search the Internet for other word lists.","title":"Alternative Word List"},{"location":"blog/2023/wordy-passwords/#closing","text":"The terminal is a magical place where mountains of code can be replaced with a few razor sharp commands. shuf and paste can make short work of many tasks. Let us know what you come up with in the comments below!","title":"Closing"}]}